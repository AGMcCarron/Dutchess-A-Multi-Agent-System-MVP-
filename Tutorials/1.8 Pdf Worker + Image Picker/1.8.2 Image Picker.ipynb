{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Jupyter Notebook follows on from the PDF Worker Notebook if you have not used that to create a series of descriptions for images within a saved folder please go back and do that first, this will not work without it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook goes over the process of retrieving the descriptions generated in the PDF Worker Notebook and displaying the image most relevant to the user query based on these descriptions. We start again by importing some modules and defining some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to switch your description_directory and image_directory to the ones on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_name = \"\"\n",
    "\n",
    "api_key = \"\"\n",
    "\n",
    "description_directory = r\"\"\n",
    "image_directory = r\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then open the descriptions json file we created and store it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{document_name}_descriptions.json\"\n",
    "file_path = os.path.join(description_directory, file_name)\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    descriptions = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a general user query. We place this query inside a prompt and ask the gpt-4o to assess which of the descriptions is closest to the query and based on this to return an indexed number starting from 1, we also ask that if non of them are relevent to state the word \"false\". We can then process this output such that the image that had the description closest to the user query is shown or if no images are relevent we can say as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the double slit experiment\"\n",
    "prompt = f\"out of this list {descriptions} which relates most to {query},if none of them relate to the query state only the word false otherwise state only a single number starting with the first being 0 as this is being used for indexing in python, \"\n",
    "\n",
    "message = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=message)\n",
    "\n",
    "index = response.json()['choices'][0]['message']['content']\n",
    "print(index)\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for names in os.listdir(image_directory):\n",
    "    filenames.append(names)\n",
    "\n",
    "if index == \"false\" or index == \"False\":\n",
    "     print(\"No image returnable\")\n",
    "else:\n",
    "    image = Image.open(os.path.join(image_directory, filenames[int(index)]))\n",
    "    image.show()\n",
    "    print(descriptions[int(index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you should have been able to retrieve an image of a double slit interference pattern (assuming you kept the same initial query). It can be inconsistent even at the best of times, 9/10 times the system works however sometimes the model will retireve the wrong index compared to what it meant and that ruins the whole thing. You can imagine however that given a query we can retireve a relevent image. It should be noted that although through the PDF Worker and Image Picker example we curated the images from a pdf and the descriptions were generated from a chat bot we could have also simply placed some images in the relevant folder and created a .json file with a list of our own manually written descriptions about those images in the order that they are retrieved (order is important as the index retrieved from the descriptions is the same one as for retieving the images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
