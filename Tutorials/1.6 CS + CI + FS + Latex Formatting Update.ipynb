{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77706afc",
   "metadata": {},
   "source": [
    "This is a simple modification to the Custom Search + Code Interpreter + File Search code that updates the output to something with nice formatting rather than the previous which had equations in pure text format of latex which was essentially unreadable. Everything in this is the same apart from one section of the event handler, scroll down to that part to see the explanation. (also remember to change your file_path when running this code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd83357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666d6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do i find the minimum chi squared value?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142406a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai \n",
    "import numpy as np\n",
    "\n",
    "openai_api_key = \"\"\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce516ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Discovery Skills\",\n",
    "  description=\"You are a factual education AI Assistant dedicated to providing accurate, useful information. Your primary task is to assist me by providing me reliable and clear responses to my questions, only ever use information from file search as your source, this knowledge base is _____.  You are reluctant of making any claims unless they are stated or supported by the knowledge base.\",\n",
    "  instructions = \"if you make any code you should always run it\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}],\n",
    "  top_p=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528c489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Summer_Project24\\20-6-24 to 26-6-24\\RAG + CI + FS Latex Formatted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2813d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"the above folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e8a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x0cUncertainties in single-variable\\nfunctions\\nThe functional approach to obtain the uncertainty in a function Z = f (A),\\nwhen A has been measured to be Ā ± α A :\\n\\x02 \\x03\\n\\x04\\n\\x03 \\x04\\x02\\nα Z = \\x02 f Ā + α A − f Ā \\x02 .\\n\\nZ = f (A)\\nf (Ā + αA )\\nf (Ā)\\n\\nThis is shown schematically in the ﬁgure.\\nAssuming small uncertainties, such that the function can be approximated\\nĀ\\nĀ + αA\\nas a straight line in the vicinity of Ā, then the calculus-based approximation to\\nthis result is:\\n\\x02 \\x02\\nAn uncertainty α A in the variable A maps\\n\\x02 dZ \\x02\\ndirectly into an uncertainty α Z in the function\\nα Z = \\x02\\x02 \\x02\\x02 α A .\\ndA\\nZ = f (A).\\nTable 1 Results for the propagation of uncertainties in single-variable functions. The results for the trigonometric functions assume that the angles and\\ntheir uncertainties are in radians.\\nFunction, Z (A)\\n\\ndZ\\ndA\\n\\n1\\nA\\nexp A\\n\\n−\\n\\n1\\nA2\\nexp A\\n\\nαz =\\n\\n1\\nA\\n\\nαz =\\n\\nln A\\n\\nUncertainty\\n\\x02α \\x02 \\x02α \\x02\\nαA\\n\\x02 Z \\x02 \\x02 A\\x02\\n2\\n=\\nZ\\nα\\nOR\\n\\x02 \\x02=\\x02 \\x02\\nA\\nZ\\nA\\nA2\\nαz = exp A α A = Z α A\\nαA\\nA\\n\\nAn\\n\\n1\\nln (10) A\\nn An−1\\n\\n10 A\\n\\n10 A ln (10)\\n\\nαA\\nln (10) A\\n\\x02α \\x02 \\x02 α \\x02\\n\\x02\\n\\x02\\n\\x02 Z \\x02 \\x02 A\\x02\\nαz = \\x02n An−1 \\x02 α A OR \\x02 \\x02 = \\x02n \\x02\\nZ\\nA\\nαz = 10 A ln (10) α A\\n\\nsin A\\n\\ncos A\\n\\nαz = |cos A| α A\\n\\ncos A\\n\\n− sin A\\n\\ntan A\\n\\n1 + tan2\\n\\nαz = |sin A| α A\\n\\x04\\n\\x03\\nαz = 1 + Z 2 α A\\n\\nlog A\\n\\nA\\n\\nαz =\\n\\n\\x0cMEASUREMENTS AND THEIR UNCERTAINTIES\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cMeasurements and their\\nUncertainties\\nA practical guide to modern error analysis\\n\\nIFAN G. HUGHES\\nPhysics Department, Durham University\\n\\nTHOMAS P. A. HASE\\nPhysics Department, Warwick University\\n\\n1\\n\\n\\x0c3\\nGreat Clarendon Street, Oxford OX2 6DP\\nOxford University Press is a department of the University of Oxford.\\nIt furthers the University’s objective of excellence in research, scholarship,\\nand education by publishing worldwide in\\nOxford New York\\nAuckland Cape Town Dar es Salaam Hong Kong Karachi\\nKuala Lumpur Madrid Melbourne Mexico City Nairobi\\nNew Delhi Shanghai Taipei Toronto\\nWith ofﬁces in\\nArgentina Austria Brazil Chile Czech Republic France Greece\\nGuatemala Hungary Italy Japan Poland Portugal Singapore\\nSo', 'uth Korea Switzerland Thailand Turkey Ukraine Vietnam\\nOxford is a registered trade mark of Oxford University Press\\nin the UK and in certain other countries\\nPublished in the United States\\nby Oxford University Press Inc., New York\\nc I. Hughes & T. Hase 2010\\n\\x02\\nThe moral rights of the authors has been asserted\\nDatabase right Oxford University Press (maker)\\nFirst published 2010\\nAll rights reserved. No part of this publication may be reproduced,\\nstored in a retrieval system, or transmitted, in any form or by any means,\\nwithout the prior permission in writing of Oxford University Press,\\nor as expressly permitted by law, or under terms agreed with the appropriate\\nreprographics rights organization. Enquiries concerning reproduction\\noutside the scope of the above should be sent to the Rights Department,\\nOxford University Press, at the address above\\nYou must not circulate this book in any other binding or cover\\nand you must impose the same condition on any acquirer\\nBritish Library Cataloguing in Publication Data\\nData available\\nLibrary of Congress Cataloging in Publication Data\\nData available\\nTypeset by SPI Publisher Services, Pondicherry, India\\nPrinted in Great Britain\\non acid-free paper by\\nCPI Antony Rowe, Chippenham, Wiltshire\\nISBN 978–0–19–956632–7 (hbk)\\n978–0–19–956633–4 (pbk)\\n1 3 5 7 9 10 8 6 4 2\\n\\n\\x0cEr cof am Mam. (IGH)\\nFor my parents. (TPAH)\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cPreface\\nThis book grew out of the process of revamping the ﬁrst-year practical course\\nat the physics department at Durham University. During the restructuring of\\nthe laboratory course, we noted the signiﬁcant changes in the skill set of the\\nstudent cohort over the previous decade. We searched for a book that could be\\na recommended text for the treatment of uncertainties. There is no shortage of\\nbooks which deal with uncertainties in measurements and error analysis. Most\\nof these books treat error analysis in the traditional, old-fashioned approach\\nwhich does not take into account modern developme', 'nts—indeed, error propagation is often treated as an exercise in calculus of many variables. In modern\\nlaboratories computers are used extensively for data taking and analysis, and\\nstudents now have access to, and familiarity with, spreadsheets for manipulation of data. This book is written assuming that most of the number crunching\\nwill be done by computer. Traditional textbooks have appendixes which list,\\ne.g. Gaussian integrals, cumulative distribution functions, tables of chi-squared\\ndistribution likelihoods, and so on. Our emphasis is on calculating the relevant\\nnumbers within routinely available spreadsheet software packages. In contrast\\nto traditional books, we have decided to produce a hands-on guide book: key\\npoints illustrated with worked examples, concise and in a handy format—\\nsufﬁciently user-friendly that students actually bring the book along and use\\nit in the teaching laboratory.\\nThe scope of this book is to cover all the necessary groundwork for laboratory sessions in a ﬁrst- and second-year undergraduate physics laboratory\\nand to contain enough material to be useful for ﬁnal-year projects, graduate\\nstudents and practising professional scientists and engineers.\\nIn contrast to the mathematically rigorous treatment of other textbooks\\nwe have adopted a ‘rule of thumb’ approach, and encourage students to use\\ncomputers to assist with as many of the calculations as possible. Last century\\nif a student had knowledge of an angle and its uncertainty, and was testing\\nthe validity of Rutherford’s scattering law with its sin−4 (θ/2) dependence, the\\nsuggested approach to error propagation was to turn this into an exercise in\\ndifferentiation. Nowadays, a student can create a spreadsheet, calculate the\\nvalue of the function at the desired angle, at the angle+error bar, and deduce the\\nuncertainty in propagation through Rutherford’s formula much more quickly.\\nThroughout the book we encourage a functional approach to calculations, in\\npreference to the calculus-based a', 'pproximation. A large number of end-ofchapter exercises are included, as error analysis is a participation, rather than a\\nspectator, sport.\\nThe only prerequisite is suitably advanced mathematics (an A-level, or\\nequivalent) which is a compulsory qualiﬁcation for studying physics and\\n\\n\\x0cviii\\n\\nPreface\\n\\nengineering at most universities. Although written originally for use in a\\nphysics laboratory we believe the book would be a useful hands-on guide for\\nundergraduates studying the physical sciences and engineering.\\nA preliminary version of this book (‘the little red book’) was used by\\nmore than 1500 students following the Discovery Skills module at Durham\\nUniversity; we are grateful to all of those who helped identify and eradicate\\ntypographical errors, inconsistencies and sources of confusion.\\nSeveral colleagues involved in the teaching laboratories at Durham have\\ncontributed to this book via a number of discussions. We would like to record\\nour gratitude to Del Atkinson (we realise the book is ‘full of errors’), Richard\\nBower, David Carty, Paula Chadwick, Simon Cornish, Graham Cross, Nigel\\nDipper, Ken Durose, David Flower, Douglas Halliday, Michael Hunt, Gordon\\nLove, John Lucey, Lowry McComb, Simon Morris, Robert Potvliege, Steve\\nRayner, Marek Szablewski, and Kevin Weatherill. Many colleagues kindly\\ndonated their time to proofread various chapters, and we are indebted to them\\nfor this service, including Charles Adams, Matthew Brewer, Paula Chadwick,\\nStewart Clark, Malcolm Cooper, David Flower, Patrick Hase, Jony Hudson,\\nMartin Lees, Phillip Petcher, Jon Pritchard, and Marek Szablewski. Simon\\nGardiner gave invaluable TEX advice. For any remaining ﬂaws or lack of\\nclarity the authors alone are responsible. While performing error analysis in\\nresearch, the authors have beneﬁted from discussions with Ed Hinds, Jony\\nHudson, Clemens Kaminski, Ben Sauer, Peter Smith, Derek Stacey, and\\nDuncan Walker. Damian Hampshire pointed out that ‘truth’ should be sought\\nin the department of th', 'eology, not an error-analysis book. Simon Cornish\\nand Lara Bogart kindly provided us with data for some of the ﬁgures. We\\nare grateful to Bethan Mair and Tony Shaw for advice on writing a book,\\nMike Curry for providing food and lodging, and Stewart Clark and Marek\\nSzablewski for eradicating the loneliness of long-distance runs.\\nWe would like to thank our families for support and encouragement, and\\nSönke Adlung and April Warman at OUP for their enthusiasm and patience.\\nDecember 2009\\n\\nDurham and Warwick\\n\\n\\x0cContents\\n1\\n\\nErrors in the physical sciences\\n1.1 The importance of error analysis\\n1.2 Uncertainties in measurement\\n1.2.1 Terminology\\n1.2.2 Random errors\\n1.2.3 Systematic errors\\n1.2.4 Mistakes\\n1.3 Precision of measurements\\n1.3.1 Precision of an analogue device\\n1.3.2 Precision of a digital device\\n1.4 Accuracy of measurements\\nChapter summary\\n\\n1\\n1\\n2\\n3\\n3\\n4\\n4\\n5\\n5\\n6\\n6\\n7\\n\\n2 Random errors in measurements\\n2.1 Analysing distributions: some statistical ideas\\n2.2 The mean\\n2.3 The width of the distribution: estimating the precision\\n2.3.1 Rough-and-ready approach to estimating the width\\n2.3.2 Statistical approach to estimating the width\\n2.4 Continuous distributions\\n2.5 The normal distribution\\n2.6 Sample and parent distribution\\n2.7 The standard error\\n2.7.1 The error in the error\\n2.8 Reporting results\\n2.8.1 Rounding and signiﬁcant ﬁgures\\n2.9 The ﬁve golden rules\\nChapter summary\\nExercises\\n\\n9\\n9\\n9\\n10\\n10\\n11\\n12\\n13\\n13\\n14\\n16\\n17\\n18\\n19\\n19\\n20\\n\\n3\\n\\n23\\n23\\n24\\n24\\n25\\n25\\n26\\n26\\n\\nUncertainties as probabilities\\n3.1 Distributions and probability\\n3.2 The Gaussian probability distribution function\\n3.2.1 Probability calculations\\n3.2.2 Worked example—the error function\\n3.3 Conﬁdence limits and error bars\\n3.3.1 Extended ranges\\n3.3.2 Rejecting outliers\\n\\n\\x0cx\\n\\nContents\\n\\n3.3.3 Experimental example of a Gaussian distribution\\n3.3.4 Comparing experimental results with an accepted value\\n3.4 Poisson probability function for discrete events\\n3.4.1 Worked example—Poisson counts\\n3.4.2 Error bars and conﬁdence limits for Poi', 'sson statistics\\n3.4.3 Approximations for high means\\n3.5 The central limit theorem\\n3.5.1 Examples of the central limit theorem\\nChapter summary\\nExercises\\n4 Error propagation\\n4.1 Propagating the error in a single-variable function\\n4.1.1 The functional approach for single-variable\\nfunctions\\n4.1.2 A calculus-based approximation for single-variable\\nfunctions\\n4.1.3 Look-up table for common single-variable functions\\n4.1.4 Worked example—single variable function\\n4.2 Propagating the error through a multi-variable function\\n4.2.1 The functional approach for multi-variable functions\\n4.2.2 Worked example—functional approach for\\nmulti-variable functions\\n4.2.3 A calculus approximation for multi-variable functions\\n4.2.4 A look-up table for multi-variable functions\\n4.2.5 Comparison of methods\\n4.2.6 Percentage errors—dominant error\\n4.2.7 Using the look-up tables\\n4.2.8 Using the look-up tables—health warning\\n4.3 Propagating errors in functions—a summary\\n4.4 Experimental strategy based on error analysis\\n4.4.1 Experimental strategy for reducing the dominant error\\n4.5 Combined experiments—the weighted mean\\n4.5.1 The error in the mean—a special case of the\\nweighted mean\\nChapter summary\\nExercises\\n5\\n\\nData visualisation and reduction\\n5.1 Producing a good graph\\n5.1.1 The independent and dependent variables\\n5.1.2 Linearising the data\\n5.1.3 Appropriate scales for the axes\\n5.1.4 Labelling the axes\\n5.1.5 Adding data points and error bars to graphs\\n5.1.6 Adding a ﬁt or trend line\\n5.1.7 Adding a title or caption\\n\\n27\\n28\\n28\\n29\\n30\\n30\\n31\\n33\\n34\\n35\\n37\\n37\\n38\\n38\\n39\\n39\\n40\\n41\\n42\\n43\\n43\\n44\\n45\\n45\\n46\\n47\\n47\\n49\\n49\\n50\\n51\\n51\\n53\\n53\\n54\\n54\\n54\\n54\\n55\\n56\\n57\\n\\n\\x0cContents xi\\n\\n5.2 Using a graph to see trends in the data\\n5.2.1 Adding a linear trend line\\n5.2.2 Interpolating, extrapolating and aliasing\\n5.3 Introduction to the method of least squares and maximum\\nlikelihood\\n5.3.1 Example using the method of least squares\\n5.4 Performing a least-squares ﬁt to a straight line\\n5.5 Using graphs to estimate random and systematic errors\\n5.', '6 Residuals\\nChapter summary\\nExercises\\n6\\n\\n7\\n\\nLeast-squares ﬁtting of complex functions\\n6.1 The importance of χ 2 in least-squares ﬁtting\\n6.1.1 χ 2 for data with Poisson errors\\n6.2 Non-uniform error bars\\n6.3 A least-squares ﬁt to a straight line with non-uniform\\nerror bars\\n6.3.1 Strategies for a straight-line ﬁt\\n6.3.2 Analysis of residuals with non-uniform error bars\\n6.4 Performing a weighted least-squares ﬁt—beyond straight\\nlines\\n6.4.1 Least-squares ﬁt to an n th -order polynomial\\n6.4.2 Least-squares ﬁt to an arbitrary nonlinear function\\n6.5 Calculating the errors in a least-squares ﬁt\\n6.5.1 The error surface\\n6.5.2 Conﬁdence limits on parameters from weighted\\nleast-squares ﬁt\\n6.5.3 Worked example 1—a two-parameter ﬁt\\n6.5.4 Worked example 2—a multi-parameter ﬁt\\n6.6 Fitting with constraints\\n6.7 Testing the ﬁt using the residuals\\nChapter summary\\nExercises\\nComputer minimisation and the error matrix\\n7.1 How do ﬁtting programs minimise?\\n7.1.1 Iterative approaches\\n7.1.2 Grid search\\n7.1.3 The gradient-descent method\\n7.1.4 Second-order expansion: the Newton method\\n7.1.5 Second-order expansion: the Gauss–Newton method\\n7.1.6 The Marquardt–Levenberg method\\n7.2 The covariance matrix and uncertainties in ﬁt parameters\\n7.2.1 Extracting uncertainties in ﬁt parameters\\n7.2.2 Curvature matrix for a straight-line ﬁt\\n7.2.3 Scaling the uncertainties\\n\\n57\\n57\\n59\\n59\\n61\\n61\\n62\\n63\\n64\\n64\\n67\\n67\\n68\\n68\\n69\\n71\\n72\\n72\\n72\\n72\\n74\\n74\\n75\\n77\\n79\\n79\\n81\\n82\\n83\\n85\\n85\\n86\\n86\\n87\\n88\\n89\\n90\\n92\\n92\\n93\\n93\\n\\n\\x0cxii\\n\\nContents\\n\\n7.3 Correlations among uncertainties of ﬁt parameters\\n7.3.1 Correlation coefﬁcients—off-diagonal elements of the\\ncovariance matrix\\n7.4 Covariance in error propagation\\n7.4.1 Worked example 1—a straight-line ﬁt\\n7.4.2 Worked example 2—a four-parameter ﬁt\\nChapter summary\\nExercises\\n8\\n\\n9\\n\\nHypothesis testing—how good are our models?\\n8.1 Hypothesis testing\\n8.2 Degrees of freedom\\n8.2.1 Data reduction and the number of degrees of\\nfreedom\\n8.3 The χ 2 probability distribution function\\n8.3.1 χ 2 for one degree of free', 'dom\\n8.4 Using χ 2 as a hypothesis test\\n8.4.1 The reduced χ 2 statistic\\n8.4.2 Testing the null hypothesis—a summary\\n8.5 Testing the quality of a ﬁt using χ 2\\n8.5.1 Worked example 1—testing the quality of a ﬁt\\n8.5.2 Worked example 2—testing different models\\nto a data set\\n8.5.3 What constitutes a good ﬁt?\\n8.6 Testing distributions using χ 2\\n8.6.1 Worked example 3—testing a discrete distribution\\n8.6.2 Worked example 4—testing a continuous\\ndistribution\\n8.7 Occam’s razor\\n8.8 Student’s t-distribution\\n8.9 Scaling uncertainties\\n8.10 Summary of ﬁtting experimental data to a theoretical\\nmodel\\nChapter summary\\nExercises\\nTopics for further study\\n9.1 Least-squares ﬁtting with uncertainties in both variables\\n9.1.1 Fitting to a straight line\\n9.1.2 Fitting to a more general function\\n9.1.3 Orthogonal distance regression\\n9.2 More complex error surfaces\\n9.2.1 Simulated annealing\\n9.2.2 Genetic algorithms\\n9.3 Monte Carlo methods\\n9.3.1 Introduction to Monte Carlo methods\\n9.3.2 Testing distributions with Monte Carlo methods\\n9.4 Bootstrap methods\\n\\n93\\n93\\n95\\n95\\n96\\n97\\n97\\n101\\n101\\n102\\n103\\n104\\n105\\n105\\n107\\n108\\n108\\n109\\n109\\n110\\n111\\n112\\n113\\n114\\n115\\n115\\n116\\n117\\n118\\n121\\n121\\n121\\n122\\n122\\n123\\n123\\n124\\n125\\n125\\n125\\n126\\n\\n\\x0cContents\\n\\n9.5 Bayesian inference\\n9.6 GUM—Guide to the Expression of Uncertainty\\nin Measurement\\nBibliography\\nIndex\\n\\n127\\n129\\n131\\n133\\n\\nxiii\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cErrors in the physical\\nsciences\\nWhat is the role of experiments in the physical sciences? In his Lectures\\non Physics, Volume 1, page 1, the Nobel Laureate Richard Feynman states\\n(Feynman 1963):\\nThe principle of science, the deﬁnition, almost, is the following: The test of all\\nknowledge is experiment. Experiment is the sole judge of scientiﬁc ‘truth’.\\n\\n1\\n1.1 The importance of error analysis\\n\\n2\\n\\n1.3 Precision of measurements\\n\\n5\\n\\n1.4 Accuracy of measurements\\n\\n6\\n\\nChapter summary\\n\\n7\\n\\nWe will emphasise in this book that an experiment is not complete until an\\nanalysis of the uncertainty in the ﬁnal result to be reported has be', 'en conducted.\\nImportant questions such as:\\n• do the results agree with theory?\\n• are the results reproducible?\\n• has a new phenomenon or effect been observed?\\ncan only be answered after appropriate error analysis.\\n\\n1.1\\n\\nThe importance of error analysis\\n\\nThe aim of error analysis is to quantify and record the errors associated\\nwith the inevitable spread in a set of measurements, and to identify how we\\nmay improve the experiment. In the physical sciences experiments are often\\nperformed in order to determine the value of a quantity. However, there will\\nalways be an error associated with that value due to experimental uncertainties.\\nThe sources of these uncertainties are discussed later in this chapter. We can\\nnever be certain what the exact value is, but the errors give us a characteristic\\nrange in which we believe the correct value lies with a speciﬁed likelihood.\\nThese ideas do not just apply to the undergraduate laboratory, but across\\nthe entire physical sciences at the very fundamental level. Some of the socalled fundamental constants, in addition to other physical constants, have been\\ndetermined experimentally and therefore have errors associated with them. For\\nfundamental constants the best accepted values can be found from experiments\\nperformed at Government laboratories such as NIST (National Institute of\\nStandards and Technology)1 in the USA and the National Physical Laboratory\\n(NPL)2 in the UK.\\nAs an example, the currently accepted values (the ﬁrst number), and their\\nerrors (the number after the ±), of Avogadro’s constant, NA , and the Rydberg\\nconstant, R∞ , are:\\n\\n1\\n\\n1.2 Uncertainties in measurement\\n\\n1 http://www.nist.gov/index.html\\n2 http://www.npl.co.uk\\n\\n\\x0c2\\n\\nErrors in the physical sciences\\n\\nNA = (6.022 141 79 ± 0.000 000 30) × 1023 mol−1 ,\\nand\\nR∞ = (10 973 731.568 527 ± 0.000 073) m−1 .\\n3 An alternative way of writing the error is:\\nR∞ = 10 973 731.568 527 (73) m−1 , altho-\\n\\nugh we will exclusively use the ± convention\\nin this book.\\n\\n4 http://physics.nist.go', 'v/cuu/Constants/\\n\\nNote that although the Rydberg constant is known to an impressive precision\\n(one part in 1011 ) there is still an uncertainty in its value.3 The only constants\\nwhich do not have an error are those that have been deﬁned. One of the most\\ncommon is the speed of light in a vacuum, c = 299 792 458 m s−1 (exact).\\nA full list of the physical constants and their errors is reviewed periodically\\nby the International Council for Science: Committee on Data for Science\\nand Technology (CODATA) task group on fundamental constants. A selfconsistent set of internationally recommended values of the basic constants\\nand conversion factors is derived from all the relevant data available, and\\nis periodically updated. The latest review is available on the fundamental\\nconstants web-page hosted at NIST.4\\n\\n1.2\\n\\nFig. 1.1 The range of a ball-bearing\\nlaunched from a spring-loaded projectile\\nlauncher. (a) shows the location at which\\nthe projectile landed on carbon paper—the\\nrepetition of the experiment with nominally\\nthe same experimental conditions is seen to\\nyield different results. In (b) a histogram of\\nthe total radial range of the projectile from\\nthe launcher is constructed, with the number\\nof occurrences within a bin of width 10 cm\\nplotted.\\n\\nUncertainties in measurement\\n\\nHow should we interpret an uncertainty in a measurement? Reporting a\\nquantity as the best estimate ± the error should be regarded as a statement of probability. The scientists who performed the measurements and\\nanalysis are conﬁdent that the Avogadro constant is within the range\\n6.022 141 49 ×1023 mol−1 ≤ NA ≤ 6.022 142 09 ×1023 mol−1 . They cannot\\nbe certain that the Avogadro constant is within the limits quoted, but the\\nmeasurements lead them to believe that there is a certain probability of its\\nbeing so. In later chapters in this book we will use statistical analysis to deﬁne\\nthis range, and thereby its conﬁdence level, more quantitatively.\\nWhy do we need a statistical description of experiments perfor', 'med on\\nsystems which are usually described by a well-known set of equations,\\nand are hence deterministic? Figure 1.1 shows the results of an experiment\\nmeasuring the range of a ball-bearing launched from a spring-loaded projectile launcher. Successive measurements were taken of the distance the\\nball-bearing projectile landed with respect to the launching cannon. A histogram of the projectile distance is plotted in Fig. 1.1(b). The crucial point\\nto note is the following: although nominally these repeat measurements\\nare performed under exactly the same conditions, and Newton’s laws of\\nmotion, which govern the trajectory, are time independent, successive repeats\\nof the experiments gave different values for the range of the ball-bearing\\nprojectile.\\nThe histogram in Fig. 1.1(b) contains the information about the range of\\nthe projectile, and the uncertainty in this range. In this book we will discuss statistical techniques to analyse the location of the centre and width of\\nhistograms generated from multiple repeats of the same experiment. For this\\nexample these techniques enable a quantitative determination of the range and\\nits uncertainty.\\n\\n\\x0c1.2 Uncertainties in measurement 3\\n\\n1.2.1\\n\\nTerminology\\n\\nYou should note that despite many attempts to standardise the notation, the\\nwords ‘error’ and ‘uncertainty’ are often used interchangeably in this context—\\nthis is not ideal—but you have to get used to it! (A discussion of the International Standardisation Organisation’s Guide to the Expression of Uncertainty\\nin Measurement (GUM) is presented in Chapter 9.)\\nThere are two terms that have very different meanings when analysing\\nexperimental data. We need to distinguish between an accurate and a precise\\nmeasurement. A precise measurement is one where the spread of results is\\n‘small’, either relative to the average result or in absolute magnitude. An\\naccurate measurement is one in which the results of the experiment are in\\nagreement with the ‘accepted’ value. Note that the concept of', ' accuracy is only\\nvalid in experiments where comparison with a known value (from previous\\nmeasurements, or a theoretical calculation) is the goal—measuring the speed\\nof light, for example.\\nFigure 1.2 shows simulations of 100 measurements of a variable. The dashed\\nvertical line in the histogram shows the accepted value. The scatter of the data\\nis encapsulated in the width of the histogram. Figures 1.2(a) and (c) show\\nexamples of precise measurements as the histogram is relatively narrow. In\\nFig. 1.2(a) the centre of the histogram is close to the dashed line, hence we call\\nthis an accurate measurement. The histograms in Fig. 1.2 show the four possible combinations of precise and accurate measurements: Fig. 1.2(a) represents\\nan accurate and precise data set; Fig. 1.2(b) an accurate and imprecise data set;\\nFig. 1.2(c) an inaccurate but precise data set; and ﬁnally Fig. 1.2(d) both an\\ninaccurate and imprecise data set.\\nBased on the discussion of precision and accuracy, we can produce the\\nfollowing taxonomy of errors, each of which is discussed in detail below:\\n• random errors—these inﬂuence precision;\\n• systematic errors—these inﬂuence the accuracy of a result;\\n• mistakes—bad data points.\\n\\n1.2.2\\n\\nRandom errors\\n\\nMuch of experimental physics is concerned with reducing random errors.\\nThe signature of random errors in an experiment is that repeated measurements are scattered over a range, seen in Fig. 1.1. The smaller the random\\nuncertainty, the smaller the scattered range of the data, and hence the more\\nprecise the measurement becomes. The best estimate of the measured quantity\\nis the mean of the distributed data, and as we have indicated, the error is\\nassociated with the distribution of values around this mean. The distribution\\nthat describes the spread of the data is deﬁned by a statistical term known\\nas the standard deviation. We will describe these terms in greater detail in\\nChapters 2 and 3.\\nHaving quantiﬁed the uncertainty in a measurement, the good experimentalist wi', 'll also ask about the origin of the scatter of data. There are two\\ncategories of scatter in experiments: (1) technical, and (2) fundamental noise.\\n\\nFig. 1.2 Terminology used in error analysis. Simulations of 100 measurements are\\nshown in histograms of constant bin-width.\\nThe extent of the scatter of the data (the width\\nof the histogram) is a measure of the precision, and the position of the centre of the histogram relative to the dashed line represents\\nthe accuracy. The histograms show (a) precise and accurate, (b) imprecise and accurate,\\n(c) precise and inaccurate and (d) imprecise\\nand inaccurate sets of measurements.\\n\\n\\x0c4\\n\\nErrors in the physical sciences\\n\\n5 Named after J. B. Johnson, who ﬁrst stud-\\n\\nied the effect at Bell Laboratories; Thermal\\nagitation of electricity in conductors, Nature\\n(1927) 119, 50–51.\\n\\n6 Even for a constant-intensity light source,\\n\\nthe actual number, N , of photons detected in\\na given time will have a Poisson distribution\\nabout the (well-deﬁned) mean. We will show\\nin Chapter 3 that the photon noise is equal\\nto the square\\n√ root of the average number\\nof photons, N . The signal-to-noise ratio is\\n√\\nN\\nthen √ = N . When the number of phoN\\ntons collected is small the shot-noise limited\\nsignal-to-noise ratio can be the limiting feature of an experiment.\\n\\nA given apparatus will have a fundamental noise limit (governed by some law\\nof physics, e.g. diffraction) but will typically operate with a higher noise level\\n(technical noise) which could, in principle, be reduced. In Fig. 1.1 the source\\nof the scatter is technical in nature. The trajectories are subject to the deterministic Newton’s laws of motion. However, the parameters which categorise the\\ntrajectories can vary. Maybe the launcher recoils and changes the next launch\\nangle, or perhaps reloading the cannon with the same projectile might load the\\nspring to a different tension each time. It is possible to design experiments with\\nsufﬁcient care that the origin of the random errors approaches the fu', 'ndamental\\nnoise limit of the apparatus. The good experimentalist will take measures to\\nreduce the technical noise for a given apparatus; if the fundamental noise level\\nremains the limiting feature of the experiment a new apparatus or approach\\nis needed.\\nExamples of fundamental noise limits include Johnson and shot noise. Johnson noise5 arises in a resistor as a consequence of the thermal agitation of the\\ncharge carriers and becomes important in experiments measuring low voltages.\\nThe discrete nature of certain quantities gives rise to so-called shot noise—\\nwhen measuring feeble light beams the manifestation of the electromagnetic\\nﬁeld being composed of ﬁnite energy bundles, or photons, gives rise to random\\nﬂuctuation of the intensity.6\\nThere exist many statistical techniques for quantifying random errors, and\\nminimising their deleterious effect. These will be discussed at length in later\\nchapters. It should be emphasised that these techniques all rely on taking\\nrepeated measurements.\\n\\n1.2.3\\n\\nSystematic errors\\n\\nSystematic errors cause the measured quantity to be shifted away from the\\naccepted, or predicted, value. Measurements where this shift is small (relative\\nto the error) are described as accurate. For example, for the data from the\\nprojectile launcher shown in Fig. 1.1 the total range needs to be measured from\\nthe initial position of the ball-bearing within the launcher. Measuring from the\\nend of the cannon produces a systematic error. Systematic errors are reduced\\nby estimating their possible size by considering the apparatus being used and\\nobservational procedures.\\nIn Figs. 1.2(c) and (d) the measurements are scattered, but none of the individual measurements is consistent with the accepted value: the measurements\\nare consistently smaller than the predicted value. This is the tell-tale sign of at\\nleast one, and possibly more, systematic error(s). In contrast to random errors,\\nthere do not exist standard statistical techniques for quantifying systematic\\nerrors.', ' It is left to the experimenter to devise other sets of measurements which\\nmight provide some insight as to the origin of the systematic discrepancies.\\n\\n1.2.4\\n\\nMistakes\\n\\nAnother class of error which deﬁes mathematical analysis is a mistake. These\\nare similar in nature to systematic errors, and can be difﬁcult to detect. Writing\\n\\n\\x0c1.3 Precision of measurements\\n\\n2.34 instead of 2.43 in a lab book is a mistake, and if not immediately corrected\\nis very difﬁcult to compensate for later.\\nThere are other well-known types of mistakes which can inﬂuence the\\nprecision and accuracy of experimental results with potentially disastrous\\nconsequences. Misreading scales occurs often with an analogue device which\\nhas a 0–10 scale above the gradations, and a 0–3 scale underneath. Care has\\nto be taken when using a signal generator where an analogue dial from 1 to\\n10 is used in conjunction with multiplier knobs such as 1–10 kHz. With an\\ninstrument such as an oscilloscope one has to be careful to check whether a\\nmultiplier such as ×10 has been engaged. In Fig. 1.3 a histogram of events is\\nshown, where the automated data-collecting software misﬁred on 10% of the\\nevents. Malfunction of the apparatus can be difﬁcult to spot; the presence of\\nerroneous points can become apparent when the data are displayed graphically.\\nThere are many examples where confusion over units has had disastrous\\nconsequences. In 1999 the failure of the NASA Mars Climate Orbiter was\\nattributed to confusion about the value of forces: some computer codes used\\nSI units, whereas others used imperial. A Boeing 767 aircraft ran out of fuel\\nmid-ﬂight in 1983; a subsequent investigation indicated a misunderstanding\\nbetween metric and imperial units of volume.\\nObviously the good experimentalist makes very few, if any, such mistakes;\\ntheir effects will not be discussed further in this book.\\n\\n1.3\\n\\nFig. 1.3 A histogram of measurements when\\n10% of the events are logged incorrectly\\nby automated data-collecting software.\\nThe presenc', 'e of the erroneous points is\\nclearly visible when the data are displayed\\ngraphically.\\n\\nPrecision of measurements\\n\\nThere are certain measurements with no statistical scatter; repeating the experiment does not yield more useful information. If six successive measurements\\nof the amount of acid titrated are 25.0, 25.0, 25.0, 25.0, 25.0 and 25.0 cm3 it\\nis obviously a waste of time to perform another similar measurement. In this\\ncase the precision of the measurement is limited by the ﬁnite resolution of the\\nscale on the titration apparatus. How do we estimate the precision of the device\\nin this case? We discuss the two types of measuring instrument (analogue and\\ndigital) below.\\nIt should be stressed that estimating the uncertainty based on some property\\nof the measuring device is only valid if successive measurements are identical.\\nThe spread of the ranges in Fig. 1.1 is signiﬁcantly greater than the precision\\nof the measuring device, hence the statistical techniques introduced in the next\\nchapter must be used to calculate the uncertainty in that case.\\n\\n1.3.1\\n\\n5\\n\\nRULE OF THUMB: The precision of a\\nmeasurement only equals the precision of the\\nmeasuring device when all repeated measurements are identical.\\n\\nPrecision of an analogue device\\n\\nImagine that you are measuring the length of a piece of A4 paper with a\\nruler with 1 mm gradations. Successive measurements all give 297 mm. It\\nseems reasonable to estimate the precision in this case to be half a division,\\ni.e. ± 0.5 mm, and thus we would report the length of the piece of paper as\\n297.0 ± 0.5 mm.\\nIt is also worth considering cases where this rule of thumb is too pessimistic.\\nImagine that the measurements of the length of the A4 paper were performed\\n\\nRULE OF THUMB: The highest precision\\nachievable with an analogue device such as a\\nruler is half a division.\\n\\n\\x0c6\\n\\nErrors in the physical sciences\\n\\n30\\n\\n40\\n\\n50\\n\\n60\\n\\n70\\n\\n20\\n\\n80\\n90\\n\\n10\\n0\\n\\n100\\n\\n30\\n20\\n10\\n0\\n\\n40\\n\\n50\\n\\n60\\n\\nwith a ruler which only had 1 cm gradations. All measurements of th', 'e length\\nwould lie between 29 and 30 cm; in this instance estimating the uncertainty to\\nbe half a division, or ±0.5 cm, is a gross overestimate. A good experimentalist\\nwill be able to interpolate, i.e. estimate the position with a ﬁner resolution\\nthan the gradations. There is no simple rule as to what value to report for\\nthe precision in this case; indeed, the error estimation can only be done by\\nthe experimenter, and is likely to vary for different experimenters. Figure 1.4\\nillustrates the issues associated with the precision of an analogue device.\\n\\n70\\n80\\n\\n1.3.2\\n\\n90\\n100\\n\\nFig. 1.4 The upper part of the ﬁgure displays\\na situation where estimating the uncertainty\\nto be half a division is appropriate; in contrast\\nin the lower part of the ﬁgure the uncertainty\\nin the measurement is substantially smaller\\nthan half a division.\\n\\nRULE OF THUMB: The precision of a digital meter is limited to the last decimal point;\\ni.e. one in the last digit.\\n\\nRepeat measurements of the voltage of a battery with a digital multimeter each\\nyields 8.41 V. What is the uncertainty?\\nSome digital instruments come with manufacturer’s speciﬁcations for the\\nuncertainty, such as ‘half the last digit’—the equivalent result to the analogue\\ncase. Therefore one could write 8.410 ± 0.005 V. Note the extra zero which\\nappears at the end of the reported number which is not present in the actual\\nreading. There is a signiﬁcant assumption implicit in this estimate, namely that\\nthe digital instrument does an appropriate rounding, i.e. it does not truncate the\\nnumber. If the former occurs then 8.419 would appear as 8.42, whereas if it is\\nthe latter, 8.419 would appear as 8.41. Ascertaining whether the meter rounds\\nor truncates can be difﬁcult, therefore the conservative estimate is to use the\\nfull last digit, i.e. we would report 8.41 ± 0.01 V for the example above to be\\non the safe side.\\n\\n1.4\\n\\nRULE OF THUMB: Ensure apparatus is\\nproperly calibrated and zeroed.\\n\\nPrecision of a digital device\\n\\nAccuracy of measurement', 's\\n\\nThe accuracy of an experiment is determined by systematic errors. For an\\ninaccurate set of measurements there will be a difference between the measured and accepted values, as in Figs. 1.2(c) and (d). What is the origin\\nof this discrepancy? Answering this question, on the whole, is difﬁcult and\\nrequires insight into the experimental apparatus and underlying theories. For\\nthe example of the projectile launcher, the range is a function of both the launch\\nangle and muzzle speed. Experimental factors which could affect the accuracy\\ninclude the setting of the launch angle or the reliance on the manufacturer’s\\nspeciﬁcation of the muzzle speed. The theoretical prediction, for this example,\\nis based on a calculation which ignores air resistance—the validity of this\\nassumption could be questioned.\\nThree of the more common sources of systematic error are zero, calibration\\nand insertion errors. An example of a zero error is using a ruler to measure\\nlength if the end of the ruler has been worn away. A metal ruler calibrated\\nat 20 ◦ C will systematically yield measurements which are too large if used\\nat 10 ◦ C owing to the thermal contraction of the gradations; this is a calibration error. Examples of insertion errors include: placing a room-temperature\\nthermometer in a hot ﬂuid, which will change the temperature of the ﬂuid;\\nthe current in an electrical circuit being changed by placing a meter across a\\ncomponent.\\n\\n\\x0c1.4 Accuracy of measurements 7\\n\\nChapter summary\\n• An experiment is not complete until an appropriate error analysis has\\nbeen conducted.\\n• When successive measurements of the same quantity are repeated there\\nis usually a distribution of values obtained.\\n• A crucial part of any experiment is to measure and quantify the uncertainties in measurement.\\n• An accurate measurement agrees with the expected value.\\n• A precise measurement has a small relative uncertainty.\\n• The signature of the presence of random errors is that repeat measurements of the same quantity produce', ' different results.\\n• The statistical spread of a data set is a reﬂection of the precision of the\\nmeasurement.\\n• The deviation of the centre of the histogram from the accepted value is\\na reﬂection of the accuracy of the measurement.\\n• Systematic errors inﬂuence the accuracy of a measurement.\\n• The precision of an analogue device is half a division.\\n• The precision of a digital device is one in the last digit.\\n• The precision of a measurement is only equal to the precision of the\\nmeasuring device if repeat measurements are identical.\\n• Ensure apparatus is properly calibrated and zeroed.\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cRandom errors in\\nmeasurements\\nIn Section 1.2 we discussed how random errors are a feature of experiments\\nin the physical sciences. In the absence of systematic errors there is a spread\\nof measurements about the accepted value owing to random errors. We have\\nseen in Chapter 1 that when successive measurements of the same quantity are\\nrepeated there is a distribution of values. A reading taken at a given time will\\ndiffer from one taken subsequently. In Section 1.2 we discussed some of the\\npossible causes for these ﬂuctuations. In this chapter we take it as given that\\nthere are random errors in repeated measurements, and discuss techniques of\\nhow to analyse a set of measurements, concentrating in particular on how to\\nextract objective numbers for two vital properties of a distribution: (i) our best\\nestimate of the quantity being measured, and (ii) our estimate of the uncertainty\\nin the value to report. We employ statistical techniques for the analysis to\\nreﬂect the fact that the distribution of measurements is a consequence of\\nstatistical ﬂuctuations inherent in collecting a ﬁnite number of data points; we\\nimplicitly assume that there are no systematic errors.\\n\\n2.1\\n\\nAnalysing distributions: some\\nstatistical ideas\\n\\nIn Fig. 2.1 we plot histograms of the occurrence of a particular value of a\\nmeasured quantity, x. Four histograms are shown where the num', 'ber of data\\npoints collected, N , increases from (a) 5, to (b) 50, to (c) 100, to (d) 1000. It is\\napparent that as the number of data points increases, the distribution becomes\\nsmoother, but that the width remains unchanged. A smoother histogram will\\nfacilitate a more precise estimate of the three quantities which are of most\\ninterest to us: the centre, the width and the uncertainty in the location of\\nthe centre. We discuss methods for ascertaining the value of each of these\\nquantities in the following sections.\\n\\n2.2\\n\\nThe mean\\n\\nThe best method for reducing the effects of random errors on a measurement\\nis to repeat the measurement, and take an average. Consider N measurements,\\nx1 , x2 , . . . , x N . The ﬂuctuations responsible for the spread of readings are\\n\\n2\\n2.1 Analysing distributions: some\\nstatistical ideas\\n\\n9\\n\\n2.2 The mean\\n\\n9\\n\\n2.3 The width of the distribution:\\nestimating the precision\\n\\n10\\n\\n2.4 Continuous distributions\\n\\n12\\n\\n2.5 The normal distribution\\n\\n13\\n\\n2.6 Sample and parent distribution\\n\\n13\\n\\n2.7 The standard error\\n\\n14\\n\\n2.8 Reporting results\\n\\n17\\n\\n2.9 The ﬁve golden rules\\n\\n19\\n\\nChapter summary\\n\\n19\\n20\\n\\nExercises\\n\\n\\x0c10\\n\\nRandom errors in measurements\\n\\nrandom, consequently they are equally likely to be higher as lower than the\\naccepted value. The arithmetic mean is a way of dividing any random errors\\namong all the readings. We therefore adopt the mean, x̄, as our best estimate\\nof the quantity x.\\nx̄ =\\n\\nN\\n1 \\x05\\n1\\nxi .\\n(x1 + x2 + · · · + x N ) =\\nN\\nN\\n\\n(2.1)\\n\\ni=1\\n\\nHowever, as is evident from Fig. 2.1, quoting the mean does not yield all the\\ninformation that is inherent in a set of repeat measurements.\\n\\n2.3\\n\\nThe width of the distribution: estimating\\nthe precision\\n\\nThe precision of the N measurements can be estimated from the distribution of\\nthe scattered data. The more similar the readings, the smaller the width of the\\ndistribution, and the more precise the measurement. (This was the situation\\ndepicted in Fig. 1.2a and b.) We can therefore quantify this precision by\\nlookin', 'g in detail at the width of this distribution.\\n\\n2.3.1\\n\\nRough-and-ready approach to estimating the width\\n\\nSuppose we had timed the period of oscillation, T , of a pendulum 10 times and\\nobtained the values listed in Table 2.1.\\nTable 2.1 Ten measurements of the period of oscillation, T , of a pendulum. The\\nprecision of the measuring device is 0.1 s.\\nTrial\\nPeriod/s\\n\\nFig. 2.1 Histograms of different experimental runs with (a) 5, (b) 50, (c) 100 and (d)\\n1000 data points. The histograms become\\nsmoother as more data points are collected,\\nmaking it easier to deduce the centre, the\\nwidth and the uncertainty in the location of\\nthe centre.\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n10.0\\n\\n9.4\\n\\n9.8\\n\\n9.6\\n\\n10.5\\n\\n9.8\\n\\n10.3\\n\\n10.2\\n\\n10.4\\n\\n9.3\\n\\nAll data points lie within the interval 9.3 ≤ T ≤ 10.5 s which covers a\\nrange of 1.2 s, or a spread around the mean (T̄ = 9.9 s) of about ±0.6 s.\\nEvaluating the maximum spread of the data is one rough-and-ready approach\\nto estimating the precision of the measurement. It is somewhat pessimistic,\\nbecause as we will see later, we generally take the precision in a measurement to be two-thirds of the maximum spread of values, and therefore the\\nspread of the data in Table 2.1 is approximately ±0.4 s. The factor of twothirds is justiﬁed for a Gaussian distribution, discussed in Chapter 3. Note\\nthat the spread of the measurements is signiﬁcantly worse than the precision of the measuring instrument—this is why taking repeat measurements is\\nimportant.\\nWe can therefore say that:\\n• a typical measurement of the period is likely to be within 0.4 seconds of\\nthe mean value;\\n• the precision of the measurements is 0.4 seconds.\\n\\n\\x0c2.3 The width of the distribution 11\\n\\nIn many cases this simple procedure (illustrated in Fig. 2.2a) provides a\\nfast method for estimating the precision, and is adequate in estimating the\\nspread of the data around the mean. It is particularly appropriate when the\\nnumber of data points is low, N ≤ 10. The method is summarised in the box\\nbelow:\\nRough-a', 'nd-ready approach to estimating the width\\n• Calculate the mean of the data set, x̄.\\n• Calculate the maximum spread of the data around the mean: either\\ndmax = xmax − x̄, or dmax = x̄ − xmin , whichever is greater.\\n• Quote the standard deviation as two-thirds of the maximum deviation:\\nσ = 2/3 × dmax .\\n\\n2.3.2\\n\\nStatistical approach to estimating the width\\n\\nAs more data points are recorded there is an increasing probability that the\\ndistribution describing the spread will have extended wings. Calculating the\\nspread of data from the maximum deviation can give a misleading estimation\\n(illustrated in Fig. 2.2b). To avoid this problem we need a measure of the\\nrandom uncertainty that depends on all the measurements, and not just the\\nextreme values as in the method above. The statistical quantity that is widely\\nused is the standard deviation.\\nWe deﬁne the deviation from the mean of the i th data point as:\\ndi = xi − x̄.\\n\\n(2.2)\\n\\nThe deviation di is equally likely to be positive as negative, and therefore when\\nsummed over a data set will be zero. Returning to the distributions of the period\\nof oscillation from Table 2.1, Table 2.2 shows the 10 measurements and their\\ndeviation from the mean.\\n\\x06\\nThe average deviation, d̄ = (1/N ) i di , is zero and therefore cannot be\\nused as a measure of the spread of the data. Note that in Table 2.2 the average\\nof the squared deviation is not zero. This motivates the introduction of the\\nsample variance, which is the square of the standard deviation, σ , as the sum\\nof the squares of these deviations over the data set. The standard deviation is\\nTable 2.2 Ten measurements of the period of oscillation, T , of a pendulum. The\\nsum of the deviations \\x06i di = 0, and the sum of the squares of the deviations\\n\\x06i di2 = 1.58 s2 .\\nPeriod, T (s)\\nDeviation, d(s)\\nSquared deviation, d 2 (s2 )\\n\\n10.0\\n0.07\\n0.0049\\n\\n9.4\\n−0.53\\n0.2809\\n\\n9.8\\n−0.13\\n0.0169\\n\\n9.6\\n−0.33\\n0.1089\\n\\n10.5\\n0.57\\n0.3249\\n\\nPeriod, T (s)\\nDeviation, d(s)\\nSquared deviation, d 2 (s2 )\\n\\n9.8\\n−0.13\\n0.0169\\n\\n10.3\\n0.', '37\\n0.1369\\n\\n10.2\\n0.27\\n0.0729\\n\\n10.4\\n0.47\\n0.2209\\n\\n9.3\\n−0.63\\n0.3969\\n\\nFig. 2.2 Histograms of 10 experimental measurements of the variable x. In (a) the maximum deviation dmax is positive, and the\\nwidth of the distribution, σ , is also indicated.\\nFor (b) the point furthest from the mean has a\\nnegative deviation, and the width is taken as\\ntwo-thirds of the modulus of this deviation. In\\n(b) the estimate of the precision is dominated\\nby one deviant point.\\n\\n\\x0c12\\n\\nRandom errors in measurements\\n\\nthus deﬁned:\\n\\x07\\x03\\nσ N −1 =\\n\\n\\x04\\nd12 + d22 + · · · + d N2\\n=\\nN −1\\n\\n\\x08\\n\\n1 \\x05 2\\ndi .\\nN −1\\nN\\n\\n(2.3)\\n\\ni=1\\n\\nThe distribution is normalised to (N − 1) as opposed to N (as was the case for\\nthe mean) because the data have already been used once to ﬁnd the mean and\\nthere are thus only (N − 1) independent values of the deviations with which\\nto deﬁne the variance (see Chapter 8).\\nThe standard deviation is thus a statistical measure, based on all of the\\navailable data, of the width of the distribution and hence will be a more\\nreliable estimation of the precision. When we take a series of measurements,\\nwe obtain a mean value, x̄, as our best estimate from that set of measurements,\\nwith a standard deviation σ . If we were to make one more measurement, we\\nbelieve there is a two-thirds chance that the new measurement will lie in the\\ninterval x̄ − σ ≤ x ≤ x̄ + σ . As we increase our sample size and reﬁne our\\nestimates for the mean and standard deviation this becomes a more robust\\nbelief.\\nFor the data set given in Table\\nfor the period of the pendulum we\\n\\x06 2.1\\nd2\\n2\\n, which numerically, from Table 2.2,\\ncalculate the variance σ N −1 =\\nN −1\\n1.58\\n= 0.176 s2 . Thus using eqn (2.3) the standard deviation is\\nis σ N2 −1 =\\n9\\nσ N −1 = 0.42 s, similar to the value obtained using the rough-and-ready\\napproach.\\n\\n2.4\\n\\nFig. 2.3 Histograms of 10 000 samples with\\nmean 10 and standard deviation 1. The binwidth is (a) 1.6, (b) 0.8, (c) 0.4 and (d)\\n0.2. The histograms become smoother as\\nthe bin-width decreases, tending toward a\\nsmooth', ' distribution. Each histogram also has\\na normal-distribution curve superimposed.\\nThe agreement between the discrete and continuous functions improves as the bin-width\\nis reduced.\\n\\nContinuous distributions\\n\\nA measurement of a physical quantity will necessarily be discrete, with the\\nsmallest division being limited by the gradations of the instrument (see Chapter 1). It is instructive to consider how the forms of the histograms of Fig. 2.1\\nwould evolve as a function of (i) the sample size (number of data points\\ncollected), and (ii) the width of the bin used to construct the histogram. The histogram becomes smoother as more data are collected, as seen in the evolution\\nfrom (a) to (d) in Fig. 2.1. Two (conﬂicting) factors inﬂuence the choice of binwidth; (i) there should be sufﬁcient occurrences per bin (guaranteed by a wide\\nbin-width), and (ii) there should be enough bins contributing to the histogram\\n(guaranteed by a narrow bin-width). Figure 2.3 shows a histogram for 10 000\\nsamples drawn from a normal distribution with mean 10 and standard deviation\\n1, constructed using different bin-widths. The distribution obviously becomes\\nsmoother as the bin-width is reduced. This trend will continue until the number\\nof occurrences per bin is not statistically signiﬁcant. It is useful to think of the\\nlimit where the bin-width tends to zero; the envelope of the histogram becomes\\na function which can be evaluated at any value of x. A continuous envelope is\\nplotted for each discrete histogram in Fig. 2.3. It becomes convenient to think\\nof a curve, or continuous distribution function, associated with the hypothetical\\nlimit of the number of data points collected, N , tending to inﬁnity.\\n\\n\\x0c2.6 Sample and parent distribution 13\\n\\n2.5\\n\\nThe normal distribution\\n\\nThe form of the continuous curve which is the envelope of the histogram\\nof Fig. 2.3 has a characteristic and familiar shape. For measurements with\\nrandom errors the distribution is called the normal, or Gaussian, distribution.1\\nMathe', 'matically, it is a two-parameter function:2\\n1\\n(x − x̄)2\\nexp −\\nf (x) = √\\n,\\n2σ 2\\nσ 2π\\n\\n‘bell curve’.\\n2 The prefactor\\n\\n(2.4)\\n\\n√1\\nin the expression for\\nσ 2π\\n\\nf (x) ensures that the function is normalised:\\n∞\\n\\nwhich describes the distribution of the data about the mean, x̄, with standard deviation, σ . Figure 2.4 shows the functional form of three normalised\\nGaussian distributions, each with a mean of 10 and with standard deviations\\nof 1, 2 and 3, respectively. Each curve has its peak centred on the mean, is\\nsymmetric about this value and has an area under the curves equal to 1. The\\nlarger the standard deviation, the broader the distribution, and correspondingly\\nlower the peak value.3\\nWhy is it called the normal distribution? Mathematical analysis shows that\\nthe Gaussian distribution arises as the envelope of the histogram obtained\\nwhen a quantity being measured is subject to small, independent ‘kicks’\\n(or perturbations) of varying sign which contribute additively. Typically the\\nunderlying mechanisms of the perturbations are unknown. As the conditions\\nwhich predict a Gaussian distribution occur often in nature, many distribution\\nfunctions of natural phenomena are found to be well described by the normal\\ndistribution. We will see in Chapter 3 that the distribution of the means from a\\nset of measurements evolves to a Gaussian shape under certain conditions.\\n\\n2.6\\n\\n1 This distribution is also referred to as the\\n\\ni.e.\\n\\n−∞\\n\\nf (x) dx = 1.\\n\\n3 There are many possible deﬁnitions of the\\n\\n‘width’ of a Gaussian distribution, including\\nFull Width at Half Maximum (FWHM), the\\n(1/e) width, the (1/e2 ) width. There are different conventions in different disciplines as to\\nwhich to adopt; each version is proportional\\nto the standard deviation, σ , and we will use\\nthat throughout this book.\\n\\nSample and parent distribution\\n\\nWhen discussing distributions of experimental measurements it is important\\nto distinguish between the sample and parent distributions. In the theory of\\nstatistics, the pare', 'nt distribution refers to the number of possible measured\\nvalues, ξi ; the parent population might consist of an inﬁnite number of values.\\nTwo independent parameters, the mean, μ, and a standard deviation, σparent ,\\ncharacterise the parent distribution, and are related thus:\\n\\x07\\x06\\n(ξi − μ)2\\n.\\n(2.5)\\nσparent =\\nNparent\\nAs the mean and standard deviation are independently determined σparent is\\ndeﬁned with N in the denominator. In practice when we take a series of\\nmeasurements in an experiment, xi , we take a selection, or sample, from this\\nparent distribution which results in a distribution called the sample distribution.\\nThis distribution is centred on the mean of the data set, x̄, and has a standard\\ndeviation:\\n\\x07\\n\\x06\\n(xi − x̄)2\\n.\\n(2.6)\\nσsample =\\nN −1\\n\\nFig. 2.4 Normalised Gaussian distributions\\nwith a mean of 10 and standard deviations of\\n1, 2 and 3.\\n\\n\\x0c14\\n\\nRandom errors in measurements\\n\\n∗ The concept of the degrees of freedom is\\ndiscussed in more detail in Section 8.2.\\n\\nTable 2.3 The evolution of the mean\\nand standard deviation of a sample distribution with sample size,\\nN . The parent distribution was randomly generated from a Gaussian\\ndistribution with mean μ = 10, and\\nstandard deviation σparent = 1.\\nN\\n5\\n10\\n50\\n100\\n1000\\n\\nx̄\\n\\nσsample\\n\\n9.8\\n9.5\\n10.1\\n10.0\\n10.07\\n\\n0.9\\n0.7\\n0.9\\n0.9\\n0.99\\n\\nThe (N − 1) is required in the denominator in the sample distribution because\\nthe mean, x̄, is also determined from the same data set and is thus no longer\\nindependently determined and the number of degrees of freedom is one fewer.∗\\nThe goal is to make use of this sample distribution to estimate the mean\\nand standard deviation of the parent distribution. When we conduct an\\nexperiment we discretely sample the parent distribution. In the limit that\\nN → ∞ the parent and sample distributions are the same and x̄ = μ and\\nσsample = σparent .\\nIf we take a single measurement we sample the parent distribution once. The\\nmost probable value of x that we would measure is the mean (see Chapter 3)\\nand we therefore', ' implicitly assume that x1 = μ. When we take multiple readings, however, we build up a set of values and populate the sample distribution.\\nAs we repeatedly sample the parent distribution we slowly build up a distrib1 \\x05\\nxi ,\\nution of values centred on the mean of the sample distribution, x̄ =\\nN\\nwhich becomes an increasingly better approximation of μ as N increases.\\nAs all the measurements sample the same parent distribution they are all\\ndetermined with the same precision as the parent distribution, σsample ≈ σparent .\\nAs more data are recorded the standard deviation of the data does not change,\\nit simply becomes better deﬁned. The evolution of the mean and standard\\ndeviation of the data shown in Fig. 2.1 is encapsulated in Table 2.3. It is clear\\nfrom a visual inspection of both Fig. 2.1 and Table 2.3 that as N gets larger the\\nmean becomes better deﬁned, but the standard deviation hardly changes.\\nA key concept which we have not discussed so far is the uncertainty in the\\nestimation of the mean. We see that as the number of data points increases the\\nhistograms become smoother, but the standard deviation does not reduce: thus\\nthe standard deviation of the sample is not a good measure of the error in the\\nestimation of the mean of the parent population. We can clearly determine the\\nposition of the mean to a better precision than the standard deviation of the\\nsample population. The important concept here is that of signal-to-noise: the\\nprecision with which we can determine the mean depends on the number of\\nsamples of the parent distribution.\\n\\n2.7\\n\\nThe standard error\\n\\nSo far we have introduced two important properties of a sequence of repeat\\nmeasurements where there is scatter owing to random errors, namely the\\nmean and standard deviation. We now introduce another crucial parameter,\\nthe uncertainty in the location of the mean.\\nFigure 2.5 shows histograms of a simulation where 2500 points are chosen\\nfrom a normal parent distribution with mean μ = 10 and standard deviation\\nσpa', 'rent = 1. In part (a) the histogram of the measurements is normal, centred\\nas expected on 10, and has a standard deviation of σsample = 1. The upper part\\nof the panel shows that most measurements are within two standard deviations\\nof the mean of the parent distribution, with very few points with a deviation\\nlarger in magnitude than two standard deviations. For part (b) the same data\\nset was partitioned differently. The mean of every ﬁve points was calculated,\\n\\n\\x0cFig. 2.5 Histograms of 2500 data points chosen from a normal parent distribution with mean μ = 10 and standard deviation σparent = 1. In (a)\\nthe raw data are plotted, in (b) a mean of every ﬁve data points was calculated, and these 500 means and their distribution are plotted. In (c) 10\\npoints were used to calculate 250 means, and in (d) 50 points were averaged to generate 50 means. Averaging over more points greatly reduces\\nthe statistical ﬂuctuations, and reduces the width of the histograms. Each histogram has the same bin-width. The mean, x̄, and standard deviation,\\nσsample , are (a)10.0, 1.0, (b) 10.0, 0.5, (c) 10.0, 0.3 and (d) 10.00, 0.14.\\n\\n\\x0c16\\n\\nRandom errors in measurements\\n\\n4 This is a special case of the weighted\\n\\nmean—see Chapter 4.\\n\\nyielding 500 mean values; the histogram shows the distribution of these means.\\nIt is evident from the width of the histogram that the distribution of these 500\\nmeans is signiﬁcantly narrower than the distribution of the unaveraged data.\\nAveraging ﬁve data points greatly reduces the statistical ﬂuctuations in the\\ndistribution of the means. This trend continues in part (c) where the data set\\nwas partitioned into 250 measurements of means of 10 points, and in part (d)\\nwhere 50 measurements of means obtained from 50 data points are plotted.\\nThe width of the histogram of means is a measure of the precision of the\\nmean. It is clearly evident from Fig. 2.5 that the width of the histogram of\\nthe means decreases as the size of the sample used to calculate the mean\\nincreases—this', ' is a consequence of averaging over statistical ﬂuctuations. The\\nwidth of the histogram of means is the standard deviation of the mean, also\\nknown as the standard error, α. When the number of measurements involved\\nin calculating the mean increases, the means are better deﬁned; consequently\\nthe histograms of the distributions of the means are narrower. Note that the\\nprecision with which the mean can be determined is related to the number of\\nmeasurements used to calculate the mean. In practice one does not generate\\nhistograms of the means based on trials containing many measurements;\\nrather one uses all N measurements xi to calculate one value for the mean\\nx̄. We expect the standard error (the standard deviation of the mean), α, to\\ndecrease as the number of data points we collect, N , increases. In Chapter 4\\nwe discuss ways of combining measurements of the √\\nsame quantity, and we\\nshow4 that the standard error is reduced by a factor of N with respect to the\\nsample standard deviation:\\nσ N −1\\nα= √ .\\nN\\n\\n5 The reduction of the standard error by a\\n√\\n\\nfactor of N with respect to the standard\\ndeviation of the measurements will reappear\\nin the discussion of the central limit theorem\\nin Chapter 3.\\n\\n6 We keep two signiﬁcant ﬁgures to illustrate\\n\\nthe argument here, although with so few data\\npoints we would generally only quote the\\nstandard deviation to one signiﬁcant ﬁgure.\\n\\n(2.7)\\n\\nA data set containing N multiple readings yields one value of the mean.\\nThus we should quote our ﬁndings as the mean ± the error on the mean, i.e.\\nσ N −1\\nx̄ ± α = x̄ ± √ . In other words, we are saying that there is a two-thirds\\nN\\nchance that the measured parameter is within the range x̄ − α ≤ x ≤ x̄ + α.\\nOne can interpret the standard error as being a standard deviation, not of the\\nmeasurements, but rather the mean: this is why the standard error is also called\\nthe standard deviation of the mean (SDOM).5\\nThe reduction of the standard deviation of the mean with respect to the\\nstandard deviation of the ', 'parent population is inherent in Fig. 2.5. The\\nstandard deviation of the mean based on using ﬁve measurements to calculate\\nthe mean is α = 0.47, when based on 10 the standard deviation of means is\\nα = 0.30, and, ﬁnally, when based on 50 the standard deviation of means\\nis α = 0.14. From eqn (2.7) we would expect the error in the mean to be\\nσparent\\n= 0.45, 0.32, 0.14, in excellent agreement with our ﬁndings.6\\nσx̄ = √\\nN\\n\\n2.7.1\\n\\nThe error in the error\\n\\nThere is one last statistical quantity which we must consider before we unveil\\nthe procedure for how to report the best value, and its uncertainty, for a\\n\\n\\x0c2.8 Reporting results 17\\n\\nsequence of repeat measurements. Given that the precision with which we\\nknow the mean varies with the number of measurements, we need to ensure\\nthat we present the results in a systematic manner which reﬂects our conﬁdence\\nin the error: i.e. we need to quantify the error in the error.\\nThere exists a formula for the fractional error in the error (Squires 2001,\\nAppendix B); it is deﬁned as\\n1\\nerror in the error = √\\n,\\n2N − 2\\n\\n(2.8)\\n\\nand plotted in Fig. 2.6. It should be noted that the error on the error is a\\nslowly decreasing function with respect to N . For example, with only ﬁve\\nmeasurements the error estimate is only good to 1 part in 3 (35%). As the\\nsample size increases, the error in the error decreases, and we can be more\\nconﬁdent in our results, allowing for more signiﬁcant ﬁgures to be quoted. Note\\nthat the error in the error does not fall to a few percent (allowing two signiﬁcant\\nﬁgures to be quoted meaningfully) until approximately 10 000 data points\\nhave been collected (see Exercise 2.4). Conversely, care should be taken when\\nchoosing the number of appropriate signiﬁcant ﬁgures if the ﬁrst signiﬁcant\\nﬁgure of the error is 1—rounding an error of 1.4 to 1, or 1.51 to 2 causes\\na change in the error of approximately 25%. The following rule is generally\\nadopted:7\\n\\nFig. 2.6 The fractional error in the error is\\nplotted as a function of the num', 'ber of measurements, N . Note the logarithmic scale for\\nthe abscissa. For ﬁve measurements the fractional uncertainty in the error is 35%; 50\\nmeasurements are needed for the error to be\\nknown to 10%, and 5000 measurements to\\nachieve a 1% fractional uncertainty.\\n7 Corollary (i) If you have collected approxi-\\n\\nmately 10 000 data points, or more, consider\\nquoting the error to two signiﬁcant ﬁgures;\\n(ii) if the ﬁrst signiﬁcant ﬁgure of the error\\nis 1, consider quoting the second signiﬁcant\\nﬁgure.\\n\\nQuote the error to one signiﬁcant ﬁgure.\\nNote that it is extremely rare to quote errors to three signiﬁcant ﬁgures or\\nhigher.8 As we saw in Section 1.1, even the currently accepted values for the\\nfundamental constants have their errors quoted only to two signiﬁcant ﬁgures.\\nNote also that there is no rule about how many signiﬁcant ﬁgures are included\\nin the mean—this is ascertained after the error (and its error) are evaluated.\\nThe value of the acceleration due to gravity deduced in the worked example\\nafter 7 500 measurements has an error known to two signiﬁcant ﬁgures, and\\na mean known to four signiﬁcant ﬁgures, whereas Avogadro’s number has an\\nerror known to two signiﬁcant ﬁgures, and a mean known to nine signiﬁcant\\nﬁgures (see Section 1.1).\\n\\n2.8\\n\\nReporting results\\n\\nFrom the preceding section, we can formulate the following procedures to be\\nconsidered when we quote our results:\\n(1) Analyse the experimental data and calculate the mean; keep all signiﬁcant ﬁgures at this stage.\\n(2) Calculate the standard error (the error in the mean); keep all signiﬁcant\\nﬁgures at this stage.\\n(3) Think about how many signiﬁcant ﬁgures should be retained for the\\nerror having reﬂected on the number of data points collected.\\n(4) Round the mean to the appropriate decimal place.\\n\\n8 Worked example Analysis of repeat mea-\\n\\nsurements of the acceleration due to gravity, g, yields ḡ = 9.812 3456 m s−2 , with\\nα = 0.032 1987 m s−2 .\\n• If this answer was based on 10\\nmeasurements, you would report\\ng = (9.81', ' ± 0.03) m s−2 ;\\n• if this answer was based on 7 500 measurements, you would consider reporting g = (9.812 ± 0.032) m s−2 .\\nIf another measurement technique has\\nresults which are ḡ = 9.817 654 m s−2 and\\nα = 0.101 23 m s−2 , then\\n• If this answer was based on 10\\nmeasurements, you would report\\ng = (9.8 ± 0.1) m s−2 ;\\n• if this answer was based on 500 measurements, you would consider reporting g = (9.82 ± 0.10) m s−2 .\\n\\n\\x0c18\\n\\nRandom errors in measurements\\n\\nReturning to the data of Table 2.1, the mean is T̄ = 9.9 s, standard deviation\\nσ N −1\\nσ N −1 = 0.42 s, and standard error α = √\\n= 0.13 s. As the analysis is\\nN\\nbased on so few data points only the ﬁrst signiﬁcant ﬁgure of the error is\\nretained; the result is reported as T = (9.9 ± 0.1) s.\\n\\n2.8.1\\nRULE OF THUMB: If an error is not quoted\\nassume that the uncertainty is in the last\\nreported digit.\\n\\nRounding and signiﬁcant ﬁgures\\n\\nThe theme of this chapter has been that all measurements are subject to\\nuncertainty. A working rule is that, in the absence of an error being quoted,\\nwe assume that a number has signiﬁcance equal to a single unit in the last\\nﬁgure quoted. Thus if we were to say that the resistance of a resistor was 97 ,\\nit is said to have an absolute uncertainty of 1 ; a resistor with a value of\\n100.04 indicates an absolute uncertainty of 0.01 . The former value is said\\nto be known to two signiﬁcant ﬁgures, the latter to ﬁve. Confusion can occur\\nin ascertaining how many signiﬁcant ﬁgures a number has when zeroes are\\ninvolved.\\nRules for identifying signiﬁcant digits\\n• All non-zero digits are signiﬁcant:\\n2.998 × 108 m s−1 has four signiﬁcant ﬁgures.\\n• All zeroes between non-zero digits are signiﬁcant:\\n6.022 141 79×1023 mol−1 has nine signiﬁcant ﬁgures.\\n• Zeroes to the left of the ﬁrst non-zero digits are not signiﬁcant: 0.51 MeV\\nhas two signiﬁcant ﬁgures.\\n• Zeroes at the end of a number to the right of the decimal point are\\nsigniﬁcant: 1.60×10−19 C has three signiﬁcant ﬁgures.\\n• If a number ends in zeroes without a', ' decimal point, the zeroes might be\\nsigniﬁcant: 270 might have two or three signiﬁcant ﬁgures.\\n\\nRULE OF THUMB: To avoid confusion\\nwhen numbers end in zeros, report your values using scientiﬁc notation.\\n\\nThe ambiguity in the last rule can be resolved by the use of so-called scientiﬁc notation. For example, depending on whether two or three signiﬁcant\\nﬁgures is appropriate, we could write 270 as 0.27 k , or 2.7×102 , both of\\nwhich have two signiﬁcant ﬁgures; or 0.270 k , or 2.70×102 , both of which\\nhave three signiﬁcant ﬁgures. Note that the entries 0.3 k and 300 in a lab\\nbook carry very different signiﬁcance.\\nSigniﬁcant ﬁgures must also be considered when carrying out calculations.\\nIt is important to carry all digits through to the ﬁnal result before rounding to\\navoid rounding errors which compromise the accuracy of the ﬁnal result. The\\nprinciple is the following:\\nThe precision of a calculated result is limited by the least precise measurement in the calculation.\\n\\nRules for rounding to the appropriate number of signiﬁcant ﬁgures\\nDecide which is the last digit to keep, then:\\n\\n\\x0c2.9 The ﬁve golden rules 19\\n\\n• Leave the last digit unchanged if the next digit is 4 or lower: 6.62×10−34\\nbecomes 6.6×10−34 if only two signiﬁcant ﬁgures are appropriate.\\n• Increase the last digit by 1 if the next digit is 6 or higher: 5.67×10−8\\nbecomes 5.7×10−8 if only two signiﬁcant ﬁgures are appropriate.\\nIf the digit after the last one to be retained is 5 the recommended procedure\\nis to choose the even round value.9\\n• Leave the last digit unchanged if it is even. For example: 3.45 becomes\\n3.4 if only two signiﬁcant ﬁgures are appropriate.\\n• Increase the last digit by 1 if it is odd. For example: 3.55 becomes 3.6 if\\nonly two signiﬁcant ﬁgures are appropriate.\\nIn addition and subtraction, the result is rounded off to the same number\\nof decimal places as the number with the least number of decimal places. For\\nexample, 1.23 + 45.6 should be quoted as 46.8. This reﬂects the fact that we\\ndo not kn', 'ow whether the 45.6 is 45.56 or 45.64 to the next decimal place.\\nIn multiplication and division, the answer should be given to the same number of signiﬁcant ﬁgures as the component with the least number of signiﬁcant\\nﬁgures. For example, 1.2 × 345.6 is evaluated as 414.72 but quoted as 4.1 ×\\n102 on account of the least precise value having only two signiﬁcant ﬁgures.\\nIt is important to carry all signiﬁcant ﬁgures through long calculations\\nto avoid unnecessary rounding errors. Rounding to the appropriate precision\\nshould only be done at the end of the calculation.\\nThere are some exact numbers which can be considered to have an inﬁnite\\nnumber of signiﬁcant ﬁgures, and they do not inﬂuence the precision to which\\n√\\na result is quoted. They are often found in conversion factors (such as π or 2)\\nand when counting: there are exactly 100 centimetres in 1 metre; there are 14\\nstudents in the laboratory.\\n\\n2.9\\n\\nThe ﬁve golden rules\\n\\nWe ﬁnish this chapter with the ﬁve golden rules which must be obeyed when\\nreporting a parameter which was determined experimentally.\\n(1)\\n(2)\\n(3)\\n(4)\\n(5)\\n\\nThe best estimate of a parameter is the mean.\\nThe error is the standard error in the mean.\\nRound up the error to the appropriate number of signiﬁcant ﬁgures.\\nMatch the number of decimal places in the mean to the standard error.\\nInclude units.\\n\\nChapter summary\\n• The presence of random uncertainties can be ascertained by taking\\nrepeat measurements.\\n• For N measurements x1 , x2 , . . . , x N the mean, x̄, is the best estimate of\\nthe quantity x.\\n\\n9 This round-to-even method avoids bias in\\n\\nrounding, because half of the time we round\\nup, and half of the time we round down.\\n\\n\\x0c20\\n\\nRandom errors in measurements\\n\\n• The standard deviation of the sample σ N −1 gives a measure of the\\nprecision of the measurements—two-thirds of the measurements will\\nlie within σ N −1 of the mean.\\n• The uncertainty in the location of the centre of the distribution is given\\nby α, the standard error of the mean. The error decrease', 's (slowly) with\\nmore measurements:\\nσ N −1\\nα= √ .\\nN\\n• The result of repeated measurements is reported as x̄ ± α.\\n• The fractional error in the error decreases very slowly with increasing\\nthe number of measurements, hence the error is usually quoted to only\\none signiﬁcant ﬁgure.\\n\\nExercises\\n(2.1) Mean, standard deviation and standard error (1)\\nAn experiment was conducted to determine the concentration of a sodium hydroxide solution. The eight repeat\\nmeasurements of the volume of hydrochloric acid titrated\\n(all in ml) are: 25.8, 26.2, 26.0, 26.5, 25.8, 26.1, 25.8 and\\n26.3. Calculate (i) the mean, (ii) the standard deviation\\nusing the rough-and-ready approach; (iii) the standard\\ndeviation using eqn (2.3); (iv) the standard error of the\\nvolume.\\n(2.2) Mean, standard deviation and standard error (2)\\n12 measurements of the sensitivity of a photodiode circuit (in amps/watt) are: 5.33, 4.95, 4.93, 5.08, 4.95, 4.96,\\n5.02, 4.99, 5.24, 5.25, 5.23 and 5.01. Calculate (i) the\\nmean, (ii) the standard deviation using eqn (2.3); (iii) the\\nstandard error.\\n(2.3) Reduction of the standard error\\nIn a magnetometry experiment, after a minute of collecting data the statistical noise was reduced to 1 picotesla.\\nFor how much longer should data be collected in order\\nto reduce the random error by a factor of 10?\\n(2.4) Error in the error\\nConsider a set of measurements with the standard error\\ncalculated to be α = 0.987 654 321. Here we address\\nthe question of how many signiﬁcant ﬁgures should be\\nquoted. Construct a spreadsheet with four columns. The\\nﬁrst column should be N , the number of measurements\\non which α is based. In the second column write α\\nto the nine signiﬁcant ﬁgures quoted above. The third\\n\\n\\x0f\\n\\x0e\\n1\\nand fourth columns should be α × 1 − √\\n2N − 2\\n\\x0f\\n\\x0e\\n1\\n, respectively. As we are interand α × 1 + √\\n2N − 2\\nested in the variation over a large dynamic range, choose\\nvalues for N such as 2, 3, 5, 10, 20, 30, etc. Verify the\\nstatement from Section 2.7.1 that the number of data\\npoints, N , needs t', 'o approach a few tens of thousands\\nbefore the second signiﬁcant ﬁgure in the error can be\\nquoted, i.e. when the values in the three columns become\\nequal to the second signiﬁcant ﬁgure. Repeat the analysis for the case where α = 0.123 456 789, i.e. the ﬁrst\\nsigniﬁcant digit of the error is 1. How many data points\\nmust be collected before the third signiﬁcant ﬁgure can\\nbe quoted?\\n(2.5) Reporting results (1)\\nFifteen measurements of a resistance are quoted here,\\nbased on approximately 10 repeat measurements. Only\\nthree of them obey the ﬁve golden rules. Identify the\\nmistakes in the other results.\\n(i) (99.8 ± 0.270) × 103\\n(ii) (100 ± 0.3) × 103\\n\\n,\\n\\n,\\n\\n(iii) (100.0 ± 0.3) × 103\\n\\n,\\n\\n(iv) (100.1 ± 0.3) × 103 ,\\n(v) 97.1 × 103 ±276 ,\\n(vi) (99.8645 ± 0.2701) × 103\\n(vii) 98.6 × 103 ± 3 × 102\\n\\n,\\n\\n,\\n\\n\\x0cExercises\\n(viii) 99.4 × 103 ± 36.0 × 102\\n(ix) 101.5 × 103 ± 0.3 × 101\\n(x) (99.8 ± 0.3) × 103 ,\\n(xi) 95.2 × 103 ± 273\\n(xii) 98, 714 ± 378\\n(xiii) 99000 ± 278\\n\\n,\\n\\n(ii) 0.001 3806,\\n\\n,\\n\\n(iii) 0.022 413 83,\\n\\n(vi) 0.1660,\\n\\n,\\n\\n(vii) 299 790 000,\\n,\\n\\n(xv) 98900 ± 300 .\\n(2.6) Reporting results (2)\\nAnalysis of a Rydberg spectrum yields a quantum defect,\\nδ, for each line. How would you report the results if you\\nobtain (i) δ̄ = 3.273 46, with αδ = 0.019 13 from ﬁve\\nmeasurements; (ii) δ̄ = 3.265 13, with αδ = 0.002 506\\nfrom 50 measurements; or (iii) δ̄ = 3.266 81, with\\nαδ = 0.000 270 from 100 measurements?\\n(2.7) Signiﬁcant ﬁgures\\nRound up the following numbers to (a) two signiﬁcant\\nﬁgures, and (b) four signiﬁcant ﬁgures:\\n(i) 602.20,\\n\\n(iv) 1.602 19,\\n(v) 91.095,\\n\\n,\\n\\n,\\n\\n(xiv) 98, 714 ± 3 × 103\\n\\n21\\n\\n(viii) 66.2617,\\n(ix) 0.000 006 672 and\\n(x) 3.141 593.\\n(2.8) Scientiﬁc notation\\nRewrite the ten numbers from Exercise (2.7) in scientiﬁc\\nnotation.\\n(2.9) Superﬂuous precision\\nA car covers a distance of 250 m in 13 s; the average\\nspeed is calculated to the 10 decimal places of the calculator as 19.230 769 23 m s−1 . Explain why it is incorrect\\nto believe all of the signiﬁcant ﬁgures of the quoted\\nspeed.\\n\\n\\x0cThi', 's page intentionally left blank\\n\\n\\x0cUncertainties as\\nprobabilities\\n\\n3\\n\\nIn this chapter we develop further some of the ideas from Chapter 2, and\\nconsider the link between uncertainties in measurements and probabilities. The\\ndiscrete histograms considered so far will be augmented by the concept of a\\nprobability distribution function. The most important distribution function for\\nerror analysis is a Gaussian, and we extend the discussion from Chapter 2\\nabout the pertinent properties of this function. We are then able to discuss\\nthe conﬁdence limits in error analysis, our conﬁdence that the accepted value\\nof a measured quantity will lie within a certain range. We also consider\\nthe converse, namely what is the range of a variable within which a certain\\npercentage of measurements is likely to lie.\\nWhen counting discrete random events, such as the number of particles\\nemitted from a radioactive source, it transpires that the distribution does not\\nfollow a Gaussian distribution as discussed so far, but rather is better described\\nby a Poisson distribution. We discuss the relevant features of this distribution\\nfor error analysis.\\n\\n3.1\\n\\nDistributions and probability\\n\\nIn Section 2.4 we introduced for a discrete histogram the concept of the\\nenvelope curve, or continuous distribution function, associated with the hypothetical limit of the number of data points collected, N , tending to inﬁnity. In\\nstatistics a continuous random variable, say x, has a probability distribution\\nwhich may be speciﬁed in terms of a probability distribution function (or\\nprobability density function), PDF (x). A probability distribution function has\\nthe following properties:\\n(1) The distribution is said to be normalised, or proper, if\\n∞\\n\\nPDF (x) dx = 1.\\n\\n(3.1)\\n\\n−∞\\n\\n(2) The probability that x lies between two values x1 and x2 , with x1 ≤ x2 ,\\nis\\nx2\\n\\nP (x1 ≤ x ≤ x2 ) =\\n\\nPDF (x) dx.\\nx1\\n\\n(3.2)\\n\\n3.1 Distributions and probability\\n\\n23\\n\\n3.2 The Gaussian probability\\ndistribution function\\n\\n24\\n\\n3.3 Conﬁdence limits an', 'd error bars\\n\\n25\\n\\n3.4 Poisson probability function\\nfor discrete events\\n\\n28\\n\\n3.5 The central limit theorem\\n\\n31\\n\\nChapter summary\\n\\n34\\n\\nExercises\\n\\n35\\n\\n\\x0c24\\n\\nUncertainties as probabilities\\n\\n(3) The expectation of the n th power of the random variable x is\\n∞\\n\\nxn\\n\\n=\\n\\nPDF (x) x n dx.\\n\\n(3.3)\\n\\n−∞\\n\\nThe mean can be calculated by applying eqn (3.3) with n = 1:\\n∞\\n\\nx̄ =\\n\\nPDF (x) x dx.\\n\\n(3.4)\\n\\n−∞\\n\\nThe variance,\\n\\nσ 2,\\n\\nis deﬁned as:\\n\\n∞\\n\\nσ =\\n\\n∞\\n\\nPDF (x) (x − x̄) dx =\\n\\n2\\n\\n2\\n\\n−∞\\n\\n\\x11\\n\\x10\\nPDF (x) x 2 + x̄ 2 − 2x x̄ dx. (3.5)\\n\\n−∞\\n\\nBy applying eqn (3.3) with n = 2 and eqn (3.4) we obtain\\nσ 2 = x 2 − x̄ 2 ,\\n\\n(3.6)\\n\\nwhere x 2 is the mean of the squares of the random variable x.\\n\\n3.2\\n\\nThe Gaussian probability\\ndistribution function\\n\\nAs we discussed in Section 2.5 the most important function in error analysis\\nis the Gaussian (or normal) probability density distribution. For the sake of\\nbrevity we usually refer to it as the Gaussian probability distribution, or\\nsimply the Gaussian distribution. In this chapter we will write the function\\nas G (x; x̄, σ ), where:\\nG (x; x̄, σ ) =\\n\\n1\\n(x − x̄)2\\n,\\n√ exp −\\n2σ 2\\nσ 2π\\n\\n(3.7)\\n\\nto emphasise that the function has x as a variable, and has the mean, x̄, and\\nstandard deviation, σ , as two parameters.\\n\\n3.2.1\\nFig. 3.1 The error function of the random variable x is the cumulative integral\\n(the area under the curve) of a Gaussian\\nfrom −∞ to x. Here it is plotted for a\\nGaussian with mean x̄ = 10 and standard\\ndeviation σ = 3. The function is antisymmetric about the mean; is equal to 0.159 for\\nx = x̄ − σ , 0.500 for x = x̄, and 0.841 for\\nx = x̄ + σ ; and the error function tends\\nasymptotically to 1.\\n\\nProbability calculations\\n\\nWe can use eqn (3.7) to determine the fraction of the data which is expected\\nto lie within certain limits. For a Gaussian the cumulative probability is the\\nwell-known error function Erf (x1 ; x̄, σ ):\\nErf (x1 ; x̄, σ ) =\\n\\nx1\\n−∞\\n\\nG (x; x̄, σ ) dx.\\n\\n(3.8)\\n\\nThis function has the mean, x̄, and the standard deviation, σ , as parameters, and\\nis evaluated ', 'at x = x1 . The error function is plotted in Fig. 3.1 and tabulated in\\n\\n\\x0c3.3 Conﬁdence limits and error bars 25\\n\\nmany data-analysis packages. The fractional area under the curve between the\\nbounds x1 and x2 is thus:\\nP (x1 ≤ x ≤ x2 ) =\\n\\n1\\n√\\nσ 2π\\n\\nx2\\nx1\\n\\nexp −\\n\\n(x − x̄)2\\ndx\\n2σ 2\\n\\n= Erf (x2 ; x̄, σ ) − Erf (x1 ; x̄, σ ) .\\n\\n(3.9)\\n\\nFigure 3.2 shows the relationship between the error function and the area\\nunder certain portions of the Gaussian distribution function. For a Gaussian\\nwith mean x̄ = 10 and standard deviation σ = 3, what fraction of the data lies\\nin the interval 5 ≤ x ≤ 11.5? For this Gaussian the probability of obtaining a\\nvalue of x ≤ 11.5 is 0.69, and the probability of obtaining a value of x ≤ 5 is\\n0.05; hence 64% of the area under the curve is in the interval 5 ≤ x ≤ 11.5.\\n\\n3.2.2\\n\\nWorked example—the error function\\n\\nA box contains 100 resistors which are known to have a standard deviation\\nof 2 . What is the probability of selecting a resistor with a value of 95 or\\nless? What is the probability of ﬁnding a resistor in the range 99–101 ?\\nLet x represent the value of the resistance which has a mean of x̄ = 100 .\\nThe standard deviation is given as σ = 2 . The probability of selecting a\\nresistor with a value of 95 or less can be evaluated from eqn (3.8):\\nP = Erf (95; 100, 2) = 0.0062.\\nApplying eqn (3.9) we ﬁnd the probability of ﬁnding a resistor in the range\\n99–101\\nP = Erf (101; 100, 2) − Erf (99; 100, 2) = 0.38.\\nThese integrals can be evaluated numerically, found in look-up tables or found\\nby using appropriate commands in spreadsheet software.\\n\\n3.3\\n\\nConﬁdence limits and error bars\\n\\nConsider ﬁrst the fraction of the data expected to lie within one standard\\ndeviation of the mean:\\nP=\\n\\n1\\n√\\nσ 2π\\n\\nx̄+σ\\nx̄−σ\\n\\nexp −\\n\\n(x − x̄)2\\ndx\\n2σ 2\\n\\n= Erf (x̄ + σ ; x̄, σ ) − Erf (x̄ − σ ; x̄, σ ) .\\n\\n(3.10)\\n\\nNumerically, this integral is equal to 0.683 (to three signiﬁcant ﬁgures). In\\nother words, approximately two-thirds of the total area under the curve is\\nwithin a standard devia', 'tion of the mean. This is the origin of the two-thirds\\nterms used extensively in Chapter 2. We can now quantify our statements about\\nthe standard deviation of a sample of measurements: we are conﬁdent, at the\\n68% level, that, were we to take another measurement, the value would lie\\nwithin one standard deviation of the mean.\\n\\nFig. 3.2 A Gaussian with mean x̄ = 10 and\\nstandard deviation σ = 3 is shown. In (a)\\nthe fraction of the curve within the interval\\n5 ≤ x ≤ 11.5 is shaded; this is equal to the\\ndifference between (b) the error function\\nevaluated at 11.5 and (c) the error function\\nevaluated at 5. The relevant values of the\\nerror function are highlighted in (d).\\n\\n\\x0c26\\n\\nUncertainties as probabilities\\n\\n3.3.1\\n\\nExtended ranges\\n\\nBy evaluating the error function of eqn (3.9) we can deﬁne the probabilities\\nthat the data lie within an interval deﬁned by two, three, etc. standard deviations from the mean; these values are indicated in Fig. 3.3, and tabulated in\\nTable 3.1.\\nTable 3.1 The fraction of the data which lies within different ranges of a Gaussian\\nprobability distribution function.\\n±σ\\n\\n±1.65σ\\n\\n±2σ\\n\\n±2.58σ\\n\\n±3σ\\n\\n68%\\n32%\\n1 in 3\\n\\n90%\\n10%\\n1 in 10\\n\\n95%\\n5%\\n1 in 20\\n\\n99.0%\\n1.0%\\n1 in 100\\n\\n99.7%\\n0.3%\\n1 in 400\\n\\nCentred on mean\\nMeasurements within range\\nMeasurements outside range\\n\\nRecalling the interpretation of the standard error as a standard deviation of the\\nmean we can also calculate other conﬁdence intervals. Whereas often in the\\nphysical sciences the error bar is taken as one standard deviation of the mean\\n(the standard error), other conventions exist; in other disciplines the 95% conﬁdence limit is often used. Evaluating the error function of eqn (3.9) it can be\\nshown that 95.0% of the measurements lie within the range ±1.96σ . Therefore\\nif a data set of N measurements has a mean x̄ and standard deviation σ N −1 , we\\nσ N −1\\nwould report the result at the 95% conﬁdence limit as x̄ ± 1.96 × √ . DifN\\nferent conﬁdence limits can be used by scaling the standard error appropriate', 'ly.\\nIt should be noted that in the above discussion it is assumed that the standard\\ndeviation of the Gaussian distribution is precisely and accurately known. When\\nσ N −1 is ascertained from experimental data, especially from a small number\\nof repeat measurements, greater care is needed with conﬁdence limits. In\\nChapter 8 we will discuss the Student’s t distribution which is more appropriate\\nfor interval estimation from a small number of data points.\\n\\n3.3.2\\n\\nFig. 3.3 The shaded areas of the Gaussian\\ncurves show the fraction of data within (a)\\none standard deviation of the mean, (b) two\\nstandard deviations, and (c) three standard\\ndeviations. The corresponding points on the\\nerror function, along with those for four standard deviations, are indicated in (d).\\n\\nRejecting outliers\\n\\nHere we discuss a controversial topic in data analysis, that of rejecting outliers.\\nFrom Table 3.1 we learn that we should not be very surprised if a measurement is in disagreement with the accepted value by more then one error bar,\\nα; indeed, for a group of 15 students in a laboratory performing the same\\nexperiment, we would expect approximately ﬁve to report results where the\\nmagnitude of the difference between the accepted and measured results is\\ngreater than one error bar. However, as the fractional area under a Gaussian\\ncurve beyond 3σ or 5σ is only 0.3% and 6 × 10−5 %, respectively, we expect\\nsuch large deviations to occur very infrequently.\\n\\n\\x0c3.3 Conﬁdence limits and error bars 27\\n\\nChauvenet’s criterion1 (Taylor 1997, Section 6.2; Bevington and Robinson\\n2003 p. 56) is a test based on the Gaussian distribution with the aim of\\nassessing whether one data point which lies many error bars from the mean\\n(an outlier) should be regarded as spurious and hence discarded. The criterion\\nis equivalent to the statement ‘a data point is rejected from a sample if the\\nnumber of events we expect to be farther from the mean than the suspect point,\\nfor the sample’s mean and standard deviation, is less that a', ' half’. The procedure\\nis as follows:\\n(1) For your N measurements x1 , x2 , . . . , x N , calculate the mean, x̄, and\\nstandard deviation, σ N −1 .\\n(2) For the potential outlier, xout , use the error function to ﬁnd the probability that a result would randomly differ from the mean by the same\\namount, or more:\\n\\n1 Consider 10 data points, where a suspected\\n\\noutlier is three standard deviations removed\\nfrom the mean. Should this data point be\\nretained? From Table 3.1 we see that Pout =\\n0.003, thus the expected number of outliers is 0.03. As this is much less than 0.5\\nChauvenet’s criterion would indicate that the\\nsuspect data point be rejected. The mean,\\nstandard deviation and standard error of the\\nremaining nine data points should then be\\nrecalculated.\\n\\nPout = 1 − P (x̄ − xout ≤ x ≤ x̄ + xout )\\n= 1 − [Erf (x̄ + xout ; x̄, σ ) − Erf (x̄ − xout ; x̄, σ )] .\\n(3) Multiply the probability of there being such an outlier with the number\\nof data points, n out = Pout × N .\\n(4) If the number n out is less than one-half, then Chauvenet’s criterion states\\nthat you reject the outlier xout . One then recalculates the mean and\\nstandard deviation for the remaining N − 1 data points.\\nThis controversial procedure should be applied with care. One should always\\nask if there is a possible reason why the outlier occurred. We are assuming that\\nthe data follow a Gaussian distribution, therefore a whole class of potentially\\ninteresting questions about the form of the distribution of measurements from\\na particular experiment would be severely compromised by applying Chauvenet’s criterion. Rejecting outliers is easier to justify when a model of the\\nexpected distribution of the measured variable is known from previous experiments or a theoretical prediction. If there is a limited set of data (for example,\\nyou only had access to the telescope for one night’s observation) consider\\nremoving outliers. A better strategy is to repeat the measurement, revisiting\\nthe settings which produced the outlier if ', 'it is reasonably straightforward\\nto do so.\\n\\n3.3.3\\n\\nExperimental example of a Gaussian distribution\\n\\nFigure 3.4 shows the signal output from a photodiode as a function of time,\\nand in part (b) a histogram of the distribution of data. The mean and standard\\ndeviation of the data were calculated, and part (b) also has a Gaussian with the\\nsame mean and standard deviation superimposed on the the data.\\n\\nFig. 3.4 Part (a) displays the voltage across\\na photodiode as a function of time sampled\\n2 500 times. In (a) the standard deviation σ is\\nindicated by the arrow centred on the mean\\nof the signal (0.4 mV). In (b) the histogram\\nof the number of occurrences in 0.2 mV bins\\nis indicated, together with a smooth curve.\\nThe curve is the Gaussian distribution which\\nhas the same mean and standard deviation as\\nthe data. A comparison of what fraction lies\\nwithin certain bounds of the mean is encapsulated in Table 3.2.\\n\\n\\x0c28\\n\\nUncertainties as probabilities\\nTable 3.2 A comparison between experimental noise and a Gaussian model.\\nCentred on mean\\n\\n±σ\\n\\n±1.65σ\\n\\n±2σ\\n\\n±2.58σ\\n\\n±3σ\\n\\nExpected values\\nFraction of data points within range\\n\\n68%\\n67%\\n\\n90%\\n89%\\n\\n95%\\n95%\\n\\n99.0%\\n99.3%\\n\\n99.7%\\n99.9%\\n\\nWe can compare the percentage of data points that fall within one, two, etc.\\nstandard deviations of the mean, and compare with the values expected from a\\nGaussian distribution. This is shown in Table 3.2 and the agreement between\\ntheory and experiment is excellent.\\nThe fraction of data lying within these bounds is very close to that expected\\nfor a Gaussian distribution. In Chapter 8 we present techniques which allow\\nus to answer more quantitatively the question ‘how good a ﬁt to the data is the\\nGaussian distribution?’.\\n\\n3.3.4\\n\\nComparing experimental results with an\\naccepted value\\n\\nIf we are comparing an experimentally determined value with an accepted\\nvalue, we can use Table 3.1 to deﬁne the likelihood of our measurement being\\naccurate. The procedure adopted involves measuring the discrepancy between\\nthe experiment', 'ally determined result and the accepted value, divided by the\\nexperimentally determined standard error. If your experimental result and the\\naccepted value differ by:\\n• up to one standard error, they are in excellent agreement;\\n• between one and two standard errors, they are in reasonable agreement;\\n• more than three standard errors, they are in disagreement.\\n\\n3.4\\n\\nPoisson probability function for\\ndiscrete events\\n\\nThe Poisson distribution is the distribution function appropriate to modelling\\ndiscrete events. It expresses the probability of a number of relatively rare\\nevents occurring in a ﬁxed time if these events occur with a known average rate, and are independent of the time since the last event. The conditions under which a Poisson distribution holds are when (Bevington and\\nRobinson 2003, p. 23):\\n• counts are of rare events;\\n• all events are independent;\\n• the average rate does not change over the period of interest.\\nOne frequently encountered example of these conditions arises when dealing with counting—especially radioactive decay, or photon counting using a\\n\\n\\x0c3.4 Poisson probability function for discrete events 29\\n\\nGeiger tube. Unlike the normal distribution the only parameter we need to\\ndeﬁne is the average count in a given time, N . The average count is the product\\nof the average count rate, λ, and the time for which we count, τ : N = λτ .\\nFor example, in a particular radioactivity experiment the average count rate is\\nλ = 1.5 s−1 , and data are collected for 10 s. The average count expected is\\nthus 15. Now, for different repeats of the experiment the random character\\nof radioactive decay will mean there is a ﬂuctuation in the number, N , of\\nactual counts registered. The Poisson probability distribution is the singleparameter function which allows us to ﬁnd the probability that there are exactly\\nN occurrences (N being a non-negative integer, N = 0, 1, 2, . . .) given the\\naverage count, N . Note that the average count does not have to be an integer:\\nif counts ', 'are only collected for 1 s for this example we would expect a mean\\ncount of N = 1.5. The Poisson probability distribution is deﬁned as:\\n\\x04 N\\n\\x03\\n\\x04 exp −N N\\n\\x03\\n.\\n(3.11)\\nP N; N =\\nN!\\nThe denominator is the factorial function, and is deﬁned such that N ! =\\nN × (N − 1) × · · · × 3 × 2 × 1. As an example, 4! = 4 × 3 × 2 × 1 = 24.\\nThe functional form of eqn (3.11) is shown in Fig. 3.5 for two Poisson\\ndistributions, with means N = 1.5 and N = 15, respectively. Note that the\\nPoisson distribution is only deﬁned at integer values of N , i.e. there is some\\nﬁnite probability of having zero counts in the time τ (0.223 for N = 1.5), a\\nprobability of 0.335 of obtaining one count, etc. Each distribution is peaked\\nclose to the average value, N ; is asymmetric about this value; and, in common\\nwith all proper probability functions, the sum of the probabilities is equal to 1.\\nWe can ﬁnd the mean and the standard deviation of the Poisson probability\\nfunction using the discrete equivalent to eqn (3.3):\\n\\x05 \\x03\\n\\x04\\nN=\\nP N; N N,\\n(3.12)\\nand\\nN2 =\\n\\n\\x05\\n\\n\\x03\\n\\x04\\nP N ; N N 2.\\n\\nFig. 3.5 Poisson distributions with (a) mean\\nN = 1.5 and (b) mean N = 15. The probability of occurrence is plotted against the\\nnumber of counts, N . Note the asymmetry of\\nthe distribution about the mean.\\n\\n(3.13)\\n\\nEvaluating the summations in eqns (3.12) and (3.13) we ﬁnd that the average\\ncount (unsurprisingly)\\n\\x12 is N√, and the standard deviation of a Poisson distribution is simply σ = N = λτ . It is worth emphasising again that, in contrast\\nto the Gaussian distribution, only a single parameter (N ) is needed to specify\\na Poisson distribution—the mean and standard deviation are not independent.2\\n\\n2 Most spreadsheet software has built-in func-\\n\\ntions for evaluating the Poisson distribution.\\n\\n3.4.1\\n\\nWorked example—Poisson counts\\n\\nA safety procedure at a nuclear power plant stops the nuclear reactions in\\nthe core if the background radiation level exceeds 13 counts per minute. In\\na random sample, the total number of counts recorded in 10 hours', ' was 1980.\\nWhat is the count rate per minute and its error? What is the probability that\\nduring a random one-minute interval 13 counts will be recorded? What is the\\nprobability that the safety system will trip?\\n\\n\\x0c30\\n\\nUncertainties as probabilities\\n\\nThe number of counts recorded in a minute will follow a Poisson distribution. The mean count rate is λ = 1980/(10\\n× 60) = 3.30 counts per minute.\\n√\\n1980\\n= 44.5; therefore the error in the\\nThe error in the number\\nof\\ncounts\\nis\\n√\\ncount rate is αλ = 1980/(10 × 60) = 0.07 counts per minute. The probability of having 13 counts in a minute is given by the Poisson distribution, with\\nN = λ × τ = 3.30 and N = 13:\\nP (N = 13; 3.3) =\\n\\nexp (−3.3) 3.313\\n= 3.3 × 10−5 .\\n13!\\n\\nTo calculate the probability of having 13 or more counts it is, in fact, easier\\nto evaluate the probability of detecting 12 counts or fewer; these numbers are\\ncomplementary.\\nP (N ≥ 13; 3.3) = 1 − [P (0; 3.3) + P (1; 3.3) + · · · P (12; 3.3)]\\n= 4.2 × 10−5 .\\nTherefore, based on the number of counts recorded in a minute, the probability\\nthat the safety system will trip is 4.2 × 10−5 .\\n\\n3.4.2\\n\\nError bars and conﬁdence limits for Poisson\\nstatistics\\n\\nFor experiments that involve counting rare independent events with a constant\\naverage rate, the Poisson distribution is used.\\nIf an experiment\\n√yields a mean count of N the best estimate of the√error in\\nthis quantity is N . We therefore report the measurement as N ± N .\\n√\\n\\nN\\n1\\n= √ . For situaN\\nN\\ntions where the number of counts expected is very low (a weak source, an inefﬁcient detector or a short data collection interval) the Poissonian ﬂuctuations\\nin the random events lead to a poor signal-to-noise ratio. This phenomenon\\nwas referred to as shot noise in Chapter 1.\\nNote also the interpretation of the error bar as the standard deviation; having\\nmeasured N counts in a given time, we believe there is a two-thirds chance\\n√\\nthat another\\nrun of the experiment will yield a count in the interval N − N to\\n√\\nN + N . Owing to the asymmet', 'ry of the Poisson distribution one should not\\napply blindly the conﬁdence limits for a Gaussian distribution from Table 3.1.\\nFor Poisson counts the fractional uncertainty is\\n\\n3.4.3\\nFig. 3.6 The evolution of the Poisson distribution as the mean increases. The Gaussian\\ndistribution as a function of the continuous\\nvariable x is superimposed. The mean of the\\ndistribution is (a) 1, (b) 3, (c) 10 and (d) 50.\\n\\nApproximations for high means\\n\\nA feature of the Poisson distribution which distinguishes it from a Gaussian is\\nthe asymmetric distribution, most prominent for a low mean. However, as the\\nmean gets larger, the Poisson distribution gets more symmetric, and closely\\nresembles a Gaussian. Figure 3.6 shows the evolution of the (discrete) Poisson\\n\\n\\x0c3.5 The central limit theorem 31\\n\\nfunction compared with the appropriate (continuous) Gaussian distribution\\nfunction, as the mean evolves from 1 to 50.\\nAs the mean becomes large, the Poisson distribution can be approximated\\nby a normal distribution with the same mean and standard deviation as the\\nPoisson distribution it is approximating. Recall that for a Poisson distribution,\\n\\x12\\nwe have that the standard deviation is deﬁned in terms of the mean, σ = N .\\nThus from eqns (3.11) and (3.7) we can write the approximation as:\\n\\x03\\n\\x04 N\\nexp −N N\\nN!\\n\\n1\\n(x − x)2\\n√ exp −\\n2σ 2\\nσ 2π\\n\\n1\\n(x − x)2\\nexp −\\n,\\n√\\n2x\\n2π x\\n\\nwhere we use the continuous variable x for the Gaussian curve.\\nFrom Fig. 3.6 it is clear that as the mean increases the Poisson distribution becomes more symmetric and the approximation becomes increasingly good. As a rule of thumb, once N ≥ 35 the asymmetry in the\\nPoisson distribution is negligible, and it can be approximated to a normal\\ndistribution.\\n\\n3.5\\n\\nThe central limit theorem\\n\\nThe central limit theorem (CLT) is a theorem from statistics of great\\nimportance; see, for example Squires (2001, Section 3.8) and Lyons (1991,\\nSection 1.11.3). One way of stating the theorem is as follows: the sum of\\na large number of independent random va', 'riables, each with ﬁnite mean and\\nvariance, will tend to be normally distributed, irrespective of the distribution\\nfunction of the random variable.\\nNote that:\\n(1) Peculiarly, a normal (Gaussian) distribution is obtained for any distribution of the individual measurements.3\\n(2) Equation (2.1), which deﬁnes the average, is a sum of a number of\\nindependent random variables. Hence the CLT applies to the statistics\\nof the evaluation of the mean.\\n(3) The resulting normal distribution will have the same mean as the parent distribution, but a smaller variance. In fact, the variance is equal\\nto the variance of the parent divided by the sample size. This is\\nthe mathematical statement which underpins our observation in Section 2.7 of the improvement in precision of estimating the mean with\\nincreasing signal-to-noise, and of the reduction of the\\n√ standard error\\n(standard deviation of the mean) by a factor of N with respect\\nto the standard deviation of the sample when N data points are\\ncollected.\\n(4) The agreement between the distribution of the sum and a Gaussian\\nonly becomes exact in the (unphysical) limit of an inﬁnite number of\\nmeasurements. Fortunately, for most ‘reasonable’ distribution functions\\n(which experimental measurements tend to follow), the agreement is\\nvery good for a small number of measurements.\\n\\n3 ‘Any’ should be interpreted here as meaning\\n\\nany kind of function which is likely to occur\\nas a distribution function for experimental\\nmeasurements; mathematicians will be able\\nto think of more exotic functions for which\\nthe central limit theorem will not hold.\\n\\n\\x0c32\\n\\nUncertainties as probabilities\\n\\nFig. 3.7 Illustration of the central limit theorem. The ﬁrst column shows four different probability distribution functions. The ﬁrst three are for\\nthe continuous variable x, and have a mean of x̄ = 0.5. The last is a Poisson distribution with mean count N = 0.5. The second column plots the\\noutcome of 1000 computer-generated trials of choosing the variable from the approp', 'riate distribution function. There are statistical ﬂuctuations\\nin the computer-generated data, but the shapes of the sample distributions match those of the population distribution. The third column shows the\\nresults of another computer-generated set of experiments, where ﬁve numbers are chosen from the parent distribution and averaged; this procedure\\nwas repeated 1000 times. The distribution of these 1000 means is plotted, and is seen in each case to follow a Gaussian\\ndistribution (the continuous\\n√\\ncurve superimposed on the histograms). The standard deviation of the distributions in the third column is 5 smaller than the parent standard\\ndeviations in the ﬁrst columns as ﬁve data points were used to generate the average.\\n\\n\\x0c3.5 The central limit theorem 33\\n\\n(5) We will use the central limit theorem as justiﬁcation for assuming that the distribution function of interest to us is always a\\nGaussian (with the exception of Poisson counting statistics), and apply\\nquantitative results, such as conﬁdence limits, valid for Gaussian\\ndistributions.\\nMore mathematically, the CLT states that if x1 , x2 , . . . , x N are N independent random variables drawn from any distribution which has a mean x̄\\nand standard deviation σ , then the distribution of the sample mean, which\\n1\\nis\\n(x1 + x2 + · · · + x N ), is normal with a mean x̄ and standard deviation\\nN\\nσ\\n√ .\\nN\\n\\n3.5.1\\n\\nExamples of the central limit theorem\\n\\nWe now give three different examples of the central limit theorem, one of\\nwhich uses data generated on a computer; the other two involve actual measurements.\\nFigure 3.7 shows four different probability density functions in the ﬁrst\\ncolumn. The ﬁrst three are for a continuous variable x, and each has a mean\\nof x̄ = 0.5. The ﬁrst distribution is the uniform distribution, the second a\\ntriangular distribution (both of the above have the range 0 ≤ x ≤ 1). The third\\nis a Gaussian distribution of mean x̄ = 0.5 and standard deviation σ = 0.3.\\nThe fourth is a discrete Poisson distribution,', ' with a mean count of N = 0.5.\\nThe second column shows the results of trials where 1000 points are chosen\\naccording to the relevant probability distribution function. Unsurprisingly,\\nthese ﬁgures have statistical noise, but are seen to have the same shape as the\\ncorresponding mathematical function. The third column depicts the result of\\n1 000 trials, each of which chose ﬁve samples from the appropriate distribution\\nand from which the mean was calculated. The distribution of the means is\\nshown here. There are three things to note: (i) irrespective of the shape of\\nthe initial probability distribution function, the histogram of the means is well\\ndescribed by a normal distribution; (ii) the distribution of means is peaked at\\n0.5, the mean of the original distributions; (iii) the width of the distribution of\\nmeans is less√than the width of the original probability distribution functions,\\nby a factor N . This is a√manifestation of the reduction of the standard\\ndeviation of the means by 5 with respect to the standard deviation of the\\noriginal probability distribution functions, in agreement with the discussion of\\nthe standard error in Chapter 2. These three outcomes are in agreement with\\nthe predictions of the central limit theorem.\\nAn example of a situation where the distribution of measurements is nonGaussian is radioactive decay, for which a Poisson distribution is obtained. Figure 3.8(a) shows a typical histogram obtained after making 58 measurements of\\n1 s duration. The mean number of counts per second is 7.2, and the histogram\\nshows the characteristic asymmetric proﬁle of a Poisson distribution. As an\\nillustration of the central limit theorem the experiment was repeated another\\n50 times. Figure 3.8(b) shows the distribution of the means of the 51 trials,\\n\\nFig. 3.8 Part (a) shows the result of a\\nradioactive decay experiment. 423 counts\\nwere recorded in 58 seconds; the histogram\\nshows the occurrences of the number of\\ncounts in one-second intervals about a mean\\nof 7.3 c', 'ounts per second. On repeating this\\nexperiment 51 times, it is possible to plot the\\ndistribution of the means, as is done in (b).\\nHere it is seen that the distribution of means\\nis (i) well described by a Gaussian, and (ii)\\nsigniﬁcantly narrower than the sample Poisson distribution.\\n\\n\\x0c34\\n\\nUncertainties as probabilities\\n\\nFig. 3.9 Part (a) shows a histogram of the\\noccurrences of the 49 balls in all 106 national\\nlottery draws for the year 2000. If there was\\nno bias a uniform distribution of 13 occurrences per ball would be expected; the experimental data are in good agreement with this\\nwithin the statistical ﬂuctuations. Six balls\\nare chosen in each draw, the average number\\nwas calculated, and the histogram of the 106\\nresults is plotted. As expected, a Gaussian\\ndistribution is obtained for the means, with\\na√narrower standard deviation (by a factor of\\n6) compared with the parent distribution.\\n\\ntogether with the best-ﬁt Gaussian distribution. It is evident that the distribution\\nof the means is symmetric, unlike the distribution of individual counts. A\\ndiscussion of how well the experimental results follow the theoretical model\\nis delayed until Chapter 8. The last example we discuss here is depicted in\\nFig. 3.9. The national lottery in the UK has six balls chosen at random from a\\nset numbered 1, . . . 49. The occurrence of any particular ball should be independent of the others, hence the relevant distribution function is the uniform\\none. Figure 3.9(a) shows the outcomes of all 106 draws in the year 2000. The\\ndistribution of individual balls is seen to be approximately uniform, centred on\\nthe mean of 13 occurrences per ball. Figure 3.9(b) shows the average number\\nof the six balls for the 106 draws; the average is obtained by summing the\\nsix integer ball numbers, and dividing by six. Once again, although the parent\\nprobability distribution function is uniform, the distribution of means is seen\\nto follow a Gaussian distribution, in accordance with the central limit theorem.\\n', 'Further analysis of the mean and standard deviation of the distributions is\\ndetailed in Exercise (3.10).\\nWhy is the distribution of means narrower than the distribution of the\\nindividual measurements? Consider the lottery example again. The smallest\\npossible mean is 3.5, which is achieved uniquely from the numbers 1, 2, 3,\\n4, 5 and 6. In contrast, to obtain a mean of 25 we could have 22, 23, 24, 26,\\n27 and 28; or 1, 22, 25, 26, 27 and 49; or 1, 10, 25, 26, 39 and 49; or 3, 9,\\n14, 31, 45 and 48; or . . .. There are many more sets of six integers chosen at\\nrandom from 1–49 with a mean of 25 than there are with a mean of 3.5. The\\nargument holds for means much larger than the most likely one also: 44, 45,\\n46, 47, 48 and 49 is the only combination which yields the highest possible\\nmean of 46.5. As each random sequence is as likely as any other one, it is far\\nmore likely statistically to obtain six numbers with a mean around 25 than 3.5.\\nConsequently, the width of the distributions of means is signiﬁcantly narrower\\nthan the distribution of individual numbers.\\n\\nChapter summary\\n• For a continuous probability distribution function PDF (x), the probability, P, that x lies between two values\\n\\x13 x x1 and x2 is given by the area\\nunder the curve: P (x1 ≤ x ≤ x2 ) = x12 PDF (x) dx.\\n• The variance, σ 2 , is the mean of the square minus the square of the\\nmean: σ 2 = x 2 − x̄ 2 .\\n• The standard deviation is the square root of the variance.\\n• The Gaussian, or normal, distribution function is speciﬁed by its centre\\n1\\n(x − x̄)2\\n.\\nand standard deviation: G (x; x̄, σ ) = √ exp −\\n2σ 2\\nσ 2π\\n• For a Gaussian distribution 68% of the data are expected to lie within\\nthe standard deviation of the mean; 95% of the data are expected to\\nlie within two standard deviations of the mean; 99.7% of the data are\\nexpected to lie within three standard deviations of the mean.\\n\\n\\x0cExercises\\n\\n35\\n\\n• The distribution of discrete counts, e.g. radioactive decays, follow a\\n\\x03\\n\\x04 N\\n\\x03\\n\\x04 exp −N N\\nPoisson distribution P N ;', ' N =\\n.\\nN!\\n• Only the mean, N , is needed to specify a Poisson distribution.\\n√\\n• If N counts are detected in a given time, the error on this is N .\\n\\nExercises\\n(3.1) Discrete or continuous\\na sample of 1000 bags how many will contain at least\\nWhich of the following variables are discrete, and which\\n530 g?\\ncontinuous? (i) The number of marks awarded for an\\n(3.6) Identifying a potential outlier\\nexamination paper; (ii) the height of adult males; (iii) the\\nSeven successive measurements of the charge stored on a\\nconcentration of CO2 in the atmosphere; (iv) the charge\\ncapacitor (all in μC) are: 45.7, 53.2, 48.4, 45.1, 51.4, 62.1\\nstored in a capacitor; and (v) the monthly salary of uniand 49.3. The sixth reading appears anomalously large.\\nversity employees.\\nApply Chauvenet’s criterion to ascertain whether this\\n(3.2) Uniform distribution\\ndata point should be rejected. Having decided whether\\nA probability distribution function of interest in error\\nto keep six or seven data points, calculate the mean,\\nanalysis is the uniform distribution. It is deﬁned as\\nstandard deviation and error of the charge.\\n\\x14\\nPU (x; x̄, a) =\\n\\n1/a\\n0\\n\\nif x̄ − a/2 ≤ x ≤ x̄ + a/2,\\notherwise.\\n\\nHere the parameter x̄ is the mean of the distribution,\\nand a is the interval in which the probability distribution\\nis uniform. Show that (i) the distribution PU (x; x̄, a) is\\nnormalised; (ii) the mean of the distribution is indeed x̄;\\na\\n(iii) the standard deviation is given by σ = √ .\\n12\\n(3.3) Normal distributions\\nConsult a reference resource and list three examples of\\nnaturally occurring distributions which are known to follow a Gaussian distribution.\\n\\n(3.7) Calculations based on a Poisson distribution (1)\\nIn the study of radioactive decay 58 successive experiments for one second yielded the following counts (these\\nare the data plotted in Fig. 3.8).\\n\\nN\\nOccurrence\\n\\n1 3\\n1 2\\n\\n4\\n3\\n\\nN\\nOccurrence\\n\\n8 9 10\\n8 8\\n6\\n\\n5\\n6\\n\\n6\\n9\\n\\n7\\n11\\n\\n11 12\\n2 1\\n\\n13\\n1\\n\\nCalculate (i) the total number of counts recorded; (ii) the\\nmean count; and (iii) t', 'he mean count rate. Assuming that\\nthe data are well described by a Poisson distribution and\\nthat another 58 one-second counts are recorded, calculate\\n(i) the expected number of occurrences of ﬁve counts\\nor fewer; (ii) the expected number of occurrences of 20\\ncounts or more.\\n\\n(3.4) Conﬁdence limits for a Gaussian distribution\\nVerify the results of Table 3.1 for the fraction of the\\ndata which lies within different ranges of a Gaussian\\nprobability distribution function. What fraction of the\\ndata lies outside the following ranges from the mean?\\n(i) ±4σ and (ii) ±5σ . What is the (symmetric) range\\n(3.8) Calculations based on a Poisson distribution (2)\\nwithin which the following fractions of the data lie? (i)\\nIn the study of radioactive decay during a one-minute\\n50% and (ii) 99.9%.\\nperiod 270 counts are recorded. Calculate: (i) the mean\\ncount rate; (ii) the error in the mean count rate; and\\n(3.5) Calculations based on a Gaussian distribution\\n(iii) the fractional error in the mean count rate. Were\\nBags of pasta are sold with a nominal weight of 500 g. In\\nthe experiment to be repeated with a 15-minute countfact, the distribution of weight of the bags is normal with\\ning interval, what is (iv) the expected count; and (v) the\\na mean of 502 g and a standard deviation of 14 g. What\\nprobability of obtaining exactly 270 × 15 counts?\\nis the probability that a bag contains less than 500 g? In\\n\\n\\x0c36\\n\\nUncertainties as probabilities\\n\\n(3.9) Approximation for high means\\nPlot a histogram of a Poisson distribution with mean\\n35. Using the same axes plot the continuous function of\\na√Gaussian with a mean of 35, and standard deviation\\n35. Comment on similarities and differences between\\nthe distributions.\\n(3.10) An example of the central limit theorem\\nThe lottery results encapsulated in Fig. 3.9 are based\\non six numbers being selected from the integers\\n1, 2, . . . , 49. The distribution of these numbers should\\nfollow the functional form given in Exercise (3.2). Use\\n\\nthe results of that exercise ', 'to predict the mean and standard deviation expected for this distribution. How do\\nthese compare with the results for the year 2000, with\\na mean of 25.4, and standard deviation 14.3? The lottery\\nhas six numbers selected, with the mean readily calculated. Based on the central limit theorem we expect the\\ndistribution of the means to follow a Gaussian\\ndistribu√\\ntion with a standard deviation which is 6 smaller than\\nthe original distribution. What do you predict for the\\nmean and standard deviation of the means? How do these\\ncompare with the results for the year 2000, with a mean\\nof 25.4, and standard deviation 5.7?\\n\\n\\x0cError propagation\\n\\n4\\n\\nThe aim of most experiments in the physical sciences is to combine several\\nvariables into a single quantity. The error on the combined value is a function\\nof the errors on the constituent terms. As the addition of probabilities is not\\nlinear, simply summing the errors of the constituent terms gives an overestimate of the error in the combined variable. In this chapter we show how\\nerrors can be propagated through single and multi-variable functions using a\\nfunctional approach (highly amenable to spreadsheet analysis) and a calculusbased approximation. We provide look-up tables for commonly encountered\\nfunctions and discuss experimental strategy based on the dominant error.\\n\\n4.1\\n\\n4.1 Propagating the error in a\\nsingle-variable function\\n\\n37\\n\\n4.2 Propagating the error through\\na multi-variable function\\n\\n40\\n\\n4.3 Propagating errors in functions\\n\\n47\\n\\n4.4 Experimental strategy based\\non error analysis\\n\\n47\\n\\n4.5 Combined experiments\\n\\n49\\n\\nChapter summary\\n\\n51\\n51\\n\\nExercises\\n\\nPropagating the error in a single-variable\\nfunction\\n\\nIf one measures a variable A to have a mean Ā and standard error α A ,\\nit is instructive to see how it propagates through\\x03a \\x04single-variable function\\nZ = f (A). The best estimate of Z will be Z̄ = f Ā . In contrast, the uncertainty in Z is a function of both A and its uncertainty.\\nIn Fig. 4.1 we show Bragg’s law which relates t', 'he X-ray wavelength, λ, to\\nthe incident Bragg angle, θ . In this example, λ = f (θ ), or more explicitly:\\nλ = 2d sin θ.\\n\\n(4.1)\\n\\nFor a given angle, θ̄, one can calculate the wavelength through eqn (4.1).\\nHowever, as eqn (4.1) contains a nonlinear relationship, the uncertainty in\\nwavelength, αλ , depends both on the angle, θ , and its uncertainty, αθ . Note\\nthat in Fig. 4.1(b) a symmetric error in the angle, αθ , maps into an asymmetric\\nerror in wavelength.\\nIf α A represents the error on the mean Ā, the error in the function Z , α Z ,\\ncan be found by propagating Ā ± α A through the function. Thus:\\n\\x04\\n\\x03\\nZ̄ ± α Z = f Ā + α A ,\\n(4.2)\\n\\x03 \\x04\\nZ̄ = f Ā ,\\n(4.3)\\n\\x04\\n\\x03\\n(4.4)\\nZ̄ ∓ α Z = f Ā − α A .\\n\\x04\\n\\x03\\nThe origin of the ± signs in eqn (4.2) and (4.4) is as follows: f Ā + α A will\\ngive Z̄ + α Z if the gradient of f ( A) with respect to Z is positive, and Z̄ − α Z\\n\\nλ + αλ\\nλ\\nλ – αλ\\n\\nθ – αθ\\n\\nθ\\n\\nθ + αθ\\n\\nFig. 4.1 (a) A plot of Bragg’s law relating the\\nX-ray wavelength, λ, to the incident angle, θ ,\\nfor a Si single crystal. (b) Enlarged section\\nshowing how an uncertainty in the incident\\nangle, αθ , maps directly into an uncertainty\\nin wavelength, αλ . As this is a nonlinear relationship αλ depends both on θ and αθ .\\n\\n\\x0c38\\n\\nError propagation\\n\\nif the gradient of f (A) is negative. The error propagation using eqns (4.2) and\\n(4.4) is shown schematically for Bragg’s\\n\\x03 law \\x04in Fig. 4.1(b). As the gradient of\\nf (θ) with respect to λ is positive, f θ̄ + αθ returns the positive error in λ.\\n\\n4.1.1\\n\\nThe functional approach for\\nsingle-variable functions\\n\\nSpreadsheets greatly facilitate the propagation of errors in a single-variable\\nfunction. The error (assumed here to be symmetric) in Z for a particular\\nmeasurement Ā is simply:\\n\\x02 \\x03\\n\\x04\\n\\x03 \\x04\\x02\\n(4.5)\\nα Z = \\x02 f Ā + α A − f Ā \\x02 .\\n\\nFig. 4.2 The error in the wavelength, αλ , as\\na function of incident angle, θ , using Bragg’s\\nlaw. The error in the incident angle, αθ , is a\\nconstant 0.050◦ . The error in the wavelength\\nhas a cosine dependence on the angle.', '\\n\\nZ = f(A)\\n\\nThis relationship is valid for any single-variable function. Many commonly\\nencountered data-analysis packages include built-in functions such as standard\\ntrigonometric functions, logarithms, exponentials, powers and even special\\nfunctions such as Bessel and gamma. The argument of the function can easily\\nbe calculated at Ā and Ā ± α A , enabling a quick determination of the error in\\nZ using eqn (4.5).\\nReturning to the Bragg’s law example, eqn (4.5) can be used to calculate\\nthe error in the wavelength as a function of the incident angle; this is shown in\\nFig. 4.2. An uncertainty of αθ = 0.050◦ will give an error of αλ = 0.92 pm at\\nθ = 15◦ and αλ = 0.25 pm at θ = 75◦ . The error as a function of incident\\nangle is, in fact, a cosine function for reasons that will become clear in\\nSection 4.1.2.\\n\\n4.1.2\\nf ( Ā )\\n\\nĀ\\nS\\nR\\nαZ\\nP\\n\\nQ\\nαA\\n\\nFig. 4.3 The upper part shows a nonlinear\\nfunction Z = f (A) and its tangent at Ā. The\\nlower part shows an expanded view in the\\nvicinity of Ā: the four\\nP, Q,\\n\\x03 points\\n\\x03 \\x04\\x04\\n\\x03 R and S\\nhave co-ordinates Ā, f Ā , Ā + α A ,\\n\\x11\\n\\x10\\n\\x03 \\x04 df\\n\\x03 \\x04\\x04\\n× α A and\\nf Ā , Ā + α A , f Ā + dA\\n\\x03\\n\\x04\\x04\\n\\x03\\nĀ + α A , f Ā + α A , respectively.\\n\\nA calculus-based approximation for\\nsingle-variable functions\\n\\nWe have seen in Fig. 4.1 how the error could be propagated through a\\nsingle-variable function. An approach based on calculus is highlighted in\\nFig. 4.3\\n\\x03 where\\n\\x03 \\x04\\x04 a nonlinear function, Z = f (A), and its tangent at point\\nP = Ā, f Ā are sketched. The gradient of the tangent can be found using\\nQR\\n.\\nthe triangle P Q R where the gradient of the tangent is\\nPQ\\nIn the limit that α A is small we can approximate the coordinates of R and\\nS to be equal. (This is equivalent to retaining only the ﬁrst two terms of the\\nTaylor series expansion of eqn (4.5) and is discussed further in Section 4.2.3.)\\nMathematically, using the coordinates from Fig. 4.3(b), we can write:\\n\\x04\\n\\x03\\n\\x03 \\x04 d f (A)\\nα A = f Ā + α A ,\\nf Ā +\\ndA\\nwhich, using eqn (4.5) and recalling that\\nresult for', ' a single-variable function:\\n\\n(4.6)\\n\\ndZ\\nd f (A)\\n≡\\n, leads to the general\\ndA\\ndA\\n\\n\\x02 \\x02\\n\\x02 dZ \\x02\\nα Z = \\x02\\x02 \\x02\\x02 α A .\\ndA\\n\\n(4.7)\\n\\n\\x0c4.1 Propagating the error in a single-variable function 39\\n\\nThere are three things to note about eqn (4.7). Firstly, the modulus sign\\nfor the gradient ensures that the error in Z is a positive number. Secondly,\\nthe calculus method predicts symmetric error bars—in contrast the functional\\napproach of eqns (4.2) and (4.4) allows for asymmetric error bars. Thirdly, this\\nresult is only valid for small errors.\\nThe calculus approximation requires the ability to calculate the derivative\\nof the function at speciﬁc arguments. For complicated functions, these calculations can become non-trivial. There are certain functions, for example\\nZ (θ) = sin−4 (θ/2), for which the spreadsheet approach is considerably simpler than the calculus approach.1\\n\\n1 The function sin−4 (θ/2) describes the\\n\\nangular dependence of the differential crosssection in Rutherford scattering.\\n\\n4.1.3\\n\\nLook-up table for common single-variable functions\\n\\nWe can use the calculus method, eqn (4.7), to derive a look-up table to help\\npropagate errors through commonly encountered single-variable functions; see\\nTable 4.1.\\nTable 4.1 Results for the propagation of errors in single-variable functions.\\nThe results for the trigonometric functions assume that the angles and their\\nerrors are in radians.\\n\\n4.1.4\\n\\nFunction, Z ( A)\\n\\ndZ\\ndA\\n\\nError\\n\\n1\\nA\\n\\n1\\n− 2\\nA\\n\\nαz =\\n\\nexp A\\n\\nexp A\\n\\nαz = exp A α A = Z α A\\n\\nln A\\n\\n1\\nA\\n\\nαz =\\n\\nlog A\\n\\n1\\nln (10) A\\n\\nαz =\\n\\nAn\\n\\nn An−1\\n\\n10 A\\n\\n10 A ln (10)\\n\\nαz = 10 A ln (10) α A\\n\\nsin A\\n\\ncos A\\n\\nαz = |cos A| α A\\n\\ncos A\\n\\n− sin A\\n\\nαz = |sin A| α A\\n\\ntan A\\n\\n1 + tan2 A\\n\\n\\x11\\n\\x10\\nαz = 1 + Z 2 α A\\n\\n\\x02α \\x02 \\x02α \\x02\\nαA\\n\\x02 Z \\x02 \\x02 A\\x02\\n= Z 2 α A OR \\x02\\n\\x02=\\x02\\n\\x02\\n2\\nZ\\nA\\nA\\n\\nαA\\nA\\n\\nαA\\nln (10) A\\n\\x02\\n\\x02α \\x02 \\x02 α \\x02\\n\\x02\\n\\x02\\n\\x02\\n\\x02 \\x02\\n\\x02\\n\\x02\\nαz = \\x02n An−1 \\x02 α A OR \\x02 Z \\x02 = \\x02n A \\x02\\nZ\\nA\\n\\nWorked example—single variable function\\n\\nWe will illustrate both approaches to the propagation of errors through the\\nsingle-variable function Z = 10 A . Suppose we had ', 'measured A = 2.3 ± 0.1.\\nWhat is the value of Z and its error?\\nOur best estimate of Z is the mean, Z̄ = 102.3 = 199.5. We defer the rounding of the mean until the error has been calculated.\\n\\n\\x0c40\\n\\nError propagation\\n\\n(a) Calculating the error in Z using the functional approach:\\nThe errors in Z are:\\n2.3+0.1\\n− 102.3 = 51.7,\\nα+\\nZ = 10\\n\\nand\\n2.3\\n− 102.3−0.1 = 41.0.\\nα−\\nZ = 10\\n\\nWe therefore say that our best estimate of Z lies within the range\\n158 ≤ Z̄ ≤ 251. An approximation to the symmetric error bar can be\\nfound by quoting the average error bar. As we only know the uncertainty\\nin A to one signiﬁcant ﬁgure, we report our best estimate of Z as\\nZ = (2.0 ± 0.5) × 102 . An alternative way \\x10to report\\x11 this result, which\\n2\\nkeeps the assymetry of the error bar, is Z = 2.0+0.5\\n−0.4 × 10 .\\n(b) Calculating the error in Z using the calculus approximation and the lookup tables:\\nα Z = Z ln (10) α A = 199.5 × ln (10) × 0.1 = 45.9,\\nagain, as we only know the uncertainty in A to one signiﬁcant ﬁgure, we\\nquote\\nZ = (2.0 ± 0.5) × 102 .\\n\\n2 The asymmetry of the error bars determined\\n\\nusing the functional approach indicate that\\nthe distribution of Z is not Gaussian. We\\ntherefore do not know trivially the conﬁdence\\nlimits to which these error bars correspond,\\nand cannot blindly apply the results from\\nChapter 3.\\n\\nWe note that it is only the functional approach that shows the asymmetry\\nin mapping the errors in A to those in Z . As the error is relatively small, the\\ncalculus method is a good approximation and the two methods yield identical\\nresults.\\nFor larger errors in A the calculus approximation becomes less reliable. Suppose we had measured A = 2.3 ± 0.4 instead. Our best estimate of Z remains\\nunchanged. Calculating the errors using the functional approach shows Z now\\nlies within the range 79 ≤ Z̄ ≤ 501. We\\nthe asymmetry of the error\\n\\x10 illustrate\\n\\x11\\n2 . In contrast, the calculus×\\n10\\nbar2 by reporting our result as Z = 2+3\\n−1\\nbased approach yields Z = (2 ± 2) × 102 .\\n\\n4.2\\n\\nPropagating the error th', 'rough\\na multi-variable function\\n\\nIn many cases the function through which we wish to propagate our errors\\nis multi-variable. One needs to map a series of measurements, A, B, C, . . .\\nand their associated errors through the function Z = f (A, B, C, . . .). As\\nin the case for a single-variable function, our best\\n\\x03 estimate of\\x04 Z is made\\nthrough the mean values of the parameters Z̄ = f Ā, B̄, C̄, . . . . As before,\\nthe error\\x03 in Z is a function of both\\n\\x04 the mean values and their errors:\\nα Z = f Ā, B̄, C̄, . . . ; α A , α B , αC , . . . .\\n\\n\\x0c4.2 Propagating the error through a multi-variable function 41\\n\\n4.2.1\\n\\nThe functional approach for multi-variable functions\\n\\n\\x03\\n\\x04\\n\\x03\\n\\x04\\nα ZA = f Ā + α A , B̄ − f Ā, B̄ .\\n\\n(4.8)\\n\\nf(A, B)\\n\\nConsider ﬁrst a function of two variables, Z = f (A, B). The equivalent of\\nFig. 4.1 is now a two-dimensional surface, as shown in\\x03 Fig. \\x044.4 (a). Our best\\nestimate of Z is a point on the surface given by Z̄ = f Ā, B̄ . The error in Z\\ncomprises two components. One component is the change in Z (the height of\\nthe surface) around the mean when A is varied and B is kept constant, as seen\\nin Fig. 4.4 (b). This change of height is:\\n\\nSimilarly, as shown in Fig. 4.4(c), there is also a change in the surface around\\nthe mean when B is changed and A remains ﬁxed:\\n(4.9)\\n\\nTo proceed, we need to assume that the uncertainties in A and B are uncorrelated and that A and B are independent variables. (An independent\\nvariable is not correlated with either the magnitude or error of any other\\nparameter.) The total error in Z is obtained by applying Pythagoras’ theorem and adding the components in quadrature. For N independent variables we apply Pythagoras’ theorem in N dimensions to obtain the general\\nresult:\\n\\x10 \\x112 \\x10 \\x112 \\x10 \\x112\\n(α Z )2 = α ZA + α ZB + α CZ + · · ·\\n\\nf(A, B)\\n\\n\\x04\\n\\x03\\n\\x04\\n\\x03\\nα ZB = f Ā, B̄ + α B − f Ā, B̄ .\\n\\nA A + αA\\n\\n(4.10)\\n\\nWe see in Fig. 4.4 that eqn (4.10) can be written in functional form as:\\n\\n+···\\n\\nf(A, B)\\n\\n\\x15 \\x03\\n\\x04\\n\\x03\\n\\x04\\x162\\n(α Z )2 = f Ā + α A , B̄, C̄, . . . − f', ' Ā, B̄, C̄, . . .\\n\\x04\\x162\\n\\x15 \\x03\\n\\x04\\n\\x03\\n+ f Ā, B̄ + α B , C̄, . . . − f Ā, B̄, C̄, . . .\\n\\x04\\x162\\n\\x15 \\x03\\n\\x04\\n\\x03\\n+ f Ā, B̄, C̄ + αC , . . . − f Ā, B̄, C̄, . . .\\n(4.11)\\n\\nAs we discussed for the single-variable case, this approach is very amenable\\nto spreadsheet analysis as the error in Z is found by quickly re-evaluating the\\nfunction with different arguments. It is straightforward to see how eqn (4.2)\\nand eqn (4.4) can be used to look for asymmetries in the error bars when propagating an error in the single-variable case. However, in N -dimensions this\\nbecomes difﬁcult, and eqn (4.11) assumes that the magnitude of the variation\\nin the function Z is the same when an independent variable is either increased\\nor decreased by an error bar around its mean position. This approximation\\nusually holds for small errors but one should be careful if the function is highly\\nnonlinear, or the error bars are large. In such cases, it is wise to look more\\ncarefully at the error surface, a concept which is discussed in more detail in\\nChapter 6.\\n\\nB B + αB\\nFig. 4.4 (a) A two-dimensional surface plot\\nof the function Z = f (A, B). (b) A slice\\nalong the A-axis when B is kept at its mean\\nvalue B̄. The change in height of the surface, α ZA , owing to a displacement α A along\\n\\x03\\n\\x04\\nthe A-axis from the point Z̄ = f Ā, B̄ is\\n\\x04\\n\\x03\\n\\x04\\n\\x03\\nf Ā + α A , B̄ − f Ā, B̄ . (c) A slice along\\nthe B-axis when A is kept at its mean\\nvalue Ā. The change in height of the surface, α ZB , owing to a displacement α B along\\n\\x03\\n\\x04\\nthe B-axis from the point Z̄ = f Ā, B̄ is\\n\\x04\\n\\x03\\n\\x04\\n\\x03\\nf Ā, B̄ + α B − f Ā, B̄ . Pythagoras’ theorem relates the total error, α Z , to the compo\\x10 \\x112 \\x10 \\x112\\nnents: (α Z )2 = α ZA + α ZB .\\n\\n\\x0c42\\n\\nError propagation\\n\\n4.2.2\\n3 The van der Waals equation of state is a cor-\\n\\nrection to the ideal gas law. The coefﬁcients\\na and b take into account, respectively, the\\nattraction between the constituents of the gas,\\nand the volume excluded owing to the ﬁnite\\nsize of the atoms or molecules. Both of these\\nterms are assumed to be ze', 'ro in the case of\\nan ideal gas. These speciﬁc corrections to the\\nideal gas law were proposed by Johannes van\\nder Waals in 1873.\\n\\nWorked example—functional approach\\nfor multi-variable functions\\n\\nThe van der Waals equation of state for a gas is3\\n\\x0e\\n\\x0f\\na\\nP + 2 (Vm − b) = RT,\\nVm\\n\\n(4.12)\\n\\nwhere P is the pressure, Vm is the molar volume, T is the absolute temperature, R is the universal gas constant, with a and b being species-speciﬁc\\nvan der Waals coefﬁcients. Calculate (i) the pressure of a sample of nitrogen\\nwith molar volume Vm = (2.000 ± 0.003) × 10−4 m3 mol−1 at a temperature\\nof T = 298.0 ± 0.2 K, given the van der Waals coefﬁcients for nitrogen\\nare a = 1.408 × 10−1 m6 mol−2 Pa, and b = 3.913 × 10−5 m3 mol−1 ; (ii) the\\nuncertainty in the pressure. Take R to be 8.3145J K−1 mol−1 .\\n(i) Rearranging eqn (4.12) to make P the subject gives\\nP (Vm , T ) =\\n\\nRT\\na\\n− 2.\\nVm − b\\nVm\\n\\n(4.13)\\n\\nInserting the numbers from the question, and recalling that\\n1 J ≡ 1 m3 Pa, we obtain the best estimate for the pressure of the gas\\n\\x03\\n\\x04\\nP Vm , T = 11.882 MPa.\\nNote we keep ﬁve signiﬁcant ﬁgures at this stage; the number of signiﬁcant ﬁgures we report for the mean is ascertained after the error has\\nbeen calculated.\\n(ii) The uncertainties in both temperature and molar volume contribute to\\nthe\\x03 uncertainty \\x04in the pressure.\\nTo use\\n\\x04 eqn (4.11) we need to evaluate\\n\\x03\\nP Vm + αV , T and P Vm , T + αT . Explicitly, the expressions are:\\n\\x03\\n\\x04\\nP Vm + αV , T =\\n\\nRT\\nVm + αV − b\\n\\n−\\x03\\n\\na\\nVm + αV\\n\\n\\x042 = 11.866 MPa,\\n\\nand\\n\\x03\\n\\n\\x04\\n\\nP Vm , T + αT =\\n\\n\\x03\\n\\x04\\nR T + αT\\nVm − b\\n\\n−\\n\\na\\nVm\\n\\n2\\n\\n= 11.892 MPa.\\n\\nThe contribution\\nto the\\n\\x04 error\\x03 in the\\x04pressure due to the temperature is\\n\\x03\\nα TP = P Vm , T + αT − P Vm , T , and similarly for the contribution\\nto the error due to the volume, α VP . These contributions are evaluated to\\nbe\\nα TP = 0.010 MPa,\\n\\nα VP = 0.016 MPa.\\n\\nAs both contributions are similar, eqn (4.10) is used to ﬁnd the uncertainty in P:\\n\\x17\\n\\x03 T \\x042 \\x03 V \\x042\\nαP =\\nα P + α P = 0.019 MPa.\\n\\n\\x0c4.2 Propagating the error through a multi-', 'variable function 43\\n\\nAs the uncertainties in T and Vm were quoted to one signiﬁcant ﬁgure,\\nwe quote the uncertainty in P to one signiﬁcant ﬁgure: α P = 0.02 MPa.\\nFinally, we decide how many decimal places to retain for the mean, and\\nquote the result as P = 11.88 ± 0.02 MPa.\\n\\n4.2.3\\n\\nA calculus approximation for multi-variable\\nfunctions\\n\\nA calculus-based approximation for the propagation of errors through multivariable functions can be derived by Taylor series expansion4 of the terms\\nin square brackets in eqn (4.11). This procedure yields, for each term in\\neqn (4.11), an expression similar to:\\n\\x02\\n\\x04\\n\\x04\\n\\x03\\n\\x03\\n∂ f \\x02\\x02\\n× αA\\nf Ā + α A , B̄, C̄, . . . = f Ā, B̄, C̄, . . . +\\n∂ A \\x02 A= Ā\\n\\x02\\n1 ∂ 2 f \\x02\\x02\\n+\\n× α 2A + · · ·\\n(4.14)\\n\\x02\\n2 ∂ A2 \\x02\\n\\n4 Taylor’s theorem enables a function to\\n\\nbe expanded in a power series in x in a\\ngiven interval, and states that if f (x) is a\\ncontinuous, single-valued function of x with\\n\\x0e\\n\\x0e\\x0e\\ncontinuous derivatives f (x) , f (x) , . . .\\nin a given interval, then f (x) = f (a) +\\n2 \\x0e\\x0e\\n(x−a) \\x0e\\nf (a) + (x−a)\\nf (x) + · · · .\\n1!\\n2!\\n\\nAn\\nalternative form, as used in the text, may be\\nobtained by changing x to a + x.\\n\\nA= Ā\\n\\nEquation (4.14) contains the function evaluated at the mean, and subsequent\\nterms proportional to the partial derivatives of the function. An implicit\\nassumption of the calculus-based approximation is that the magnitude of the\\nerror is small. Thus, second and higher order derivate terms are negligible compared to the gradient term and consequently are not included. In the derivation\\nof eqn (4.11) we assumed that the variables were independent, thus cross-terms\\n∂2 f\\n× α A α B , average\\ninvolving products of uncertainties in two variables,\\n∂ A∂ B\\nto zero.5\\nEquation (4.14) thus gives the error in the function Z due to deviations in\\nthe variable A:\\n\\x02\\n\\x0e\\n\\x0f\\n\\x03\\n\\x04\\n\\x03\\n\\x04\\n∂ f \\x02\\x02\\nf Ā + α A , B̄, C̄, . . . − f Ā, B̄, C̄, . . . =\\n×\\nα\\n(4.15)\\nA .\\n∂A\\x02\\n\\n5 The cross-terms will be important in con-\\n\\nstructing the covariance matrix in Chapter 7.\\n\\nA= Ā\\n\\nWe recognise this', ' as a combination of the results of eqns (4.5) and (4.7). Hence\\nthe generalisation of eqn (4.7) to obtain an expression for the error in a multivariable function Z = f (A, B, C, . . .) using the calculus approximation is:\\n\\x0e\\n\\x0e\\n\\x0e\\n\\x0f\\n\\x0f\\n\\x0f\\n∂Z 2\\n∂Z 2\\n∂Z 2\\n(α A )2 +\\n(α B )2 +\\n(αC )2 + · · · (4.16)\\n(α Z )2 =\\n∂A\\n∂B\\n∂C\\nEquation (4.16) highlights the fact that the contributions to the total\\nerror from independent variables are summed in quadrature, as depicted\\nin Fig. 4.5.\\n\\n4.2.4\\n\\nA look-up table for multi-variable functions\\n\\nWe can apply the general calculus-based approximation for some common\\nfunctions to produce a look-up table; see Table 4.2.\\n\\nαZ\\n\\n∂Z\\n∂A\\n\\n∂Z α\\nB\\n∂B\\n\\nαA\\n\\nFig. 4.5 As A and B are independent variables their contributions to the error in Z are\\northogonal. The total error in Z is obtained\\nby adding the contributions from A and B in\\nquadrature, subject to Pythagoras’ theorem.\\n\\n\\x0c44\\n\\nError propagation\\nTable 4.2 Some simple rules for the propagation of errors in multi-variable functions.\\nAlways perform a quick check for dominant errors before using these formulae.\\nFunction, Z (A)\\nZ = A+B\\nZ = A−B\\n\\n\\x17\\n(α A )2 + (α B )2\\n\\nαZ\\n=\\nZ\\n\\nZ = An\\n\\n\\x02α \\x02 \\x02 α \\x02\\n\\x02 Z \\x02 \\x02 A\\x02\\n\\x02 = \\x02n\\n\\x02\\n\\x02\\nZ\\nA\\n\\nZ =k\\n\\nA\\nB\\n\\nAn\\nZ =k m\\nB\\nZ = A+ B −C + D\\n\\n\\x1c\\x10\\n\\nα A \\x11 2 \\x10 α B \\x112\\n+\\nA\\nB\\n\\n\\x02α \\x02 \\x02α \\x02\\n\\x02 Z \\x02 \\x02 A\\x02\\nα Z = |k| α A OR \\x02\\n\\x02=\\x02\\n\\x02\\nZ\\nA\\n\\x1c\\x10\\nα A \\x11 2 \\x10 α B \\x112\\nαZ\\n+\\n=\\nZ\\nA\\nB\\n\\x1c\\x10\\nα \\x112 \\x10 α \\x112\\nαZ\\nn A + m B\\n=\\nZ\\nA\\nB\\n\\x17\\nα Z = (α A )2 + (α B )2 + (αC )2 + (α D )2\\n\\nZ=\\n\\n(A × B)\\n(C × D)\\n\\nαZ\\n=\\nZ\\n\\nZ=\\n\\n\\x04\\n\\x03 n\\nA × Bm\\n(C p × D q )\\n\\nαZ\\n=\\nZ\\n\\n4.2.5\\nfor the amplitude-reﬂection coefﬁcient of a\\nwave at a boundary between two media of\\nimpedance A and B.\\n\\nαZ =\\n\\n⎫\\nZ = A×B⎬\\nA\\nZ=\\n⎭\\nB\\n\\nZ = kA\\n\\n6 This is a commonly encountered function\\n\\nExpression used to calculate α Z\\n\\n\\x18\\n\\n\\x1c\\x10\\n\\nα A \\x112 \\x10 α B \\x112 \\x10 αC \\x112 \\x10 α D \\x112\\n+\\n+\\n+\\nA\\nB\\nC\\nD\\n\\n\\x1c\\x10\\n\\nα \\x112 \\x10 α \\x112 \\x10 αC \\x112 \\x10 α D \\x112\\nn A + m B\\n+ p\\n+ q\\nA\\nB\\nC\\nD\\n\\nComparison of methods\\n\\nWe will illustrate the two approaches to the propagation of errors through the\\nmulti-variable function:6\\nZ=\\n\\n(A − B)\\n.\\n(A + B)\\n\\n(4.17)\\n\\nSuppose we have', ' measured\\nand B̄ = 80 both with 1% errors. Our\\n\\x03 Ā = 1000\\n\\x04\\nĀ − B̄\\n\\x04 = 0.852.\\nbest estimate of Z is Z̄ = \\x03\\nĀ + B̄\\n(a) Calculating the error in Z using the calculus approximation: The error\\nin Z is:\\n\\x0e\\n\\x0f2 \\x0e\\n\\x0f2\\n∂Z\\n∂Z\\n2\\n· αA +\\n· αB\\n(α Z ) =\\n∂A\\n∂B\\n\\x0e\\n\\x0f2 \\x0e\\n\\x0f2\\n2B\\n−2A\\n=\\n· αA +\\n· αB .\\n(A + B)2\\n(A + B)2\\n\\n\\x0c4.2 Propagating the error through a multi-variable function 45\\n\\nThis gives, for the error in Z , α Z = 0.00194. As the errors in A and\\nB are only quoted to one signiﬁcant ﬁgure we report that Z = 0.852 ±\\n0.002.\\n(b) Calculating the error in Z using the functional approach:\\n\\x04\\x162 \\x15 \\x03\\n\\x04\\x162\\n\\x15 \\x03\\n\\x04\\n\\x03\\n\\x04\\n\\x03\\n(α Z )2 = f Ā + α A , B̄ − f Ā, B̄ + f Ā, B̄ + α B , − f Ā, B̄ .\\nUsing a spreadsheet to calculate the function at each argument:\\n\\x04\\n\\x04\\n\\x03\\n\\x03\\n\\x04\\n\\x03\\nf Ā, B̄ = 0.8519, f Ā + α A , B̄ = 0.8532, f Ā, B̄ + α B = 0.8505\\nallows the error bar to be found, α Z = 0.00193. As the errors in A and\\nB are only quoted to one signiﬁcant ﬁgure we report that Z = 0.852 ±\\n0.002.\\nThe two methods give identical results. Note also that during any arithmetic calculation it is advisable to reduce the effects of rounding errors by\\nmaintaining a suitable number of signiﬁcant ﬁgures and only rounding to the\\nappropriate number of signiﬁcant ﬁgures at the end.\\n\\n4.2.6\\n\\nPercentage errors—dominant error\\n\\nMany of the expressions for the propagation of errors that arise in Table 4.1 are\\nrepresented by the percentage error. It is frequently possible to bypass the need\\nto use the rigorous expression if one performs a quick back of the envelope\\ncalculation. For example, if Z = A × B × C × D, and A is known to 5%,\\nand B, C and D to 1%, what is the percentage error in Z ? The experienced\\npractitioner will not have to use the appropriate formula from Table 4.2 as the\\naddition of the percentage errors in quadrature will yield, to one signiﬁcant\\nﬁgure, 5%.\\n\\n4.2.7\\n\\nUsing the look-up tables\\n\\nThe look-up tables are ideal for propagating errors in multi-variable functions,\\nparticularly when summation or multiplication are invol', 'ved. For example, the\\nresonant frequency, f 0 , in a circuit with an inductance, L, and capacitance,\\nC, is:\\nf0 =\\n\\n1 1\\n.\\n√\\n2π LC\\n\\n(4.18)\\n\\nThe inductance and its error can be found by measuring the resonant frequency\\nand the capacitance. The error in L can be found directly from the look-up\\ntables:\\n\\x0e\\n\\x0f\\n\\x10 α \\x112 \\x0e α \\x0f2 \\x10 α \\x112\\nα f0 2 \\x10 αC \\x112\\n1\\nf0\\nL\\nC\\n⇒\\n=\\n2\\n+\\n=\\n4\\n+\\n.\\nL=\\nL\\nf0\\nC\\nf0\\nC\\n4π 2 f 02 C\\n(4.19)\\n\\nRULE OF THUMB: Perform a quick calculation to identify any dominant errors. Consider whether a more rigorous calculation is\\nuseful.\\n\\n\\x0c46\\n\\nError propagation\\n\\nNote the factor of 4 in the contribution to the square of the percentage error in\\nthe inductance that arises on account of the inverse-squared dependence on the\\nresonant frequency.\\nOccasionally the function of interest does not appear directly in the\\ntables. Fortunately, the terms in the look-up table are applicable, after\\nsuitable modiﬁcation, to many single-variable functions as well. For\\nexample:\\nZ (A, B) = k A + B,\\n\\n(4.20)\\n\\nwhere k is a constant. We can make the substitution X (A) = k A. Then the\\nfunction Z (A, B) becomes Z = X (A) + B. This functional form can be\\nfound in look-up Table 4.2, giving the error in Z as:\\n\\x17\\nαZ =\\n\\n(α X )2 + (α B )2 .\\n\\n(4.21)\\n\\nWe now need to calculate explicitly α X , which is also in look-up Table 4.2:\\nX (A) = k A ⇒ α X = kα A .\\n\\n(4.22)\\n\\nFinally, we can substitute eqn (4.22) back into eqn (4.21) to ﬁnd the expression\\nfor the error on Z :\\n\\x17\\n(4.23)\\nα Z = k 2 (α A )2 + (α B )2 .\\n\\n4.2.8\\n\\nUsing the look-up tables—health warning\\n\\nIt is important to ensure that the independence of the variables is maintained\\nwhen making a substitution. The look-up tables are only valid for singlevariable functions or variables. Recalling the example of eqn (4.17):\\nZ=\\n\\n( A − B)\\n.\\n(A + B)\\n\\nOne might be tempted to use the look-up tables and make the substitutions\\nX (A, B) = (A − B) and Y (A, B) = ( A + B) such that Z = X/Y . If we then\\nuse the tables to compute the error it comes out to be α Z = 0.012, an order of\\nma', 'gnitude larger than the correct value. This is because X and Y are now no\\nlonger independent variables but are correlated.\\nFig. 4.6 The phase shift, δ, between two sine\\nwaves can be measured using the Lissajous\\nmethod with an oscilloscope. The phase shift\\nis the origin of the ellipticity of the ellipse in\\nthe ﬁgure, and is related to the quantities\\nA\\n\\x10 \\x11\\nand B via the equation δ = arcsin BA .\\n\\nOnly substitute single-variable functions when using the look-up tables.\\nRecall that the look-up tables are only valid for independent variables\\nor single-variable functions.\\n\\n\\x0c4.4 Experimental strategy based on error analysis 47\\n\\n4.3\\n\\nPropagating errors in functions—a\\nsummary\\n\\nIn practice, error analysis is often an exercise that requires different approaches\\nfor different situations. We have detailed above the standard methods, but\\ncommon sense should always be applied. To summarise the above:\\n• For simple functions which involve summation, multiplication and powers the look-up tables are the most convenient method.\\n• The calculus-based approach is only useful if the derivatives are easy to\\ncalculate.\\n• The functional approach, in which the function is calculated for various\\narguments, is particularly suitable for spreadsheet analysis.\\nOften a hybrid approach proves to be the most efﬁcient method for determining the error in a multi-variable function. For example, consider the case\\ndepicted in Fig. 4.6 where the angle δ is deﬁned as the arcsine of the ratio of\\nA and B,\\n\\x0e \\x0f\\nA\\n.\\n(4.24)\\nδ = arcsin\\nB\\nIn this case one could deﬁne a variable C = A/B. Using the look-up tables the\\nerror in C is quickly identiﬁed as:\\n\\x1c\\x10 \\x11\\nα A 2 \\x10 α B \\x112\\n+\\n.\\n(4.25)\\nαC = C\\nA\\nB\\nGiven that C and its error have been determined, the easiest method to\\ncalculate the error in δ is through the functional approach. This method has\\nthe added advantage that, because arcsine is nonlinear, one could calculate the\\nasymmetric error bars if the errors in C were large:\\n\\x02\\n\\x03\\n\\x04\\x02\\n\\x03 \\x04\\n(4.26)\\nαδ± = \\x02arcsin C̄ − arcsin C̄ ± α', 'C \\x02 .\\nSome of the issues regarding error propagation with a nonlinear function\\nare highlighted in Fig. 4.7. Arcsine is a multi-valued function, i.e. there are\\nmany angles whose sine is 0.5. Care has to be exercised in deciding which\\nbranch of the function to choose. Arcsine is an example of a function whose\\nargument has a restricted range; speciﬁcally −1 ≤ C ≤ 1. In Fig. 4.7(b) the\\nargument is small, and eqn (4.26) can be used to calculate the assymetric error\\nbars. In contrast, as depicted in Fig. 4.7(c), if the argument is large it will not\\nbe possible to use eqn (4.26) to calculate αδ+ when C̄ + αC > 1.\\n\\n4.4\\n\\nExperimental strategy based on\\nerror analysis\\n\\nThe uncertainties in A, B, C, etc. can have very different effects on the magnitude of the error in Z depending on its functional form. One should always con-\\n\\nFig. 4.7 (a) As arcsine is a multi-valued\\nfunction, care has to be exercised in deciding which branch of the function to choose.\\nIn addition, the argument of arcsine has the\\nrestricted range −1 ≤ C ≤ 1. In (b) the argument is small, and eqn (4.26) is used to calculate the assymetric error bars. (c) When\\nC̄ + αC > 1 it will not be possible to use\\neqn (4.26) to calculate αδ+ .\\n\\n\\x0c48\\n\\nError propagation\\n\\ncentrate on reducing the dominant error, and not waste time trying to reduce\\nthe error on parameters which do not contribute signiﬁcantly to the error on Z .\\nOne example that is often encountered is when the functional form includes\\nhigh-order powers. For example, the formula for the density, ρ, of a sphere of\\nradius r and mass m is:\\nρ=\\n\\n3m\\nm\\n.\\n=\\nV\\n4πr 3\\n\\n(4.27)\\n\\nThe different dependence on the parameters m and r of the density are shown\\nin Fig. 4.8. Preliminary readings indicate that both the mass and radius were\\ndetermined to a precision of 1%, and the radius to 1%. What should the strategy\\nbe to obtain the most precise measurement of the density?\\nFrom the look-up tables the fractional error in the density is:\\n\\x07\\n\\x1c \\x10 \\x11\\n\\x0e\\n\\x0e\\n\\x0f\\n\\x0f\\nαρ\\nαr 2 \\x10 αm \\x11\\n1 2\\n1\\n+\\n+\\n= 9\\n= 9', '\\n= 3.2%.\\nρ\\nr\\nm\\n100\\n100\\n\\nFig. 4.8 The dependence of density on (a)\\nradius and (b) mass. Owing to the inverse\\ncubed dependence on radius the fractional\\nerror in density is three times larger than the\\nα\\nfractional error in radius: ρρ = 3 αrr . By contrast, the linear dependence on mass means\\nthat the fractional uncertainties are equal:\\nαρ\\nαm\\nρ = m .\\n\\nThe error in the density is therefore dominated by the uncertainty in the\\nradius—ignoring the error in the mass would give a 3% error in the density\\nfrom the uncertainty in the measurement of r alone. The uncertainty in the\\nmass hardly contributes to the error in the density (0.2%), therefore there\\nis little point in measuring it more precisely. Only after the uncertainty in\\nthe radius has been decreased by at least one order of magnitude is it worth\\nreconsidering the contribution from the error in the mass.\\nAnother well-known case where particular care is needed is when the function of interest is the difference in two numbers of similar magnitude. Consider\\ntwo parameters A = 18 ± 2 and B = 19 ± 2. The sum, C = A + B = 37 ± 3,\\nis known to a similar percentage error as either A or B. On the other hand, the\\ndifference D = A − B = −1 ± 3 is poorly deﬁned. Many experiments involve\\nlooking for small differences. One should always be aware that the fractional\\nprecision with which one can determine the difference is no longer trivially\\nrelated to the precision of the individual parameters. A much better strategy\\nis to ﬁnd a physical parameter that is related directly to the difference. For\\nexample, consider the transmission of light through an optically active medium\\n(e.g. sugar solution). One could measure the refractive index of the solution\\nfor right-hand circular polarisation, n R , and then take a second measurement\\nfor left circular light, n L . The degree of optical anisotropy is characterised\\nby the difference, n R − n L , which is generally smaller than either n R or n L .\\nCalculating the optical anisotropy using this m', 'ethod is prone to the large\\npercentage error problem highlighted above. A better experimental technique\\nis to illuminate the solution with plane polarised light. The polarisation axis\\nrotates as the light propagates through the medium. Measuring the rotation\\nangle is a direct measurement of n R − n L and is typically recorded with a\\npercentage error less than 1%.\\nBefore beginning the deﬁnitive data set in an experiment identify the dominant source of error and concentrate your effort in reducing it. Pay particular\\n\\n\\x0c4.5 Combined experiments 49\\n\\nattention when the calculation involves: (i) taking the difference between two\\nnearly equal quantities; (ii) taking the power (>1) of a variable.\\n\\n4.4.1\\n\\nExperimental strategy for reducing\\nthe dominant error\\n\\nThe examples in the previous section highlighted the importance of identifying\\nthe dominant error. If one exists, there are two possible ways of reducing the\\nuncertainty in the dominant error. (1) Persevere with the same apparatus: the\\nstandard deviation of the results is likely to be the same, but the uncertainty\\nin the standard error on the mean will decrease (slowly) as the number of\\nmeasurements is increased. (2) Find a better instrument, or method, to perform the experiment—this will result in the distribution of measurements\\nhaving a smaller standard deviation, and hence a smaller standard error on\\nthe mean.\\n\\n4.5\\n\\nCombined experiments—the weighted mean\\n\\nSuppose that there is a series of experiments, each of which measures the\\nsame parameter. The experiments could be attempting to calculate a particular\\nvariable in a number of different ways, or it could be the same experiment,\\nbut performed by different people. How do we combine all these separate\\nmeasurements to yield the best value and its error? Before discussing how to\\ncombine different results, we ﬁrst give this health warning.\\nWhen taking the weighted mean of a series of measurements, it is important\\nthat the compatibility of the results is considered: Combin', 'e multiple measurements of the same quantity only if they are consistent with each other.\\nConsider outliers with care.\\nFor example, if the result of an experiment to measure the speed\\nof light is c1 = (3.00 ± 0.01) × 108 m s−1 and another technique yields\\nc2 = (4.00 ± 0.02) × 108 m s−1 it is a waste of time to combine these\\nresults as the second value is obviously the subject of systematic\\nerrors.\\nLet the (consistent) results for one experiment be xi ± αi and those of\\nanother be x j ± α j ; see the graphs in Fig. 4.9. If the two results had errors\\nof a similar magnitude the mean of the two readings would be the best estimate of the value, as this accords equal importance to the two experimental\\nvalues:\\n\\x04\\n1\\x03\\n(4.28)\\nxi + x j .\\nx̄i, j =\\n2\\nIt can be shown that the error in the above case is:\\n\\x07\\n1\\n1\\n1\\n\\x03\\n\\x04=\\n+ \\x03 \\x042 .\\n(4.29)\\n2\\nαx̄i, j\\n(αi )\\nαj\\n\\nFig. 4.9 Three circumstances which can\\noccur when combining a pair of measurements. In (a) there is very little overlap\\nbetween the distribution of results—there is\\nno point trying to combine them. A better use\\nof time would be trying to ascertain the origin\\nof the discrepancy between the two sets of\\nmeasurement. In (b) the two measurements\\ncan be combined, to yield a better estimate of\\nthe mean with a smaller uncertainty. In (c) the\\nresults are consistent, but there is little point\\ncombining them as adding the less precise\\nmeasurement will hardly improve the more\\nprecise result.\\n\\n\\x0c50\\n\\nError propagation\\n\\nIn the more general case the error bars are different. Then, in the absence of\\nany systematic error, we would naturally give more credence to the results with\\nthe smaller error. For a range of error values we treat each measurement with\\nan importance, or weight, inversely proportional to the square of its standard\\nerror—in other words, the lower the standard error the more precise the measurement, and the greater its signiﬁcance. One can derive an expression for this\\nweighted mean and its uncertainty (Bevington and Robinson 2003, Chap', 'ter 4).\\nThe best combined estimate, xCE , incorporating all of the available data is the\\nsum of the weighted means, normalised by the sum of the weightings:\\n\\x06\\nwi xi\\n,\\n(4.30)\\nxCE = \\x06i\\ni wi\\nwhere the weighting, wi , is given by:\\nwi =\\n\\n1\\n.\\nαi2\\n\\n(4.31)\\n\\nThe inverse of the square of the standard error of the weighted mean is the sum\\nof the weightings:\\n\\x1d \\x1e\\n\\x05 1\\n1\\n1\\n1\\n1\\n= 2 + 2 + 2 + ··· =\\n.\\n(4.32)\\n2\\nαCE\\nαi\\nαj\\nαk\\nαi2\\ni\\n\\n4.5.1\\n\\nThe error in the mean—a special case of the\\nweighted mean\\n\\nWe can apply the formalism of the previous section to calculate the error in the\\nmean. Consider N measurements of the same quantity, xi , with i = 1, . . . , N .\\nWe can think of each measurement as an estimate of the mean, and the best\\nestimate will be their weighted sum. As there is two-thirds chance that each\\nmeasurement will be within σ of the mean, we can take σ to be the error in one\\nof these measurements. As the error is the same for each xi , each measurement\\ncarries the same weight, and eqn (4.30) becomes:\\n\\x06\\n\\x06\\nwi xi\\nxi\\n= i\\n(4.33)\\n= x.\\nxCE = \\x06i\\nN\\ni wi\\nThis gives the expected result that the combined estimate is the mean of the\\nmeasurements. In a similar manner we can calculate the standard error of the\\nweighted mean to be\\n\\x05\\x0e 1 \\x0f\\nN\\n1\\n=\\n(4.34)\\n= 2.\\n2\\nσ2\\nσ\\nαCE\\ni\\n\\nThis analysis conﬁrms (i) the assertion from Chapter 2 that the standard error\\nσ N −1\\nfor N repeat measurements is α = √ , where we use σ N −1 , the sample\\nN\\nstandard deviation, as our best estimate of the population standard deviation;\\nand (ii) the standard error is equivalent to the standard deviation of the mean.\\n\\n\\x0cExercises\\n\\n51\\n\\nChapter summary\\n• When propagating the error in a measurement of A through a nonlinear\\nfunction, Z = f (A), the uncertainty in Z is a function of both A and\\nits uncertainty, α A .\\n• For a single-variable\\n\\x02 \\x03 function\\n\\x04 the \\x03error\\n\\x04\\x02 in Z for a particular measurement Ā is α Z = \\x02 f Ā + α A − f Ā \\x02.\\n• A calculus-based approximation \\x02for the\\n\\x02 uncertainty propagation for a\\n\\x02 dZ \\x02\\nsingle-variable functi', 'on is α Z = \\x02\\x02 \\x02\\x02 α A .\\ndA\\n• For multi-variable functions the total error in Z is obtained by adding\\nthe components from each variable in quadrature (provided the variables are independent).\\n• The calculus-based approximation for multi-variable functions is\\n\\x0e\\n\\x0e\\n\\x0e\\n\\x0f\\n\\x0f\\n\\x0f\\n∂Z 2\\n∂Z 2\\n∂Z 2\\n(α A )2 +\\n(α B )2 +\\n(αC )2 + · · ·.\\n(α Z )2 =\\n∂A\\n∂B\\n∂C\\n• A hybrid approach which combines the calculus and functional\\napproaches with results from a look-up table often proves to be the most\\nuseful.\\nall of the available\\n• The best combined estimate, xCE , incorporating\\x06\\nwi xi\\n, where the\\ndata is the sum of the weighted means xCE = \\x06i\\ni wi\\n1\\nweighting is wi = 2 ; the inverse of the square of the standard error\\nαi\\n\\x1d \\x1e\\n\\x05 1\\n1\\nof the weighted mean is the sum of the weightings: 2 =\\n.\\nαCE\\nαi2\\ni\\n\\nExercises\\n(4.1) Propagating the error through a single-variable function\\nA variable is measured to be A = 9.274 ± 0.005. Calculate the mean and uncertainties in Z when it is related to\\nA via the following relations: (i) Z = 2A, (ii) Z\\n\\x10 =\\x11 A/2,\\nA2 , (v) Z = arcsin 1 , (vi)\\n,\\n(iv)\\nZ\\n=\\n(iii) Z = A−1\\nA+1\\n\\x11\\n\\x10 A\\x11\\n\\x10 A−2\\n√\\nZ = A, (vii) Z = ln √1 , (viii) Z = exp A2 , (ix)\\nA\\n\\x17\\n1 , (x) Z = 10 A .\\nZ = A+ A\\n(4.2) Propagating the error through a multi-variable function\\nThree variables are measured to be A = 12.3 ±\\n0.4, B = 5.6 ± 0.8 and C = 89.0 ± 0.2. Calculate the mean and uncertainties in Z when it\\n\\nis related to A, B and C via the relations: (i)\\nZ = A + B, (ii) Z = A − B, (iii) Z = A−B\\nA+B , (iv)\\n\\x10 \\x11\\nAB\\nB\\nZ = C , (v) Z = arcsin A , (vi) Z = A × B 2 × C 3 ,\\n(vii) Z = ln\\x10(ABC),\\n(viii) Z = exp (ABC), (ix)\\n\\x11\\nB\\nZ = A + tan C , (x) Z = 10 ABC .\\n(4.3) Comparing methods\\nThe relationship between the period, T , of the oscillation of a spring with a mass M\\x17attached to a spring\\nwith spring constant K is T = 2π M\\nK . In an experiment\\nT and M and their associated uncertainties are measured; show that the equation for the error in K is the\\n\\n\\x0c52\\n\\nError propagation\\nsame using (a) the look-up tables, and (b) the calculus\\nappro', 'ximation.\\n(4.4) Angular dependence of the reﬂection coefﬁcient of light\\nThe intensity reﬂection coefﬁcient, R, for the component\\nof the ﬁeld parallel to the plane of incidence is\\nR=\\n\\ntan2 (θi − θt )\\n,\\ntan2 (θi + θt )\\n\\nwhere θi and θt are the angles of incidence and transmission, respectively. Calculate R and its associated error if\\nθi = (45.0 ± 0.1)◦ and θt = (34.5 ± 0.2)◦ .\\n(4.5) Snell’s law\\nThe angle of refraction θr for a light ray in a medium\\nof refractive index n which is incident from vacuum at\\nan angle θi is obtained from Snell’s law: n sin θr = sin θi .\\nCalculate θr and its associated error if θi = (25.0 ± 0.1)◦\\nand n = 1.54 ± 0.01.\\n(4.6) The Lennard-Jones potential\\nThe Lennard-Jones potential, V (r ), is an effective potential that describes the interaction between two uncharged\\nmolecules or atoms, as a function of their separation r . It\\nis written as\\nB\\nA\\nV (r ) = − 6 + 12 ,\\nr\\nr\\n\\n(4.8) Poiseuille’s method for determining viscosity\\nThe volume ﬂow rate, dV\\ndt , of ﬂuid ﬂowing smoothly\\nthrough a horizontal tube of length L and radius r is\\ngiven by Poiseuille’s equation:\\nπρghr 4\\ndV\\n=\\n,\\ndt\\n8ηL\\nwhere η and ρ are the viscosity and density, respectively,\\nof the ﬂuid, h is the head of pressure across the tube, and\\ng the acceleration due to gravity. In an experiment the\\ngraph of the ﬂow rate versus height has a slope measured\\nto 7%, the length is known to 0.5%, and the radius to\\n8%. What is the fractional precision to which the viscosity is known? If more experimental time is available,\\nshould this be devoted to (i) collecting more ﬂow-rate\\ndata, (ii) mesuring the length, or (iii) the radius of the\\ntube?\\n(4.9) Error spreadsheet for van der Waals calculation\\nConstruct a spreadsheet which has the data from the\\ncalculation in Section 4.2.2. Include cells for: (i) the\\nvariables (molar volume and the absolute temperature),\\n(ii) the uncertainties, and (iii) the universal gas constant\\nas well as the parameters a and b. Verify the numbers obtained in the worked example. Rep', 'eat the calculation for (i) Vm = (2.000 ± 0.003) × 10−3 m3 mol−1\\nand T = 400.0 ± 0.2 K; (ii) Vm = (5.000 ± 0.001) ×\\n10−4 m3 mol−1 and T = 500.0 ± 0.2 K. Repeat the\\ncalculations with the same variables for (a) He with\\na = 3.457 209 × 10−3 m6 mol−2 Pa, and b = 2.37 ×\\n10−5 m3 mol−1 ; (b) CO2 with a = 3.639 594 ×\\n10−1 m6 mol−2 Pa, and b = 4.267 × 10−5 m3 mol−1 ;\\nand (c) Ar with a = 1.362 821 25 × 10−1 m6 mol−2 Pa,\\nand b = 3.219 × 10−5 m3 mol−1 .\\n\\nwhere A and B are positive constants. Experimentally it\\nis easy to measure the two parameters r0 and \\x0f; here r0\\nis the equilibrium separation of the pair, and \\x0f the energy\\nrequired to separate the pair from their equilibrium separation to inﬁnity. Obtain expressions for A and B in terms\\nof r0 and \\x0f. Given that for helium \\x0f = 0.141 × 10−21 J,\\n(4.10) Weighted mean\\nand r0 = 2.87 × 10−10 m, evaluate A and B. If \\x0f can be\\nA group of six students make the following meadetermined to a precision of 1%, and r0 can be detersurements of the speed of light (all ×108 m s−1 ):\\nmined to a precision of 0.5%, to what precision can A\\n3.03 ± 0.04, 2.99 ± 0.03, 2.99 ± 0.02, 3.00 ± 0.05,\\nand B, respectively, be determined?\\n3.05 ± 0.04 and 2.97 ± 0.02. What should the cohort\\n(4.7) Experimental strategy\\nreport as their combined result? If another stuThe resistance R of a cylindrical conductor is propordent then reports c = (3.0 ± 0.3) × 108 m s−1 , is\\nthere any change to the cohort’s combined measuretional to its length, L, and inversely proportional to\\nment? If a further student reports c = (4.01 ± 0.01) ×\\nits cross-sectional area, πr 2 . Which quantity should be\\ndetermined with higher precision, L or r , to optimise the\\n108 m s−1 , is there any change to the cohort’s combined\\nmeasurement?\\ndetermination of R? Explain your reasoning.\\n\\n\\x0cData visualisation\\nand reduction\\nThe graphical representation of data is the most efﬁcient method of reporting experimental measurements in the physical sciences. Graphs are a very\\neffective visual aid, and we make use ', 'of them to (i) highlight trends in, and\\nrelationships among, experimental data, (ii) test theories, (iii) enable comparisons between data sets to be made, (iv) look for evidence of systematic errors\\nand (v) extract additional parameters which characterise the data set. We treat\\neach of these concepts in this chapter, and also emphasise the role graphs can\\nplay with regard to helping to minimise errors.1\\n\\n5.1\\n\\nProducing a good graph\\n\\n5\\n5.1 Producing a good graph\\n\\n53\\n\\n5.2 Using a graph to see trends in\\nthe data\\n\\n57\\n\\n5.3 Method of least squares and\\nmaximum likelihood\\n\\n59\\n\\n5.4 Performing a least-squares ﬁt\\nto a straight line\\n\\n61\\n\\n5.5 Using graphs to estimate\\nrandom and systematic errors\\n\\n62\\n\\n5.6 Residuals\\n\\n63\\n\\nChapter summary\\n\\n64\\n\\nExercises\\n\\n64\\n\\nThe overriding considerations when producing a good graph are simplicity and\\nclarity. To this end there are several conventions that are usually followed. A\\nset of guidelines to follow is provided here, together with a fuller discussion of\\nsome of the points raised.\\n1 Note that we assume here that a suitable\\n\\nGuidelines for plotting data\\n(1) Plot the independent variable on the horizontal axis, and the dependent\\nvariable on the vertical axis.\\n(2) Consider linearising the data to generate a straight-line plot.\\n(3) Use appropriate scales for the axes such that most of the area of the\\ngraph is utilised.\\n(4) Label each axis with the name and units of the variable being plotted.\\n(5) Add data points and error bars, ensuring that they are clear, with\\ndifferent data sets being distinguishable.\\n(6) Add a ﬁt or trend line—either a straight line, a smooth curve to capture\\nthe trend of the data set, or a suitable theoretical model.\\n(7) Add an informative title to lab-book graphs, write a caption for ﬁgures\\nfor publication.\\nA good graph enables the reader to absorb quickly the key points of the data.\\nAs such it needs to be simple, clear and contain all pertinent information. We\\ndistinguish between two instances where graphs are used extensiv', 'ely. Generating a lab-book graph by plotting the experimental data in your lab book as\\n\\ncomputer package is being used to generate\\ngraphs, although most of the advice will also\\nbe relevant for hand-drawn graphs.\\n\\n\\x0c54\\n\\nData visualisation and reduction\\n\\nTable 5.1 Preﬁxes used in the SI\\nsystem. Note that the symbols for\\nfactors which are smaller than 1 are\\nall lower case, and that the symbols\\nfor factors greater than or equal to\\na million are all upper case.\\nFactor\\n\\nPreﬁx\\n\\nSymbol\\n\\n10−24\\n10−21\\n10−18\\n10−15\\n10−12\\n10−9\\n10−6\\n10−3\\n10−2\\n10−1\\n101\\n102\\n103\\n106\\n109\\n1012\\n1015\\n1018\\n1021\\n1024\\n\\nyocto\\nzepto\\natto\\nfemto\\npico\\nnano\\nmicro\\nmilli\\ncenti\\ndeci\\ndeca\\nhecto\\nkilo\\nmega\\ngiga\\ntera\\npeta\\nexa\\nzetta\\nyotta\\n\\ny\\nz\\na\\nf\\np\\nn\\nμ\\nm\\nc\\nd\\nda\\nh\\nk\\nM\\nG\\nT\\nP\\nE\\nZ\\nY\\n\\nyou progress is excellent laboratory practice. The dissemination of the results\\nof an experiment are published either in a report or a scientiﬁc paper. The\\ngraphs which appear as ﬁgures in these documents are presented in a slightly\\ndifferent format from the lab-book graphs and we also include guidelines to\\nproduce graphs for publication.\\n\\n5.1.1\\n\\nThe independent and dependent variables\\n\\nIt is a convention that the data are plotted with the independent variable (the\\nparameter that the experimenter is varying) on the horizontal, or x, axis and the\\ndependent variable (the parameter that is measured) on the vertical, or y, axis.\\nThe x-coordinate is also called the abscissa, and the y-coordinate referred to\\nas the ordinate.\\n\\n5.1.2\\n\\nLinearising the data\\n\\nFor clarity of the graphical representation of data one should always attempt to\\nshow a linear relationship between the dependent and independent variables.\\nThis is because it is much easier to (i) see deviations from a straight line,\\n(ii) ﬁt linear relations and express the relationship between the experimental\\nquantities and those predicted by theory. In particular there exist analytic\\nexpressions for the slope and intercept and their uncertainties for a straight-line\\nﬁt. For example, it is known th', 'at the period,\\n\\x17 T , of a simple pendulum depends\\n\\non the length L via the relation T = 2π Lg , where g is the acceleration due to\\ngravity. Typically one sets the length of the pendulum (the independent variable) and makes multiple measurements of the period (the dependent variable)\\nto give T ± αT . Thus by plotting T 2 on the y-axis versus L on the x-axis we\\nshould get a straight line through the origin, and can extract a value for g and\\nits error from the slope. Note that the conventional terminology is to call this\\nis ‘a graph of T 2 against L’.\\n\\n5.1.3\\n\\nAppropriate scales for the axes\\n\\nIt is important that the range of each axis is independently adjusted such\\nthat the data set is fully encapsulated without large areas of the graph being\\nempty. The default settings in most graphical packages try to achieve this goal;\\nhowever to produce a clear graph the scales may need to be optimised further.\\nA common problem is in deﬁning the minimum value of the axis range—think\\ncarefully whether an axis should start at 0. It is possible to include a smaller\\nﬁgure as an inset to a larger graph if there is plenty of white space available—\\nthis is an efﬁcient way to convey more information in the same space (a vital\\nconsideration when preparing ﬁgures for publication in prestigious journals, or\\nlaboratory reports for assessment when there is a strict page limit).\\n\\n5.1.4\\n\\nLabelling the axes\\n\\nEach axis must be labelled with the variable being plotted (either the name, or\\nthe accepted symbol) and units. There are two extensively used conventions\\n\\n\\x0c5.1 Producing a good graph 55\\n\\nas to how units are included: one can either (i) write the unit in parentheses\\nafter the variable, e.g. displacement (m); or (ii) the unit can be separated from\\nthe quantity with a solidus (/), e.g. displacement/m. Use SI units wherever\\npossible. When plotting data the use of arbitrary units should be avoided as\\nmuch as possible; if this is impossible the correct terminology to label the\\naxis is (arbitrary un', 'it) not (a.u.) as this can be confused with, for example,\\nastronomical unit or atomic unit. To improve the clarity of a graph, use of\\nexponential notation or numbers containing many decimal places should be\\navoided. This can be achieved by using appropriate multipliers and preﬁxes.\\nThe standard factors range from 10−24 to 1024 and are listed in Table 5.1; for\\nexample 0.000 005 A and 5E − 6 A both become 5 μA.\\nMany different data sets can be plotted simultaneously on one graph in order\\nto establish trends among different parameters, see Fig. 5.1 for an example\\nof current–voltage characteristics for three different semiconductor diodes.\\nWhen plotting multiple data sets on a single graph different and distinguishable\\nsymbols should be used for distinct sets. An explanation of which symbol\\nrepresents which data set can either be added as an inset to the graph, or\\nexplained clearly in the caption as is demonstrated in the caption of Fig. 5.1\\n(some journals will specify a preference). The information from the caption\\nof Fig. 5.1 could also be conveyed by the sentence ‘the open squares are for\\ngermanium, the open circles for silicon, and the solid stars for the zener diode’.\\n\\n5.1.5\\n\\nFig. 5.1 Combining many different data sets\\non one graph. The forward-bias current–\\nvoltage characteristics of a silicon (◦),\\ngermanium (\\x02) and zener (\\x11) diode are\\ndepicted. A logarithmic scale was chosen\\nfor the current to emphasise the exponential\\ngrowth of the current with increasing voltage.\\n\\nAdding data points and error bars to graphs\\n\\nExperimental data are plotted as discrete points using a common symbol for\\na single data set. Most graphical plotting packages have built-in symbols that\\nare distinct, scalable and easily distinguishable. The symbol size should be\\nadjusted for maximum clarity. When the number of data points is large, such\\nas occurs with computer-recorded spectra, it may be more appropriate to plot\\nthe data as continuous lines without a symbol as even the smallest symbols\\nwou', 'ld overlap and obscure the underlying trend. If plotting several of these\\ndata sets on a single graph it may be useful to plot a subset of the points on the\\ncurves to differentiate between the different data sets and enhance the clarity\\nof the ﬁgure. As in Fig. 5.1 a common and unique symbol should be used\\nfor each different data set. For lab-book graphs it is important that a legend\\ndetailing the different data sets plotted is included within the area of the graph;\\npublication graphs would have this information either within the area of the\\ngraph, or in a detailed caption under the ﬁgure.\\nThe coordinates of a data point on a graph are our best estimate (i.e. the\\nmean) of the independent and dependent variables. There is an uncertainty\\nassociated with these mean values and a graph needs to reﬂect this. In Chapter 2 we showed how the standard error of the mean, α, is calculated for single\\nvariables, and in Chapter 4 how these could be propagated through various\\nfunctions. We represent the ﬁnal error in both the abscissa and ordinate as an\\nerror bar which is the two-thirds\\nconﬁdence\\nlimit\\nthat the measured value,\\n\\x04\\n\\x03\\n\\x03\\n+\\x04\\nto\\n,\\nas\\nshown in Fig. 5.2. To\\nZ , lies within the range Z − α −\\nZ\\n+\\nα\\nZ\\nZ\\nproduce a straight-line graph, we often process the data. In this case, although\\nthe uncertainty in the original measurements might be equal and symmetric,\\n\\nFig. 5.2 Error bars are added to points on a\\ngraph to indicate the 68% conﬁdence limits. The Gaussian distributions shown in (a)\\nrepresent the probability distribution function\\nfor the mean value, and we expect 68% of\\nthe points to be within one standard error of\\nthe mean of this value. In (b) we represent\\nthe same information as in (a), but plot error\\nbars with a magnitude of one standard deviation of the distributions shown in (a).\\n\\n\\x0c56\\n\\nData visualisation and reduction\\n\\nFig. 5.3 The number of atoms (in millions)\\nand the lifetime of the atoms in a magnetooptical trap are displayed as a function of\\nthe dispenser current. B', 'y plotting both dependent variables simultaneously the trade-off\\nbetween a high number of atoms and long\\nlifetime is evident. The smooth curve is a\\nguide to the eye.\\n\\nby propagating through a nonlinear function the uncertainties vary from point\\nto point and may also be asymmetric. In general, the fractional errors on the\\ndependent variable should be larger than those of the independent variable—\\nthe analysis in subsequent chapters assumes that this is the case. A discussion\\nof how to proceed when both variables contain errors is given in Chapter 9.\\nIf the error bars are not larger on the vertical axis than those on the horizontal\\naxis consider revising the experimental strategy.\\nHorizontal and vertical error bars should be plotted as long as they do not\\nobscure the clarity of the graph. A common issue is when the size of the symbol\\nused to plot the data is larger than the size of the error bar. In this case, consider\\nreducing the size of the symbol within the constraint of graph clarity. If the\\nmeasurements are precise the error bars may be too small to be seen, as occurs\\nin Fig. 5.10 below. This should be noted in the ﬁgure caption on published\\ngraphs and included as an annotation in lab-book graphs. If the trend in the\\ndata is clear as there are many data points, it may reduce the clarity of the\\ngraph to add every error bar. Representative error bars can be added to a small\\nsubset of the data in this case.\\nPlotting error bars\\nThe uncertainty in a quantity is represented\\nusing error bars. The\\n\\x04 graphically\\n\\x03\\n\\x03\\n+\\x04\\nZ\\n+\\nα\\nand\\nerror bars are drawn between Z − α −\\nZ\\nZ , where α Z is the\\nstandard \\x10error. √\\nFor \\x11\\nPoisson\\nwith\\nN\\ncounts\\nthe\\nerror bar is drawn\\n\\x10 statistics\\n\\x11\\n√\\nbetween N − N and N + N .\\n\\nFig. 5.4 The intensity of X-rays transmitted\\nas a function of the slit width.\\n\\nThere are circumstances in which two dependent variables are measured\\nfor each value of the independent variable. In such a situation it is possible\\nto draw a graph with two y-axes, provided a sufﬁ', 'cient level of clarity is\\nmaintained. Figure 5.3 shows an example of data obtained for the number and\\nlifetime of cold atoms in a trap as a function of the current passed through the\\natom dispenser. It is crucial to indicate clearly which data set is associated\\nwith which axis. A smooth curve can be added to emphasise the trend in\\nthe data where there is no particular theoretical model, with an explanation\\nin the caption that the curve is a guide to the eye.\\n\\n5.1.6\\n\\nAdding a ﬁt or trend line\\n\\nThere are three types of ﬁt, or trend line, which we can add to a graph. (1)\\nIf a visual inspection of the graph conﬁrms a linear dependence, we add a\\nlinear trend line. This topic is discussed in detail in Section 5.2.1. (2) There\\nare occasions when the theoretical model cannot be linearised. For such a case\\nthe appropriate nonlinear function can be added to the graph. The relevant\\nparameters are initially chosen, by eye, to capture the trend of the data. There\\nwill be an extensive discussion in Chapters 6 and 7 of how to optimise the\\nparameters and evaluate their uncertainties. (3) In circumstances where there\\nis no theoretical prediction of the relationship between the dependent and\\n\\n\\x0c5.2 Using a graph to see trends in the data 57\\n\\nindependent variable one can add a smooth curve to guide the eye. The caption\\nshould clearly state that the smooth curve is a guide to the eye, and not a\\ntheoretical prediction.\\n\\n5.1.7\\n\\nAdding a title or caption\\n\\nFor a lab-book graph an informative title should be included. Graphs for a\\npublication would have this information in a detailed caption under the ﬁgure.\\nGraphs in this book have captions, not titles. To improve clarity, the use of\\nshading, coloured backgrounds and grid lines should be avoided.\\n\\n5.2\\n\\nUsing a graph to see trends in the data\\n\\nIt is far easier to see trends in a data set from a graph rather than the raw\\ndata—this is why it is important to plot graphs as data are being collected.\\nConsider the data shown in Fig. 5.4 which show', 's the intensity of X-rays\\ntransmitted as a function of the slit width. The graph allows us to deduce\\nthat (a) for widths smaller than approximately 0.25 mm an increase in slit\\nwidth has a concomitant increase in transmitted X-ray intensity: (b) for widths\\ngreater than approximately 0.25 mm the X-ray intensity is largely independent\\nof width. Both of these statements can be put on a more quantitative footing\\nlater, but the graphical representation of the data allows us to draw preliminary\\nconclusions rapidly.\\nIn Fig. 5.5(a) the number of laser-cooled Cs atoms in a magneto-optic trap\\nis plotted as a function of time, showing a monotonic decrease. Theoretical\\nconsiderations lead us to believe that the dependence might be an exponential\\ndecay, which motivated plotting the natural logarithm of the atom number, as\\nshown in parts (b) (using a logarithmic scale) and in part (c) by evaluating\\nthe logarithm of the dependent variable. For the logarithmic plots we see that\\nthere are two different straight lines: the ﬁrst is associated with a time constant\\nof τ = 8.67 ± 0.04 s, and the second with a time constant of τ = 67 ± 4 s.\\nFurther theoretical analysis leads us to believe that the former is associated\\nwith light-assisted collisions, and the latter with collisions with background gas\\nmolecules. Most of this information was gleaned rapidly through plotting the\\nappropriate graph. It is possible to extract values for the two decay constants\\nand their uncertainties from the straight-line ﬁts to such a trace; it is also\\npossible by repeating the experiment many times to obtain many readings of\\nthe time constants, and the results of Section 4.5 can be used to combine these\\nindependent measurements.\\n\\n5.2.1\\n\\nAdding a linear trend line\\n\\nExperiments are often designed such that the dependent variable exhibits a\\nlinear dependence on the independent variable. There are simple analytic\\nresults for calculating the best-ﬁt straight line for a data set with constant error\\nbars on the verti', 'cal axis (we will discuss in more detail in the next section,\\nand extensively in later chapters, what exactly we mean by ‘best ﬁt’). Most\\n\\nFig. 5.5 The number of atoms in a trap as a\\nfunction of time. In (a) the number is plotted against time, in (b) a logarithmic scale\\nis chosen for the y-axis, and in (c) the natural logarithm of the atom numbers is plotted against time for every third point shown\\nin (a) and (b).\\n\\n\\x0c58\\n\\nData visualisation and reduction\\n\\n2 We assume that a computer plotting package\\n\\nis being used to add the trend line, therefore\\nwe will not give advice about using a clear\\nplastic ruler, using a sharp pencil, etc. which\\nis relevant for a hand-drawn graph.\\n\\ngraphical packages and spreadsheets allow you to add a linear trend line, which\\nis the calculated best-ﬁt straight line to the data.2\\nAs was discussed in Section 5.1.5 the error bars on the y-axis of a graph\\nrepresent the 68% conﬁdence limit for the value of the ordinate. If we assume\\nthat the best-ﬁt straight line is a good description of the data, we would\\ntherefore expect that the line intersects two-thirds of the measurements within\\ntheir error bar.\\nFor a good ﬁt we expect two-thirds of the data points to be within one\\nstandard error bar of the trend line.\\n\\n3 In Chapter 7 we will argue that the correla-\\n\\ntion coefﬁcient should also be reported for a\\nstraight-line ﬁt.\\n\\nThere are two obvious reasons why the fraction of points which are consistent with the line of best ﬁt may be signiﬁcantly different from this: (i) the\\nerror bars have been overestimated; and (ii) the assumed linearity of the best\\nﬁt is not valid. A thorough discussion of whether a model (be it a linear ﬁt or\\notherwise) describes a data set is reserved until Chapter 8.\\nIf approximately two-thirds of the data points intersect the linear trend line,\\nthe data are well modelled by a straight line y = mx + c, and it is appropriate\\nto extract four important parameters—these are the gradient, m, and intercept,\\nc, and their associated erro', 'rs.3 Using a process known as the method of least\\nsquares (to be discussed in the next section) one can derive analytic expressions for the gradient and its uncertainty and the intercept and its uncertainty\\n(Taylor 1997, pp. 182–8, or Barford 1985, Section 3.3). The results are:\\n\\x06 \\x06\\n\\x06 2\\x06\\ni xi\\ni yi −\\ni xi\\ni x i yi\\n,\\n(5.1)\\nc=\\n\\x12\\nand\\nm=\\n\\nN\\n\\n\\x06\\ni\\n\\n\\x06 \\x06\\nxi yi − i xi i yi\\n,\\n\\x12\\n\\n(5.2)\\n\\nwith the error in the intercept,\\n\\x07\\n\\n\\x06\\n\\nxi2\\n,\\n\\x12\\n\\n(5.3)\\n\\nN\\n,\\n\\x12\\n\\n(5.4)\\n\\ni\\n\\nαc = αCU\\nand the error in the gradient,\\n\\x1c\\n4 With a carefully constructed spreadsheet\\n\\x06 2 \\x06\\n\\x06\\n\\x06\\nthe terms\\ni xi ,\\ni xi ,\\ni yi ,\\ni xi yi ,\\n\\x06\\nand i (yi − mxi − c)2 for the evaluation\\n\\nof eqns (5.1)–(5.6) are easily determined.\\nNote also that many spreadsheets and software packages have in-built functions which\\nperform these summations.\\n\\nαm = αCU\\nwhere4\\n\\x12=N\\n\\n\\x05\\n\\n\\x1d\\nxi2 −\\n\\ni\\n\\n\\x05\\n\\n\\x1e2\\nxi\\n\\n,\\n\\n(5.5)\\n\\ni\\n\\nand the so-called common uncertainty αCU is deﬁned as\\n\\x07\\n1 \\x05\\nαCU =\\n(yi − mxi − c)2 .\\nN −2\\ni\\n\\n(5.6)\\n\\n\\x0c5.3 Method of least squares and maximum likelihood 59\\n\\nThe common uncertainty will be discussed in greater detail in Chapter 8—\\nessentially it represents an approximation to the magnitude of the uncertainty\\nin the y measurements, assumed to be common to all data points, assuming\\nthat the straight line is the appropriate theoretical model to describe the data.\\nNote that the gradient and intercept are parameters and should be quoted\\nusing the ﬁve golden rules introduced at the end of Chapter 2. Note also\\nthat quoting the slope and intercept is an example of data reduction. In the\\nsame way that we introduced three numbers (the mean, standard deviation and\\nstandard error) to summarise the information contained within N data points,\\nthe four numbers (slope, intercept and their uncertainties) are an attempt to\\nsummarise the information from N data pairs.\\n\\n5.2.2\\n\\nInterpolating, extrapolating and aliasing\\n\\nBy adding a trend line to a discrete data set we have some conﬁdence in an\\nunderlying model. However, we must be very careful in over-interpreti', 'ng the\\ndata, as, at a fundamental level, all we have are our pairs of discrete measurements of the dependent and independent variables, and their uncertainties.\\nThe process of using the straight line (or any other smooth-curve ﬁt to a data\\nset) to infer a value of the dependent variable for a value of the independent\\nvariable between two measured values is called interpolating and is shown in\\nFig. 5.6. The process of predicting a value for the dependent variable when the\\nindependent variable is outside the measured range is called extrapolating;\\nboth processes should be used with caution. There are many examples of\\nphysical phenomena where the linear dependence exhibited for small values of\\nthe independent variable breaks down at higher values: for example, a spring\\nshows a linear extension as a function of the applied force only up to the elastic\\nlimit; the number of atoms or molecules in an excited state increases linearly\\nwith laser intensity initially, but saturates at higher intensities.\\nIf the values chosen for the independent variable are periodic it is possible to suffer from the problem of aliasing. For example, if voltages\\nin an a.c. electrical circuit are sampled at times t = 0, 1, 2, . . . seconds,\\nthe three waveforms V1 (t) = 5 volts, V2 (t) = 5 cos (2π × t) volts, and\\nV3 (t) = 5 cos (2π × 3t) volts will all give identical results; the timedependent functions are said to alias the constant. If measurements of temperature which are evenly spaced in time give the results 21.1◦ C, 21.1◦ C, 21.2◦ C,\\n21.3◦ C and 21.4◦ C, what temperature might we expect half-way between the\\nlast two measurements? We could ﬁt a straight line, or a higher order polynomial, to aid with the interpolation. However, if we learn that the measurements\\nwere of the temperature in a particular city at midday, the measurements will\\nbe useless for predicting the temperature at midnight.\\n\\n5.3\\n\\nIntroduction to the method of least squares\\nand maximum likelihood\\n\\nMost straight-line graphs we', ' draw have a large number of data pairs, and we\\nwish to learn about the slope and intercept. The situation under consideration\\n\\nFig. 5.6 Five tabulated values of the viscosity of an aqueous glycerol solution as a function of the percentage of glycerine are plotted\\n(solid dots). It is reasonable to expect the\\nviscosity to vary smoothly as a function of\\nthe percentage of glycerine; thus one can\\ninterpolate to estimate the viscosity at values other than the tabulated ones. The open\\ncircles show the results of a linear interpolation between successive points for 5, 15 and\\n25% glycerine. A higher-order polynomial ﬁt\\ncould also be used if required.\\n\\n\\x0c60\\n\\nData visualisation and reduction\\n\\nFig. 5.7 The residual of a data point is\\ndeﬁned as the measured value, yi , minus\\nthe theoretical y-value for that x-value. In\\nthe method of least squares the sum of the\\nsquares of the residuals is minimised by\\nchanging the value of the slope and intercept\\nof the ﬁtted line.\\n\\nis one that mathematicians call overdetermined, i.e. we have more equations\\nthan unknowns. To extract two parameters (slope and gradient) is obviously\\nimpossible with one data point; we could solve for both m and c (with no\\nuncertainty) if we had two exact pairs of data (x1 , y1 ) and (x2 , y2 ). The situation we face is very different: we typically have far more than two data points,\\nbut the experimental values are subject to random statistical ﬂuctuations. We\\ntherefore perform what is known as regression analysis, where the goal is\\nto determine the optimal values of parameters for a function (a straight line\\nin the present case) that lead to the function having the best ﬁt to the set of\\nexperimental data.\\nThe best-ﬁt straight line is deﬁned as the line which is in closest proximity\\nto as many of the data points as possible. If the coordinates of the i th data\\npoint are (xi , yi ) and the line of best ﬁt is of the form y = mx + c, then\\nthe y-coordinate of the best-ﬁt line at xi is y = mxi + c. If we have selected\\nap', 'propriate values of m and c, then the difference (yi − y) will be small—\\nthis difference between the experimentally measured value of the dependent\\nvariable and the theoretical prediction is called the residual. The deﬁnition\\nof the residual is shown schematically in Fig. 5.7. We cannot simply obtain\\nthe best-ﬁt line by minimising the difference, (yi − y), for all data points as\\nsometimes the residual will be negative, and sometimes positive (Fig. 5.7).\\nInstead, we must consider a quantity which is always positive. One approach\\nis to minimise the modulus of the difference, |yi − y|; an alternative, and\\nwidespread, approach is to minimise the square of the difference, (yi − y)2 ,\\nwhich is also always positive. In the method of least squares one seeks to\\nminimise the sum of the squares of the residuals. By deﬁnition, therefore, the\\nbest values of m and c will be those in which the squares of the differences\\nsummed for all data points is minimised. The method of least squares can\\nbe derived from the formalism of maximum likelihood in conjunction with\\nthe central limit theorem (see Section 3.5), which motivates the statement that\\neach data point that we measure, yi , is drawn from a Gaussian distribution\\nwith a width given by the standard error, αi . The link between the Gaussian\\ndistribution and the error bar was highlighted in Fig. 5.2.\\nThe y-coordinate of the line of best ﬁt at xi , y (xi ), is the most probable\\nvalue of the mean of the parent distribution. We can use the parent distribution\\nto calculate the probability of obtaining the value yi , given the parameters m\\nand c, which is proportional to the value of the probability density function at\\nyi . The assumption that we make is that the parent distribution is described by\\nthe Gaussian probability density function given in Section 3.2, eqn (3.7):\\n1\\n(yi − mxi − c)2\\nexp −\\ndyi .\\nPi = G i dyi = √\\n2αi2\\n2π αi\\n\\n(5.7)\\n\\nThe total probability that we obtain our observed set of N measurements\\ngiven m and c is the product ', 'of the probabilities for each individual\\nmeasurement:\\n\\x0e\\n\\x0f\\n\\x1f dyi\\n\\x1f\\n1 \\x05 yi − mxi − c 2\\nPi =\\nexp −\\n. (5.8)\\nP (m, c) =\\n√\\n2\\nαi\\n2π αi\\ni\\n\\ni\\n\\ni\\n\\n\\x0c5.4 Performing a least-squares ﬁt to a straight line 61\\n\\nIn eqn (5.8) we think of the values of yi , αi and xi as being ﬁxed once the\\nexperiment is complete, and of m and c as variables whose values can be chosen to maximise the probability, P (m, c)—which occurs when the line of best\\nﬁt is as close as possible to the data points. The analytic solutions to the line\\nof best ﬁt presented in eqns (5.1)–(5.6) were found by differentiating P (m, c)\\nwith respect to m and c and setting the result to zero, for the special case of\\nall the uncertainties αi being equal. In eqn (5.8) the pre-factor is independent\\nof m and c and the probability is maximised when the summation term in the\\nargument of the exponent is minimised. The probability is maximised when\\nthe goodness-of-ﬁt parameter, χ 2 , is minimised. We have deﬁned χ 2 as:\\n\\x0e\\n\\x0f\\nyi − y (xi ) 2\\n2\\n.\\n(5.9)\\nχ =\\nαi\\nWhen the error bars, αi , are constant they do not inﬂuence the values\\nof the best-ﬁt intercept, gradient or their associated errors. We shall see\\nin Chapter 6 that, in general, to ﬁnd the line of best ﬁt we vary the\\nparameters m and c to minimise the weighted sum of the square of the\\ndeviations, χ 2 .\\n\\n5.3.1\\n\\nExample using the method of least squares\\n\\nAs a simple example, consider the case shown in Fig. 5.8. The data points\\nobviously show a linear trend through the origin. In this, rather contrived,\\nexample we know that y = mx. But how do we arrive at the best value for\\nm? One method is to try many different values of m until we see that the\\nhypothesised model goes through our data points (Fig. 5.8a). By such a method\\nit becomes obvious that the best line is y = 2x.\\nAlternatively, we can arrive\\x06at the same result by minimising the sum of\\nthe squares of the residuals, i (yi − y)2 . The best-ﬁt line will be the one\\nwith the value of m for which the sum\\n\\x06of the squares of the residua', 'ls is a\\nminimum. By inspection of the plot of i (yi − y)2 against m (Fig. 5.8b) we\\nsee the well-deﬁned minimum (in this case zero) corresponding to the best ﬁt\\nwith\\n\\x06m = 2. Obviously, with genuine experimental data, the minimum value\\nof i (yi − y)2 will never be zero for two reasons: (i) the inevitable statistical\\nﬂuctuations associated with the data, and (ii) the hypothesised model (a straight\\nline in this case) might not be an appropriate description of the data over the\\nentire range.\\n\\n5.4\\n\\nPerforming a least-squares ﬁt\\nto a straight line\\n\\nThere are three methods for obtaining the best-ﬁt straight line parameters\\nfor a given a data set. Firstly, the analytic functions of eqns (5.1)–(5.6)\\ncan be used to determine both the value and uncertainty of the slope and\\nintercept. The terms to be evaluated within these equations are commonly\\nfound on scientiﬁc calculators and spreadsheet analysis packages. Secondly,\\n\\nFig. 5.8 The evolution of the goodness-ofﬁt parameter with the gradient, m. The open\\npoints in (b) correspond to the lines shown\\nin (a).\\n\\n\\x0c62\\n\\nData visualisation and reduction\\n\\nFig. 5.10 Data from three experiments used to determine the value of a resistor. Error bars too small to be seen. In (a) a correctly calibrated\\nvoltmeter and ammeter were used giving a ﬁtted gradient of 200 ± 2 k and an intercept, consistent with Ohm’s law, of 0.0 ± 0.1 V. In (b) the\\ndata are recorded with an ammeter with a zero error. The gradient remains the same as (a), but the intercept is −0.26 ± 0.06 V. In (c) the voltmeter\\nhas a calibration error—again the gradient remains the same as in (a) with an intercept of 10.09 ± 0.09 mV. In both (b) and (c) the intercept is not\\nconsistent with Ohm’s law and indicates a systematic error. Note the axes scales have been set to be the same for these three graphs to highlight the\\ndifferences between the curves.\\n\\nFig. 5.9 The least-squares best-ﬁt straight\\nline to a sinusoidal variation. Error bars\\nsmaller than symbol size. Health warning It\\nis p', 'ossible to use the method of least squares\\nto ﬁnd the ‘best-ﬁt’ straight line for any data\\nset. This does not mean that a linear ﬁt is an\\nappropriate theoretical model.\\n\\nany computer ﬁtting/plotting software will have the ability to conduct a leastsquares regression. Finally, one could construct the appropriate terms within\\na spreadsheet and use the in-built minimisation routine. The last method\\nmay be over-elaborate for this situation; however it is easily generalised\\nto far more complex ﬁtting and analysis, and is used extensively later in\\nthe book.\\nThe method of least squares will always ﬁt a straight line to a data set, but\\ndoes not answer another interesting question, namely ‘are the data consistent\\nwith a straight line?’. One could ‘ﬁt’ a straight line to a data set which exhibits\\nsinusoidal variation, as seen in Fig. 5.9, with obvious ridiculous consequences\\nif one takes the ‘best-ﬁt’ parameters seriously. We postpone until Chapter 8 the\\nmathematically rigorous techniques for giving a quantitative measure for the\\nquality of a ﬁt, but note that, in Fig. 5.9, 68% of the data points do not coincide\\nwith the line of best ﬁt and there would be little point in continuing with an\\nanalysis based on the least-squares best-ﬁt straight line.\\n\\n5.5\\n\\nUsing graphs to estimate random\\nand systematic errors\\n\\nA single pair of measurements of current and voltage through a resistor\\nallows us to calculate an experimental value of the resistance and its error.\\nThis assumes that Ohm’s law is valid for the particular current and voltage\\nparameters used. For example, for a voltage of 6.0 ± 0.1 V and a current of\\n30.0 ± 0.1 μA, we deduce a resistance, R, of 200 ± 3 k . A better experimental strategy is to take a series of measurements for different current–voltage\\npairs, and plot a graph, as shown in Fig. 5.10(a). Any departure from the linear\\ntrend is visually immediately apparent. The best estimate of the resistance\\nis the gradient of the graph, which we can extract by ﬁtting a least', '-squares\\n\\n\\x0c5.6 Residuals 63\\n\\nstraight line. By collecting more data the statistical error in the resistance will\\nbe reduced.\\nImagine the meter we use to measure the current has a systematic error,\\nand each of the current values is systematically too high by 2μA. The singlepoint measurement of 6.0 ± 0.1 V and a current of 32.0 ± 0.1 μA, yields a\\nresistance of 188 ± 3 k , which is incorrect. However, by plotting the graph\\nthe fact that all of the data points are systematically displaced will have\\nno bearing on the slope of the graph, and hence our determination of the\\nresistance; see Fig. 5.10(b). Similarly, a systematic offset on all of the voltage\\nreadings will give an incorrect single-point measurement, but the slope of the\\ngraph will be correct, as in Fig. 5.10(c). Thus a whole class of systematic\\nerrors can be negated by plotting a graph. In both of these cases, the intercepts are not consistent with zero—a sign of the presence of a systematic\\nerror.\\n\\n5.6\\n\\nResiduals\\n\\nThe best-ﬁt line in Fig. 5.9 is clearly not a good description of the data. Here\\nwe introduce the idea of performing a preliminary test of the quality of the ﬁt\\nfrom the best-ﬁt straight line. Based on the ideas discussed in Section 5.3 and\\nChapter 3 we would only expect two-thirds of the data points to lie on the bestﬁt line, within their error bars. Therefore a quick visual inspection of a line of\\nbest ﬁt to a graph should be performed; approximately two-thirds of the data\\npoints should be consistent with the line, and approximately half of the other\\npoints should lie above the line, approximately half below.\\nIt is very useful to plot the residuals Ri = yi − y (xi ). If the data are consistent with a straight line, the residuals should have a mean of zero and show no\\nobvious structure. If there are many data points, a histogram of the residuals\\ncan be plotted. One would expect to see a Gaussian distribution centred on\\nzero. The power of plotting the residuals is evident in the two graphs of\\nFig. 5.', '11. A quick visual inspection in both cases indicates that a linear model\\n\\nFig. 5.11 Data sets with a linear ﬁt. The error\\nbars are too small to be seen. In both cases, a\\nquick visual inspection suggests a good ﬁt.\\nHowever, a plot of the residuals shows structure. In (a) we clearly see that a quadratic\\nterms needs to be incorporated into the model\\nof our data and in (b) a sinusoidal variation\\nshould be included.\\n\\n\\x0c64\\n\\nData visualisation and reduction\\n\\nseems a good ﬁt; however, in both cases, the residuals clearly indicate that\\nhigher order terms have to be included in the model.\\n\\nChapter summary\\n• The overriding considerations when producing a good graph are simplicity and clarity.\\n• The error bar on a point on a graph is the two-thirds conﬁdence\\nlimit.\\n\\x04\\n\\x03\\n\\x03\\n+\\x04\\n• The error bar is drawn between Z − α −\\nZ and Z + α Z , where α is\\nthe standard error (standard deviation of the mean).\\n• For\\nstatistics\\nN counts the error bar is drawn between\\n\\x10 with\\n\\x10 Poisson\\n√ \\x11\\n√ \\x11\\nN − N and N + N .\\n• The method of least squares can be used to deduce the best-ﬁt parameters for linear regression y = mx + c where the data have constant\\nerror bars.\\n• The best estimate of the intercept and slope are\\n\\x06 \\x06\\n\\x06 2\\x06\\ni xi\\ni yi −\\ni xi\\ni x i yi\\n, and\\nc=\\n\\x12\\n\\x06 \\x06\\n\\x06\\nN i xi yi − i xi i yi\\nm=\\n,\\n\\x12\\n\\x03\\x06 \\x042\\n\\x06\\nwhere \\x12 = N i xi2 −\\ni xi .\\n• The best estimate of the error in the intercept and slope are\\n\\x07\\x06\\n\\x1c\\n2\\nN\\ni xi\\n, and αm = αCU\\n,\\nαc = αCU\\n\\x12\\n\\x12\\n\\x1c\\n1 \\x06\\nwhere αCU =\\n(yi − mxi − c)2 .\\nN −2 i\\n• Having plotted a straight-line graph the residuals should be analysed—\\ntwo-thirds of the data points should be consistent with the line within\\ntheir error bars.\\n\\nExercises\\n(5.1) Geometry of the best-ﬁt straight line\\nShow, using eqns (5.1) and (5.2), that the line of best ﬁt\\ngoes through the point (x, y).\\n(5.2) Linearising functions for plotting\\nHow can the following functions be linearised, suitable\\nfor a straight-line plot? Explain what transformation is\\n\\nneeded for the functions to get them to be of the form\\ny = mx + c. What woul', 'd the slope and intercept of the\\nline be? Take U to be the independent variable, and V\\nthe dependent variable.\\n(i) V = aU 2 ,\\n√\\n(ii) V = a U ,\\n\\n\\x0cExercises\\n(iii) V = a exp (−bU ),\\n(iv) U1 + V1 = a1 .\\n(5.3) Best-ﬁt straight line—an unweighted ﬁt\\nThe data listed below come from an experiment to verify\\nOhm’s law. The voltage across a resistor (the dependent\\nvariable) was measured as a function of the current ﬂowing (the independent variable). The precision of the voltmeter was 0.01 mV, and the uncertainty in the current\\nwas negligible.\\nCurrent (μA)\\nVoltage (mV)\\n\\n10\\n0.98\\n\\n20\\n1.98\\n\\n30\\n2.98\\n\\n40\\n3.97\\n\\nCurrent (μA)\\nVoltage (mV)\\n\\n60\\n5.95\\n\\n70\\n6.93\\n\\n80\\n7.93\\n\\n90\\n8.91\\n\\n50\\n4.95\\n\\n65\\n\\n(i) Use the results of Section 5.2.1 to calculate the\\nunweighted best-ﬁt gradient and intercept, and their\\nuncertainties. (ii) Calculate the common uncertainty,\\nαCU , and compare the value with the experimental uncertainty. (iii) Plot a graph of the data and add the best-ﬁt\\nstraight line. (iv) Calculate the residuals, and comment\\non their magnitudes.\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cLeast-squares ﬁtting of\\ncomplex functions\\nOften the data we wish to plot either have error bars which are not uniform,\\nor the data are described by a function which is not a simple straight line. In\\nboth cases, the graphical representation of the data remains the most efﬁcient\\nmethod of highlighting trends, testing our theories and enabling comparisons\\nbetween data sets to be made. However, if one wishes to ﬁt the data, we need\\nto extend our strategies beyond those discussed in the previous chapter.\\n\\n6.1\\n\\nThe importance of\\n\\nχ2\\n\\nin least-squares ﬁtting\\n\\nThe dimensionless quantity χ 2 deﬁned in Chapter 5 as a goodness-of-ﬁt parameter,\\n\\x05 (yi − y (xi ))2\\n,\\nχ =\\nαi2\\ni\\n2\\n\\n(6.1)\\n\\nis also valid for non-uniform error bars. In Chapter 5 we treated the special\\ncase of the error bars, αi , all being equal and the function y (xi ) being the\\nstraight line y (xi ) = m xi + c. In this chapter we will relax these constraints,\\nand consi', 'der the more general case. First, we will discuss the situation where\\nthe errors are no longer uniform and in the later part of the chapter we will\\nconsider in detail examples of ﬁts to more complex functions. In all cases,\\nthe best-ﬁt parameters remain those for which χ 2 is minimised. Note that,\\nbeing a function of the random variables yi , χ 2 is in turn a random variable with a probability distribution function and we return to this concept in\\nChapter 8.\\nThere are three methods for obtaining the best-ﬁt parameters to a given\\ndata set. Firstly, for some simple theoretical models (such as a straight line\\nor low-order polynomials) analytic functions can be used to determine the\\nvalue of the best-ﬁt parameters such as slope and intercept. However, the\\ntwo disadvantages of this method are that (i) there are no easily accessible\\nclosed-form expressions to calculate the uncertainties in the parameters, and\\n(ii) it is impossible to generalise the analytic results to an arbitrary function.\\nSecondly, most computer-based ﬁtting/plotting software will have the ability\\nto conduct a weighted least-squares regression which will give the best-ﬁt\\nparameters and their associated uncertainties. Finally, one could perform the\\nappropriate analysis in a spreadsheet and use the in-built routine to minimise\\n\\n6\\n6.1 The importance of χ 2 in\\nleast-squares ﬁtting\\n\\n67\\n\\n6.2 Non-uniform error bars\\n\\n68\\n\\n6.3 A least-squares ﬁt to a\\nstraight line\\n\\n69\\n\\n6.4 Performing a weighted\\nleast-squares ﬁt—beyond\\nstraight lines.\\n\\n72\\n\\n6.5 Calculating the errors in a\\nleast-squares ﬁt\\n\\n74\\n\\n6.6 Fitting with constraints\\n\\n79\\n\\n6.7 Testing the ﬁt using the residuals\\n\\n81\\n\\nChapter summary\\n\\n82\\n\\nExercises\\n\\n83\\n\\n\\x0c68\\n\\nLeast-squares ﬁtting of complex functions\\n2 , can then be used\\nχ 2 . For all three cases, the ﬁnal minimised value of χ 2 , χmin\\nto determine the quality of the ﬁt.\\nThere are three related questions when considering the ‘best ﬁt’: (i) are\\nmy data consistent with the proposed model at a particular conﬁdence le', 'vel?\\nAssuming the model is valid, (ii) what are the best-ﬁt parameters of the model?\\nand ﬁnally (iii) what are the uncertainties in these best-ﬁt parameters? The\\nﬁrst question is often the hardest to answer, and we return to it in Chapter 8.\\nThroughout this chapter we implicitly assume that the uncertainties in our data\\nset are Gaussian and that the proposed theoretical model is a valid description\\nof the data. We use the phrase ‘good ﬁt’ for the case where there is agreement\\nbetween our data and the proposed theoretical model.\\n\\n6.1.1\\n\\nχ 2 for data with Poisson errors\\n\\nWhen the sample distribution is a discrete function, i.e. where the experiment\\ninvolves counting, we have seen that the distribution of the measurements is\\ngiven by the Poisson probability\\x12distribution function with a mean count Oi\\nand associated uncertainty αi = Oi (Section 3.4). Here Oi is the observed\\nnumber of counts for the i th interval.\\nFrom the deﬁnition \\x12\\nof χ 2 one may think that for Poisson statistics we\\nshould substitute αi = Oi into eqn (6.1). However the appropriate formula\\nfor χ 2 for Poisson statistics (see Squires 2001, Appendix E, or Taylor 1997,\\nChapter 12) is:\\nχ2 =\\n\\n\\x05 (Oi − E i )2\\n,\\nEi\\n\\n(6.2)\\n\\ni\\n\\nwhere E i is the expected number of counts in the same interval. To ensure that\\nthe χ 2 calculation is not skewed by any asymmetry in the Poisson probability\\ndistribution function for low means, it is important that the data are re-binned\\nsuch that within each re-binned interval the sum of the expected counts is not\\ntoo low; the threshold\\n\\x12 is usually\\n\\x12 set as ﬁve. Note that if we have a good ﬁt, then\\nby deﬁnition, αi = E i ≈ Oi .\\nEquation (6.2) should only be used for Poisson counts, as it is a special case\\nof eqn (6.1). Applying eqn (6.2) to any other situation leads to nonsensical\\nresults because χ 2 will no longer be dimensionless.\\n\\n6.2\\n\\nNon-uniform error bars\\n\\nA sequence of data points with non-uniform error bars is referred to as heteroscedastic. There are many reasons why the data w', 'e obtain and wish to plot\\nmay have error bars which are not uniform; these may include:\\n• The uncertainty in a variable may be intrinsically non-uniform; this\\noccurs with, for example, a Poisson distribution of counts in radioactive\\n\\n\\x0c6.3 A least-squares ﬁt to a straight line\\n\\n69\\n\\ndecay, where the errors decrease as the count rate decreases (although the\\nfractional error increases).\\n• Different numbers of repeat measurements have been taken for each\\nvalue of the independent variable.\\n• Measuring devices may have similar percentage precision for different\\nscale settings. The magnitude of the error bar will then depend on the\\nscale selected. (Multimeters are a common example of this—the precision of the instrument could be 0.1 μA on the 200 μA scale but 0.1 mA\\non the 200 mA scale.)\\n• The process of linearising the data through a nonlinear function will\\nresult in non-uniform error bars for the processed data even when the\\nuncertainty in the raw data is uniform.\\nFigure 6.1 shows four examples of heteroscedastic data sets. In part (a) we\\nsee a data set where the percentage error of the ordinate grows approximately\\nlinearly with the value of the abscissa. Part (b) displays the natural logarithm\\nof the count rate as a function of time for a background-corrected radioactive\\ndecay. There are two factors which lead to the non-uniform error bars here:\\n(i) the inherent nonlinearity of the error in Poisson counts, and (ii) the nonlinearity introduced by propagating the error through the logarithm. A data\\nset to measure the speed of light by measuring a phase shift as a function\\nof separation between source and detector is shown in Fig. 6.1(c). As we\\ndiscussed in Chapter 4, there is an inherent nonlinearity in the error in the\\nphase deduced from the Lissajous method; note that the error is relatively\\nlarge when the phase is close to π/2. The output of a frequency-to-voltage\\nconverter is seen in Fig. 6.1(d), where it is evident that when the frequency\\nis a multiple of the mains fr', 'equency (50 Hz) the signal becomes more\\nnoisy.\\n\\n6.3\\n\\nA least-squares ﬁt to a straight line with\\nnon-uniform error bars\\n\\nIn Chapter 5, Section 5.2.1, we applied the method of least squares to evaluate\\nthe slope and intercept (and their uncertainties) of a straight-line ﬁt to a\\ndata set without taking into account the uncertainties in the measurements.\\nIt is possible to include the uncertainties in the analysis, and in this section we extend the treatment to perform a weighted least-squares ﬁt to the\\nstraight line y (xi ) = m xi + c. The method of least squares can be used to\\ngenerate analytic expressions (Taylor 1997, pp. 201–4, or Press et al. 1992,\\nSection 15.2) for the slope, m, the intercept, c, and their uncertainties αm\\nand αc :\\n\\x06\\n\\x06\\n\\x06\\n\\x06\\nwi xi2 i wi yi − i wi xi i wi xi yi\\n,\\n(6.3)\\nc= i\\n\\x0e\\n\\x12\\nand\\n\\x06\\n\\x06\\n\\x06\\n\\x06\\ni wi\\ni wi x i yi −\\ni wi x i\\ni wi yi\\n,\\n(6.4)\\nm=\\n\\x0e\\n\\x12\\n\\nFig. 6.1 Four examples of heteroscedastic\\ndata sets well-described by a straight line.\\nIn (a) there is a constant percentage error,\\nin (b) Poisson counts of a radioactive decay\\nhave non-uniform error bars. In (c) the large\\nerror bar in phase near π/2 is highlighted\\nwhen using the Lissajous method is highlighted, whereas (d) illustrates the degradation of the signal-to-noise ratio from a\\nfrequency-to-voltage converter near harmonics of the mains frequency.\\n\\n\\x0c70\\n\\nLeast-squares ﬁtting of complex functions\\n\\n1 With a carefully constructed spreadsheet\\nthe terms wi , wi xi , wi xi2 , wi yi , wi xi yi ,\\n\\nwith errors,1\\n\\x07\\n\\ntheir products and summations required for\\nthe evaluation of eqns (6.3)–(6.7) are easily\\ndetermined.\\n\\n\\x06\\ni\\n\\nαc =\\n\\nwi xi2\\n,\\n\\x0e\\n\\x12\\n\\n(6.5)\\n\\nand\\n\\x07\\x06\\nαm =\\n\\ni wi\\n,\\n\\x0e\\n\\x12\\n\\n(6.6)\\n\\nwhere\\n\\x0e\\n\\n\\x12 =\\n\\n\\x05\\ni\\n\\n2 Equations (5.1)–(5.5) in Chapter 5 are a spe-\\n\\ncial case of eqns (6.3)–(6.7) with the weighting, w, being the same for each data point.\\n\\nFig. 6.2 Weighted (solid) and unweighted\\n(dashed) lines of best ﬁt for two of the data\\nsets of Fig. 6.1 Details of the gradients, intercepts and their uncertainties can be found in\\nTable', ' 6.1.\\n\\nwi\\n\\n\\x05\\ni\\n\\n\\x1d\\nwi xi2\\n\\n−\\n\\n\\x05\\n\\n\\x1e2\\nwi xi\\n\\n.\\n\\n(6.7)\\n\\ni\\n\\nThe weighting for each point, from eqn (4.25), is the inverse square of the\\nuncertainty, wi = αi−2 , and the summation is over all the data points.2\\nWe will now illustrate the mathematical results of eqns (6.3)–(6.6) with\\nworked examples from Fig. 6.1 and we will compare the results of the weighted\\nﬁt with the unweighted values obtained in Chapter 5.\\nThere are two ﬁtted lines shown on both graphs in Fig. 6.2. The dashed\\nline is the unweighted least-squares ﬁt. This procedure gives equal weighting\\nto all the data points. When the error bars are not uniform, a better strategy\\nis to give more weighting to the data points with least uncertainty; this is\\ninherent in eqns (6.3)–(6.6). The results of this weighted least-squares ﬁtting\\nare shown as the solid lines in Fig. 6.2. The results of the ﬁts are summarised\\nin Table 6.1.\\nFor graph (a) in Fig. 6.2 the weighted and unweighted ﬁts give very similar gradients, and errors in gradients. Note, however, the order-of-magnitude\\nreduction in the uncertainty in the intercept obtained with the weighted leastsquares ﬁt. The weighted ﬁt gives signiﬁcantly more credence to the data with\\nthe smallest error bars; in this case these are the ones close to the origin, hence\\nthe better estimate of the intercept. For graph (b) in Fig. 6.2 the gradients\\ndetermined by the two methods are distinct—this is a consequence of the\\nweighted ﬁt giving less importance to the two points with large error bars,\\nwhich ‘pull down’ the unweighted line of best ﬁt. We note that the uncertainty\\nin the weighted gradient is also smaller.\\n\\n\\x0c6.3 A least-squares ﬁt to a straight line\\n\\n71\\n\\nTable 6.1 Details of the gradients and intercepts from Fig. 6.2.\\nGraph (a)\\nUnweighted\\n\\nWeighted\\n\\nGraph (b)\\nUnweighted\\n\\nWeighted\\n\\nGradient\\n\\n1.03 ± 0.02\\n\\n1.01 ± 0.01\\n\\n(1.9 ± 0.2) mV/Hz\\n\\n(2.03 ± 0.05) mV/Hz\\n\\nIntercept\\n\\n−0.5 ± 0.9\\n\\n0.01 ± 0.08\\n\\n(0 ± 1) × 10 mV\\n\\n(−1 ± 3) mV\\n\\n6.3.1\\n\\nStrategies for a straight-line ﬁt\\n\\nAn interesting', ' feature of Table 6.1, which contains the least-squares bestﬁt parameters to the data of Fig. 6.2, is the order-of-magnitude reduction in\\nthe error bar for the uncertainty with the weighted ﬁt. There are two broad\\ncategories of experiments in the physical sciences—the ﬁrst seeks to verify the\\nform of a physical law as manifest in a mathematical relation; the second seeks\\nto extract a parameter from a well-known physical law. If the experimenter is\\nperforming the ﬁrst type of experiment, there is no a priori preference for\\nreducing the error bars for particular data points. In contrast, for experiments\\nfor which a linear regression (y(xi ) = mxi + c) will be performed the strategies are clear:\\n(1) If one wishes to know the intercept with great precision, the best strategy\\nis to invest most of your time and effort in reducing the error bars on the\\npoints close to the y-axis. Reducing the error bars on points which are\\nfar removed from the intercept will hardly alter the magnitude of the\\nerror in the intercept (Fig. 6.1a and b).\\n(2) If one wishes to know the gradient with great precision, the experimenter should devote most time and effort in reducing the size of the\\nerror bars for two points at the extrema of the data set—i.e. the data\\npoint with the smallest x-value, and the one with the largest x-value. A\\nmore robust measurement will be obtained if the data are recorded over\\nas large a range as can be realised with the experimental apparatus or\\nfor which the theory is valid. Again, it is a waste of resource to measure\\npoints in the middle of the range of x values as they will hardly inﬂuence\\nthe error on the gradient (Fig. 6.1c).\\nThese points are further illustrated in Fig. 6.3, which shows four computergenerated heteroscedastic data sets. In parts (a)–(c) the points close to the yaxis have a small error bar, consequently the error in the intercept is small.\\nIn part (d), by contrast, the points close to the y-axis have large error bars,\\nleading to a corresponding in', 'crease in the error of the intercept. In parts (a)\\nand (b) the error bars of the points at the extrema of the data set are small,\\nhence the error in the slope is small; in parts (c) and (d) for one of the extrema\\nthe data are relatively poorly known, which is reﬂected in the larger uncertainty\\nin the slope.\\n\\nFig. 6.3 Computer generated data sets with\\nGaussian noise. For (a), m = 2.01 ± 0.01\\nand c = −0.02 ± 0.07; (b) m = 1.99 ± 0.01\\nand c = 0.04 ± 0.08; (c) m = 1.97 ± 0.03\\nand c = 0.09 ± 0.06 and (d) m = 2.04 ±\\n0.04 and c = −0.3 ± 0.4.\\n\\n\\x0c72\\n\\nLeast-squares ﬁtting of complex functions\\n\\n6.3.2\\n\\nAnalysis of residuals with non-uniform error bars\\n\\nAs we saw in Chapter 5 a powerful way to learn rapidly about the quality\\nof the ﬁt is to plot the residuals, yi − y(xi ). For heteroscedastic data the raw\\nresiduals are more difﬁcult to interpret. It is therefore useful to introduce the\\ndimensionless quantity, the normalised residual, Ri , deﬁned as\\nRi =\\n\\nFig. 6.4 An analysis of the residuals to the ﬁt\\nof graph (a) from Fig. 6.2. The data and the\\nbest-ﬁt straight line are shown in the upper\\npanel; part (a) shows the residuals, and panel\\n(b) the normalised residuals. As this is a heteroscedastic data set the raw residuals are\\ndifﬁcult to interpret, whereas the normalised\\nresiduals are seen to be scattered within ±2\\nof zero, as expected for a good ﬁt.\\n\\nyi − y (xi )\\n,\\nαi\\n\\n(6.8)\\n\\nwhere yi , αi and y (xi ) are the i th measurement, uncertainty and value of the ﬁt,\\nrespectively. An analysis of the residuals to the ﬁt of graph (a) from Fig. 6.2\\nis shown in Fig. 6.4. The data and the best-ﬁt straight line are shown in the\\nupper panel, part (a) shows the raw residuals, and panel (b) the normalised\\nresiduals. We note that the raw residuals grow in magnitude with increasing\\ntrial number. However, analysis of the normalised residuals shows that 65%\\nare scattered within ±1 and 96% are within ±2, as expected for a good ﬁt.\\nUnlike the case for homoscedastic data, the shape of the histogram of th', 'e raw\\nand normalised residuals will be different; the presence of a bias or trend in the\\ndata would manifest itself much more obviously in a visual inspection of the\\nnormalised residuals. The validity of Gaussian uncertainties of the data is also\\neasier to verify with normalised residuals.\\n\\n6.4\\n6.4.1\\n\\nPerforming a weighted least-squares\\nﬁt—beyond straight lines.\\nLeast-squares ﬁt to an nth -order polynomial\\n\\nWe now consider having a theoretical model which is not restricted simply to\\na straight line. Consider ﬁrst the n th -order polynomial:\\ny (x) = a0 + a1 x + a2 x 2 + · · · + an x n =\\n\\nn\\n\\x05\\n\\nak x k .\\n\\n(6.9)\\n\\nk=0\\n\\n3 In practice for anything higher than a third-\\n\\norder polynomial numerical techniques are\\nused.\\n\\nNote that the function depends linearly on the coefﬁcients ak . One can substitute eqn (6.9) into eqn (6.1), and minimise the goodness-of-ﬁt parameter\\nχ 2 by taking partial derivatives with respect to each of the parameters in\\nturn, and setting them to zero. This procedure yields (n + 1) linear coupled\\nequations for the (n + 1) coefﬁcients. It is possible to solve the relevant\\ncoupled equations with matrix methods3 to yield the best-ﬁt coefﬁcients, and\\ntheir uncertainties (Bevington and Robinson 2003, Section 7.2, Press et al.\\n1992, Section 15.4). It is also possible to use computer software to minimise\\nχ 2 , and this is the approach we will use throughout the remainder of the\\nchapter.\\n\\n6.4.2\\n\\nLeast-squares ﬁt to an arbitrary nonlinear function\\n\\nMany of the theoretical models which describe experiments performed in the\\nphysical sciences involve a nonlinear dependence on some, or all, of the model\\nparameters. In general there will not be an analytic solution for the best-ﬁt\\n\\n\\x0c6.4 Performing a weighted least-squares ﬁt 73\\n\\nparameters. We will still use the goodness-of-ﬁt parameter χ 2 from eqn (6.1)\\nto deﬁne the problem, and discuss the numerical methods of obtaining the\\nminimum value of χ 2 in Chapter 7.\\nThe generalisation of eqn (6.9) to an arbitrary nonlinear ', 'function with N\\nparameters is:\\ny (x) = f (x ; a1 , a2 , . . . , aN ) .\\n\\n(6.10)\\n\\nUsing an arbitrary nonlinear function necessitates numerical methods for ﬁnding the optimum parameters. The ﬁrst stage in ﬁtting your data is to deﬁne\\nexplicitly the theoretical model which describes your data. This choice is\\noften motivated by some physical insight or prior experience.4 The method\\nfor obtaining the best-ﬁt parameters is the following:\\n\\n4 It is important to deﬁne the problem care-\\n\\nfully: a given data set can always be ﬁtted to\\nany function if enough parameters are introduced.\\n\\n• For each value of the independent variable, xi , calculate y(xi ) from eqn\\n(6.10) using an estimated set of values for the parameters.\\n• For each value of the independent variable calculate the square of the\\n!2\\ni ))\\n.\\nnormalised residual, (yi −y(x\\nαi\\n• Calculate χ 2 (by summing the square of the normalised residuals over\\nthe entire data set).\\n• Minimise χ 2 by optimising the ﬁt parameters.\\nThe minimum value of χ 2 must be found using numerical methods either by\\ntrial-and-error or through more elaborate methods which we discuss in more\\ndetail in Chapters 7 and 9. Often a handful of iterations via trial-and-error\\nwill yield coarse estimates of the best-ﬁt parameters. Invariably computers are\\nrequired to facilitate a precise and efﬁcient estimate of the best-ﬁt parameters,\\nespecially if the number of parameters or data points is large. As the minimisation procedure of χ 2 is a complex problem in its own right it is important that\\nthe minimisation starts with reasonable estimates of the parameters that will be\\noptimised. This ubiquitous method is implemented in data analysis and ﬁtting\\npackages, but can be readily incorporated into either a spreadsheet or ﬁtting\\nalgorithm.\\nWe illustrate these ideas by considering the example shown in Fig. 6.5(a)\\nwhich shows the voltage across the inductor in an LCR circuit as a function of\\ntime when the circuit is driven externally by a square wave.\\nA theoretical an', 'alysis predicts that the form of the voltage as a function of\\ntime is a nonlinear function, V (t; a1 , a2 , . . . , aN ) and we construct a model\\n\\nFig. 6.5 Experimental data of the voltage\\nacross an inductor in an LCR circuit as a function of time, and the best-ﬁt theoretical model\\nof eqn (6.11). The inset shows detail of the\\noscillations, and the magnitude of the experimental error bars. The histogram shows the\\ndistribution of normalised residuals. Nearly\\nall of the data lie within ±2 error bars of the\\ntheoretical model, which is consistent with a\\ngood ﬁt.\\n\\n\\x0c74\\n\\nLeast-squares ﬁtting of complex functions\\n\\nwhich is a damped sinusoidal oscillation with ﬁve parameters:\\n\\x0e\\n\\x0f\\nt\\nV (t) = Vbgd + V0 cos 2π + φ exp(−t/τ ).\\nT\\n\\n(6.11)\\n\\nHere, Vbgd is a background voltage, V0 the amplitude of oscillation, T the\\nperiod of the oscillations, φ a relative phase between the driving ﬁeld and\\nvoltage across the inductor, and τ an amplitude-decay, or damping, constant.\\nFor this data set, we would like to know the period of oscillations and the\\ndamping constant. The data consists of 2200 values of time, voltage and error\\nin voltage (ti , Vi , αi ). To obtain the best-ﬁt parameters the following procedure\\nwas adopted: for each value of ti , a theoretical voltage V (ti ) was calculated\\nusing eqn (6.11) with reasonable estimates of the ﬁve parameters, Vbgd , V0 ,\\nT , φ and τ . The estimates of the parameters were deduced by analysing the\\nexperimental data. χ 2 was calculated and subsequently minimised by varying\\nall the ﬁve parameters to yield the best-ﬁt line shown overlaid with the data in\\nFig. 6.5(a).\\nTwo obvious questions now arise: (i) is the theoretical model appropriate for\\nthe data? and, if so, (ii) what are the errors in the best-ﬁt parameters? We shall\\naddress the latter in the next section, and the former in detail in Chapter 8.\\nHowever we can obtain a qualitative answer to the question ‘is the theoretical\\nmodel appropriate for the data?’ by conducting a visual inspection of our ﬁt', '\\nand the normalised residuals. A good ﬁt will have approximately two-thirds\\nof the data within one error bar of the theoretical function and a histogram of\\nthe normalised residuals which is Gaussian. We note that for the particular ﬁt\\nshown in Fig. 6.5(a) approximately two-thirds of the data points are consistent\\nwith the theory, and the histogram of the normalised residuals is also well\\nmodelled by a Gaussian distribution (the continuous line in Fig. 6.5b).\\nGiven that the model is appropriate, we now show how to answer the\\nquestion ‘what are the uncertainties in the best-ﬁt parameters?’ for a nonlinear\\nfunction. Note that it would be inappropriate to proceed with this analysis if\\nthe ﬁt were poor.\\n\\n6.5\\n\\n5 This\\n\\nis often referred to as an N dimensional hyper-surface.\\n\\nCalculating the errors in a least-squares ﬁt\\n\\nIn Section 5.3.1, Fig. 5.8, we showed how the goodness-of-ﬁt parameter for a\\nsimple function, y = mx, evolved as m was varied for a given data set. This\\nevolution results in a one-dimensional curve with a clear minimum, which\\ndeﬁnes the best-ﬁt value. In the more general examples above, where one is\\nﬁtting more complex functions with non-uniform error bars, the goodness-ofﬁt parameter remains χ 2 , but we now need to consider the evolution of χ 2 over\\na surface deﬁned by the many ﬁt parameters.5\\n\\n6.5.1\\n\\nThe error surface\\n\\nWe begin this discussion by considering the special case of a nonlinear function\\nwith two parameters, f (A, B), before extending the discussion to the more\\ngeneral case.\\n\\n\\x0c6.5 Calculating the errors in a least-squares ﬁt\\n\\nFor a two-parameter function the equivalent of Fig. 5.8 in Section 5.3.1 is\\nnow a two-dimensional surface which is shown schematically in Fig. 6.6. The\\ncoordinates of the point in the A–B plane at which χ 2 is minimum deﬁne the\\nbest-ﬁt values of the ﬁt parameters, A and B, shown by the dot in the centre.\\nIn the plot we also show contours of constant χ 2 around the minimum value,\\n2 . The shape of the error surface in the v', 'icinity of the minimum shows\\nχmin\\nhow the ﬁt is sensitive to the variations in the ﬁt parameters. A high density of\\ncontours along a given parameter axis indicates high sensitivity to that parameter and conversely a sparse contour density shows that the ﬁt is insensitive\\nto that parameter. In general the shape of a ﬁxed χ 2 contour will be elliptical.\\nThe tilt of the contours yields information about the correlation between the\\nuncertainties in parameters, a topic which is discussed extensively in Chapter 7.\\nWhen the ellipse axes coincide with the parameter axes, the uncertainties in the\\nparameters are independent. For the remainder of this chapter we will assume\\nthat the contour plot of χ 2 is a well-behaved function with a single minimum.\\nStrategies for dealing with more complex error surfaces will be outlined brieﬂy\\nin Chapter 9.\\nOne can investigate the shape of the error surface in the vicinity of the\\nminimum by performing a Taylor-series expansion of χ 2 . For one parameter\\nthe second order of expansion reads:\\n\\x02\\n2χ 2 \\x02 \\x03\\n\\x03\\n\\x04\\n\\x03\\n\\x04\\n\\x042\\n1\\n∂\\n\\x02\\n(6.12)\\nχ 2 a j + \\x12a j = χ 2 a j +\\n\\x02 \\x12a j ,\\n2 ∂a 2j \\x02\\naj\\n\\nwhere \\x12a j is the excursion of the parameter away from its optimal value,\\na j . There is no linear term in eqn (6.12) as the ﬁrst-order derivative of χ 2\\ndisappears at the minimum. In the next section we will see that for an excursion\\nequal in magnitude to the size of the error bar, the value of χ 2 will increase by\\n1. This allows us to write the standard error in the parameter in terms of the\\ncurvature of the error surface:\\n\\x08\\n2\\n\\x0f.\\n(6.13)\\nαj = \\x0e\\n∂2χ 2\\n∂a 2j\\n\\nWe see that a large curvature of χ 2 near the optimal value results in a small\\nstandard deviation of the parameter a j . This is a mathematical way of relating\\nthe contour density to the uncertainty in the parameter. We will return to this\\nmathematical formalism for evaluating the uncertainties in parameters from\\nthe curvature of the error surface in Chapter 7, where we will discuss the\\ncorrelation of the parameters, ', 'and thus the correlations between the parameter\\nuncertainties, in terms of the Hessian matrix.\\n\\n6.5.2\\n\\nConﬁdence limits on parameters from weighted\\nleast-squares ﬁt\\n\\nHaving ascertained the best-ﬁt parameters from a weighted least-squares ﬁt\\nand undertaken a qualitative analysis of the quality of the ﬁt, the question\\n\\n75\\n\\nFig. 6.6 Contours of constant χ 2 in the\\nA− B plane for a general two-parameter\\nnonlinear function f (A, B). The minimum\\n2 , is obtained with the\\nvalue of χ 2 , χmin\\nbest-ﬁt values of the parameters, A and B,\\nshown by the dot in the centre. The contours\\nincrease in magnitude as one departs from the\\nbest-ﬁt parameters.\\n\\n\\x0c76\\n\\nLeast-squares ﬁtting of complex functions\\nTable 6.2 Conﬁdence limits associated with various \\x12χ 2 contours for one\\ndegree of freedom.\\n\\x12χ 2 contour\\nMeasurements within range\\n\\nFig. 6.7 The \\x12χ 2 = 1 contour in the A–B\\nplane. The horizontal and vertical tangent planes deﬁne the uncertainties in the\\nparameters.\\n\\nFig. 6.8 The procedure for obtaining the\\n2\\nuncertainties in the best-ﬁt parameters. χmin\\nis achieved when the parameters have the\\nvalues A, B. If A is increased with B held\\nconstant one follows the trajectory labelled 1\\nto arrive at the desired \\x12χ 2 contour. Then,\\nB must be allowed to vary to reduce χ 2 ,\\nwhich results in motion across the error surface along the path labelled 2. This iterative\\nprocedure is repeated until an extremum of\\nthe desired \\x12χ 2 contour is achieved, where\\nthe coordinate of the abscissa yields A + α A .\\nRepeating this procedure from A, B by keeping A constant and increasing B will give the\\nerror bar for B.\\n\\n1.00\\n\\n2.71\\n\\n4.00\\n\\n6.63\\n\\n9.00\\n\\n68.3%\\n1σ\\n\\n90.0%\\n\\n95.4%\\n2σ\\n\\n99.0%\\n\\n99.7%\\n3σ\\n\\nremains ‘what are the errors on the best-ﬁt parameters?’. Speciﬁcally, one\\nwould like to know the 68% (1σ ), 95.4% (2σ ), etc. conﬁdence limits. We\\nhave seen that the value of χ 2 is an indicator of the goodness of ﬁt and in\\nthe previous section how the variation of χ 2 around its minimum is related to\\nthe sensitivity of the ﬁt', ' to the individual parameters. We can therefore use the\\n2 , which is \\x12χ 2 , to characterise\\nvariation in χ 2 from its minimum value, χmin\\nthe uncertainties in the best-ﬁt parameters.\\nHow do we determine which \\x12χ 2 contour represents the 68% conﬁdence\\nlimit for a given parameter? The probability of χ 2 changing by a certain\\namount is given by the probability distribution function of χ 2 (discussed in\\ndetail in Chapter 8) with the appropriate degrees of freedom. From the PDF of\\nχ 2 for one degree of freedom we can calculate the \\x12χ 2 values that correspond\\nto a particular conﬁdence limit. For one degree of freedom these \\x12χ 2 contours\\nare given in Table 6.2.\\nIn the example shown in Fig. 6.7, the \\x12χ 2 = 1 contour is plotted. This\\nis the contour that corresponds to the conﬁdence limit that we have adopted\\nfor our error bar throughout this book. This contour deﬁnes a conﬁdence\\nregion in the A–B plane for both parameters. However, what we require is\\nthe conﬁdence limit for a single parameter—in this case either A or B. To\\nextract the conﬁdence limit in one of the parameters, we do not read off the\\nintersection of the relevant contour with the parameter axis, but rather take\\nthe extremum of the ellipse. As shown in Fig. 6.7 there are four extrema of\\nthe ellipse; two are extrema for B and occur at the horizontal tangent planes,\\nwith the other two being extrema for A occurring at the vertical tangent planes.\\nThe difference between the value of A at which the extremum occurs and the\\nbest-ﬁt value, A, deﬁnes the error bar, α A .\\nTo arrive at the extremum of a particular \\x12χ 2 contour requires a series\\nof orthogonal steps across the error surface. So, if one wishes to ﬁnd the\\nprojection of a particular contour in A, the ﬁrst stage would be to move along\\n2 changing A from its optimal value A\\nthe error surface from the location of χmin\\nuntil the appropriate contour is reached (path 1 in Fig. 6.8). Having reached this\\npoint, an orthogonal motion is undertaken by re-optimising B whils', 't keeping\\nA at its new value (path 2 in Fig. 6.8). These two steps are repeated until no\\ndiscernible change is observed in the χ 2 value. It is not too difﬁcult to automate\\nthis process in most spreadsheet packages. The difference between the ﬁnal\\niterated value of A, A + α A , and the optimal value, A, is the uncertainty in A.\\nThe mathematical operations required to move to the extremum of a particular\\n\\x12χ 2 contour are two independent χ 2 minimisations. For the special case of\\na two-parameter ﬁt, both operations are χ 2 minimisations with one degree of\\nfreedom.\\n\\n\\x0c6.5 Calculating the errors in a least-squares ﬁt\\n\\n77\\n\\nExtending the procedure for N parameters (a1 , a2 , . . . , aN ) is similar to\\nthat described above for the two-dimensional case. The error surface becomes\\nN -dimensional. Navigating this surface involves making a change to one of\\nthe parameters from its optimal value as before and then re-optimising all\\nother N − 1 parameters. As before, both operations are independent χ 2 minimisations. The minimisation where the parameter of interests is changed has\\none degree of freedom; the re-optimisation of all other parameters has many\\ndegrees of freedom. Thus, for the uncertainty in the single variable of interest,\\nthe \\x12χ 2 contours which correspond to a particular conﬁdence level remain\\nthose listed in Table 6.2. If one is interested in the other conﬁdence limits\\nlisted in Table 6.2 one follows the same procedure to locate the extremum of\\nthe appropriate \\x12χ 2 contour.\\nA summary of calculating errors on parameters using χ 2 minimisation\\n(1) Find the best-ﬁt parameters by minimising χ 2 .\\n(2) Check the quality of the ﬁt. If the ﬁt is poor, there is little point in\\nusing, or calculating, the errors in the best-ﬁt parameters.\\n(3) Adjust the parameter whose error you wish to determine until χ 2\\n2 + 1.\\nbecomes χmin\\n(4) Re-minimise χ 2 using all the other parameters, but not the parameter\\nwhose error you are measuring.\\n(5) Iterate 3 and 4 until the value of χ 2 does ', 'not change (within some tolerance). The standard error on the parameter is the absolute difference\\nbetween the current and optimal value of that parameter.\\n(6) Repeat steps 3–5 for each of the remaining ﬁt parameters of interest.\\nWe now illustrate some of these abstract concepts explicitly through worked\\nexamples.\\n\\n6.5.3\\n\\nWorked example 1—a two-parameter ﬁt\\n\\nFigure 6.9 shows the \\x12χ 2 contours for the two parameters (gradient, m,\\nand intercept, c) of the weighted least-squares straight-line ﬁt to the data of\\n2 are m = 2.03 mV/Hz, and\\nFig. 6.1(d). The coordinates of the location of χmin\\nc = −1 mV, in agreement with Table 6.1. Some of the contours of Table 6.2\\nare indicated on Fig. 6.9.\\nWe can obtain the error in the slope by looking at the coordinates of the\\nextremum of the \\x12χ 2 = 1 contour along the gradient axis. The lower righthand extremum for m is located at m = 2.08 mV/Hz, giving the uncertainty in\\nm as αm = 2.08 − 2.03 = 0.05 mV/Hz. A similar procedure using the lower\\nextremum for the intercept gives αc = −1 − (−4) = 3 mV.6 We obtain identical values of the error for either parameter if we choose the other extremum.\\nThe fact that the axes of the contours of χ 2 around the minimum are not\\ncoincident with the m–c axes is an indication of the degree of correlation\\nbetween the variables. We will discuss the implications of such a correlation in Chapter 7. The importance of allowing the other parameters to be\\n\\n6 The extremum of the \\x12χ 2 = 1 contour\\n\\nalong one axis does not occur at the same\\ncoordinates as the extremum along the\\northogonal axis. Thus two separate iterations\\nare required to obtain the value of the errors\\nfor both parameters.\\n\\n\\x0c78\\n\\nLeast-squares ﬁtting of complex functions\\n\\nFig. 6.9 A contour plot showing iso-χ 2 lines for the gradient and intercept of the straight-line ﬁt to the data of Fig. 6.1(d). The \\x12χ 2 =1, 4, 9 and\\n2.71 contours correspond, respectively, to one, two, three standard deviations, and the 90% conﬁdence limit.\\n\\nFig. 6.10 Cuts through', ' the error surface of\\nFig. 6.9 as a function of (a) the gradient,\\nand (b) the intercept. The dashed lines are\\nobtained when one parameter is varied, and\\nthe other held at its optimum value; the solid\\nline is obtained when one parameter is varied, and the other re-optimised to minimise\\nχ 2 . The open circles correspond to increases\\n2 of 1, 2.71, 4 and 9 and are\\nin χ from χmin\\nthe extrema along the appropriate axes of the\\nellipses in Fig. 6.9.\\n\\nre-optimised when evaluating the error in one of the parameters is highlighted\\nin Fig. 6.10.\\nParts (a) and (b) of Fig. 6.10 show the variation of χ 2 with respect to the\\ngradient and intercept, respectively. The dashed curves show the variation with\\nrespect to one parameter, when the other is left at its optimum value. In contrast, the solid curves show the variation with respect to one parameter, when\\nthe other is re-optimised. It is the latter which yields the conﬁdence limit on\\nthe parameters. The \\x12χ 2 = 1 contour is reached at a gradient of 2.05 mV/Hz\\nif m is increased and the intercept kept as c which gives an unrealistic error\\n\\n\\x0c6.6 Fitting with constraints 79\\n\\nof 0.02 mV/Hz. However, following the procedure depicted in Fig. 6.8, the\\nextremum is at a value of 2.08 mV/Hz and the uncertainty is 0.05 mV/Hz,\\nmore than double the value obtained without re-optimising the intercept. The\\nmore tilted the contours are, the more extreme this difference becomes.\\n\\n6.5.4\\n\\nWorked example 2—a multi-parameter ﬁt\\n\\nHere we look at an example of a four-parameter ﬁt. The data in Fig. 6.11(a)\\nshow the number of counts per second (c.p.s.) when X-rays are diffracted from\\nthe (111) peak of a thin ﬁlm of permalloy as a function of the scattering angle.\\nThe error bars come from Poisson count statistics. The model to describe the\\ndata has four parameters: the height of the Lorentzian lineshape, S0 , the angle\\nat which the peak is centred, θ0 , the angular width of the peak, \\x12θ , and a\\nconstant background offset, Sbgd . Mathematically, the signal, S,', ' is of the form:\\nS = Sbgd +\\n\\n1+4\\n\\nS0\\n\\x10\\n\\nθ−θ0\\n\\x12θ\\n\\n\\x112 .\\n\\n(6.14)\\n\\nThe error surface for this problem is four dimensional. To extract the uncertainty in a parameter one needs to reduce this four-dimensional surface to a single one-dimensional slice as shown in Fig. 6.11(d). This is achieved by varying\\nthe parameter of interest and allowing all other parameters to be re-optimised to\\nminimise χ 2 . Additionally it is useful to consider two-dimensional slices of the\\nerror surface to investigate the correlation of the parameters. These 2D surfaces\\nare created by varying two of the parameters and allowing all other parameters\\nto be re-optimised to minimise χ 2 . In Fig. 6.11(b) and (c) we show the twodimensional surface contours of \\x12χ 2 where we investigate the correlation\\nbetween the background and peak centre in (b) and the background with peak\\n2 are aligned with\\nwidth in (c). In Fig. 6.11(b) the contour ellipses close to χmin\\nthe coordinate axes, indicating that there is very little correlation between\\nthe background and the peak centre. In contrast the contours are tilted with\\nrespect to the axes in Fig. 6.11(c), indicating a negative correlation between\\nbackground and peak width. The rotation of the ellipse is a manifestation of\\nthe fact that the background and width can be played off against each other to\\na certain extent—an increase of the background can be partially compensated\\nfor by a decrease of the width of the peak. The inﬂuence on the uncertainty of\\none parameter owing to correlation with other parameters is taken into account\\nby allowing all the other parameters to be re-optimised when calculating the\\none-dimensional variation of χ 2 with respect to that parameter in the vicinity\\nof the minimum (Fig. 6.11d).\\n\\n6.6\\n\\nFitting with constraints\\n\\nA physical insight often allows the number of independent ﬁtting parameters\\nto be reduced. A constraint is easily incorporated into most ﬁtting packages or\\na spreadsheet.\\n\\nFig. 6.11 (a) An X-ray diffraction peak as a\\nfunctio', 'n of scattering angle. The model comprises a Lorentzian peak on a constant background. (b) Contour plot of the background\\nand centre of the peak. (c) Contour plot of\\npeak width and background. (d) The variation of χ 2 around the optimum background\\nvalue, where the other three parameters are\\nre-optimised for each background value.\\n\\n\\x0c80\\n\\nLeast-squares ﬁtting of complex functions\\n\\nFig. 6.12 Plots of (a) the real and (b) the\\nimaginary parts of the electrical susceptibility of a sample of laser-cooled atoms. The\\nformer is proportional to the refractive index\\nof the medium, the latter to the absorption\\ncoefﬁcient. These quantities are related via\\nthe Kramers–Kronig relations.\\n\\nConsider the data shown in Fig. 6.12 displaying the (a) real and (b) imaginary parts of the electrical susceptibility of a medium comprising lasercooled atoms. The data in part (a) follow the dispersion curve associated\\nwith the spectral dependence of the refractive index, whereas the absorption\\nspectrum of (b) displays a Lorentzian lineshape. The Kramers–Kronig relations explain how the knowledge of the spectral response of either the real\\nor imaginary part of the susceptibility enables the other to be calculated. The\\ntheoretical prediction is that the complex electrical susceptibility, χ E , in this\\nsituation is\\n\\x12\\n,\\n(6.15)\\nχ E = χ0\\n\\x12 − i\\x14\\nwhere \\x12 = ω − ω0 is the detuning (the difference between the applied frequency and the resonant frequency), and \\x14 is the linewidth. By calculating\\neqn (6.15) in a spreadsheet, with two parameters, the real and imaginary parts\\ncan be compared with the experimental data and their uncertainties. A leastsquares ﬁt can then be conducted simultaneously on both data sets. Simultaneous data ﬁtting is difﬁcult to achieve using a ﬁtting package, but is relatively\\nstraightforward in a spreadsheet. The thick lines on the ﬁgures show the results\\nof such a minimisation procedure. The result obtained for the linewidth with\\nthis procedure is \\x14 = 37.69 ± 0.03 MHz; when the two da', 'ta sets are analysed\\nindividually, less precise results are obtained: \\x14 = 37.71 ± 0.04 MHz from the\\nreal part, and \\x14 = 37.66 ± 0.05 MHz from the imaginary component.\\nDuring a minimisation procedure it is possible, on occasion, for χ 2 to be\\nreduced by extending the value of a parameter outside a range for which it is\\nphysically realistic. Most ﬁtting or spreadsheet packages enable constraints to\\nbe applied during the minimisation. The experimenter should ensure that after\\nminimisation all parameters remain within a physically realistic domain, even\\n2 value.\\nif this means a higher χmin\\nSometimes the experimenter has some prior knowledge which can be useful\\nin constraining ﬁt parameters. Examples include branching ratios, the ratio of\\nmasses, mass differences, and atomic energy level intervals. Figure 6.13(a)\\nshows an X-ray diffraction spectrum of the (3 1 1) peak of Cu. There are,\\nin fact, two unresolved peaks which have a width greater than their angular\\nseparation. It is known that the peaks must have the same lineshape function, the same angular width, and a well-deﬁned angular separation. A multidimensional χ 2 ﬁt was performed, and the result is shown as the solid line in\\nFig. 6.13. In this case the relative heights of the peaks was allowed to ﬂoat\\nas a free parameter, but analysis of the optimal parameters gave a ratio of the\\nintensity of the two peaks as 2.1 ± 0.1, consistent with the theoretical value of\\n1.96. One could have used the theoretical value to constrain the parameters (i.e.\\nreduce the number of ﬁtting parameters by 1), or, as here have allowed them\\nto ﬂoat. Although this increases the number of ﬁt parameters it is a useful\\ntest of the validity of the theoretical model, especially when the number of\\ndata points greatly exceeds the number of parameters. Note that allowing the\\nwidths of the two components to vary independently, in this case, leads to\\ninconsistent results with poor precision; similarly, ﬁtting the data with a singlepeak function result', 's in a poorer ﬁt with unrealistic peak widths.\\n\\n\\x0c6.7 Testing the ﬁt using the residuals 81\\n\\n6.7\\n\\nTesting the ﬁt using the residuals\\n\\nIn Chapter 5 and in section 6.3.2 we stressed the importance of investigating\\nthe normalised residuals as an indicator of the quality of a ﬁt. We return to this\\ntopic in this section and show how an incorrect model can lead to structure and\\nautocorrelations in the normalised residuals. In Fig. 6.13 we show two ﬁts to\\nthe X-ray diffraction spectrum from the (3 1 1) peak of Cu that was discussed\\nin Section 6.6. In Fig. 6.13(a) the correct constrained model with two peaks is\\nused to ﬁt the data, whereas in (b) we show the ﬁt to an erroneous model based\\non a single peak. A quick visual inspection of the two ﬁgures shows that both\\nﬁts reproduce most of the main features, but a closer inspection of the residuals\\nshows structure in the normalised residual plot close to the ﬁtted peak centre\\nin Fig. 6.13(b).\\nStructure in the residuals can be visualised more clearly by making use\\nof a lag plot which is constructed by plotting the normalised residual Ri\\n(see eqn 6.8) against a lagged residual Ri−k where k is an integer, and is\\nusually 1. These plots are useful for identifying outliers and for testing the\\nrandomness of the errors. Any non-random pattern in the lag plot is an indicator\\nof autocorrelations in the residuals and suggests something is missing from the\\ntheoretical model. In Fig. 6.14 the lag plots for k = 1 are shown for the two\\nﬁts in Fig. 6.13. The lag plot for the constrained ﬁt (Fig. 6.14a) shows no\\nstructure, but that of the single-peak ﬁt (Fig. 6.14b) clearly shows a positive\\ntrend suggesting a positive correlation between some of the lagged residuals.\\nFor a good ﬁt we expect that, if the uncertainties in the data are Gaussian, 91%\\nof the normalised residuals should fall within a two-dimensional box deﬁned\\nby the ±2 limits on the lag plot. For the constrained ﬁt, the number of residuals\\ninside this box is 93%, in excellent agreem', 'ent with this hypothesis. On the\\nother hand, the single-peak ﬁt only has 82% of the data points which are within\\nthe box, indicative of a poor ﬁt.\\nThe degree of correlation, or shape, in the lag plot can be reduced to a\\nsingle numerical value by evaluating the Durbin–Watson (Durbin and Watson\\n1950) statistic, D. In its weighted form, for k = 1, D is deﬁned in terms of the\\nnormalised residuals:\\nN \\x15\\n\\x06\\n\\nD=\\n\\nRi − Ri−1\\n\\ni=2\\nN\\n\\x06\\n\\n\\x162\\n.\\n\\n(6.16)\\n\\n[Ri ]2\\n\\ni=1\\n\\nThe Durbin–Watson statistic has values in the range 0 < D < 4 and may\\nindicate three limiting cases:\\n(1) D = 0: systematically correlated residuals;\\n(2) D = 2: randomly distributed residuals that follow a Gaussian distribution;\\n(3) D = 4: systematically anticorrelated residuals.\\nAn experimenter should be highly suspicious if the value of D approaches\\neither 0 or 4, and question the ﬁt should D differ signiﬁcantly from 2. For\\n\\nFig. 6.13 Experimental\\nspectra\\nand\\nweighted least-squares-ﬁt (thick line) for\\nthe Cu (3 1 1) X-ray diffraction peak. In (a)\\nthe ﬁt and residuals are shown for a\\nconstrained double peak model and in\\n(b) the experimental data are ﬁtted to a\\nsingle-peak function. The residuals are\\nrandomly distributed for the double-peak ﬁt,\\nbut show structure for the single-peak ﬁt.\\n\\n\\x0c82\\n\\nLeast-squares ﬁtting of complex functions\\n\\nhomoscedastic data sets it is possible to use the D statistic to test the quality\\nof the ﬁt but in Chapter 8 we will discuss a more robust test based on the χ 2\\nstatistic. For the examples shown in Fig. 6.13 the Durbin–Watson statistic is\\n1.97 for the constrained ﬁt and 1.12 for the erroneous ﬁt. As D is very close\\nto 2 for the constrained double-peak ﬁt we would expect that this model was\\nbetter than the alternative single peak for which D was signiﬁcantly different\\nfrom 2.\\n\\nChapter summary\\n• A sequence of data points with non-uniform error bars is referred to as\\nheteroscedastic.\\n\\x05 (yi − y (xi ))2\\n, with y (xi )\\n• The goodness-of-ﬁt parameter is χ 2 =\\nαi2\\ni\\nthe theoretical model, yi the da', 'ta and αi the corresponding error bars.\\n• For linear regression, y (xi ) = m xi + c, with non-uniform error bars\\nthere exist analytic solutions for the best values of the slope, m, the\\nintercept c and their associated errors:\\n\\x06\\ni\\n\\nm=\\n\\n\\x06\\n\\x06\\nwi xi yi − i wi xi i wi yi\\n,\\n\\x042\\n\\x03\\x06\\n\\x06\\n2\\ni wi\\ni wi xi −\\ni wi x i\\n\\nwi\\n\\x06\\n\\n\\x06\\n\\ni\\n\\n\\x08\\nFig. 6.14 Lag plots with k = 1 of the normalised residuals shown in Fig. 6.13. (a) The\\nlag plot from the two-peak ﬁt with 93% of\\nthe normalised residuals within ±2σ of the\\nzero mean. (b) The lag plot from Fig. 6.13(b)\\nin which a clear linear trend is observed and\\nonly 82% of the data are within the expected\\nconﬁdence limit. The Durbin–Watson statistic D is 1.97 for ﬁt (a) and 1.12 for (b).\\n\\nαm =\\n\\n\\x06\\n\\n\\x06\\n\\ni wi\\n\\n\\x06\\ni\\n\\nc=\\n\\nwi xi\\n\\n\\x042 ,\\n\\n\\x06\\n\\x06\\nwi yi − i wi xi i wi xi yi\\n,\\n\\x042\\n\\x03\\x06\\n\\x06\\n2\\ni wi\\ni wi xi −\\ni wi x i\\n\\nwi xi2\\n\\x06\\n\\n\\x08\\nαc =\\n\\ni wi\\n\\x03\\x06\\n2\\ni wi xi −\\ni\\n\\n\\x06\\n\\x06\\n\\ni\\n\\n\\x06\\n\\n\\x06\\ni\\n\\nwi\\n\\nwi xi2\\n\\x042 ,\\n\\x03\\x06\\n2\\ni wi xi −\\ni wi x i\\n\\n\\x06\\n\\ni\\n\\nwhere the weighting for each point is the inverse square of the uncertainty, wi = αi−2 , and the summation is over all the data points.\\n• The best-ﬁt parameters for a nonlinear function are usually found by\\ncomputer minimisation. The best-ﬁt parameters are the ones for which\\n2 . The uncertainty in a given parameter can\\nχ 2 is at a minimum, χmin\\nbe found by an iterative procedure: the parameter A is increased from\\nthe best value, Ā, with all the other parameters held constant until χ 2\\nhas increased by 1. Then, all the other parameters must be allowed\\nto vary to reduce χ 2 . A is increased again, and the process repeated\\nuntil convergence is obtained. The value of A at which this occurs\\nis Ā + α A .\\n\\n\\x0cExercises\\n\\n83\\n\\nExercises\\n(6.1) Linear regression—unweighted ﬁt\\nThe data plotted in Fig. 6.1(d) are listed below.\\nFrequency (Hz)\\nVoltage (mV)\\nError (mV)\\n\\n10\\n16\\n5\\n\\n20\\n45\\n5\\n\\n30\\n64\\n5\\n\\n40\\n75\\n5\\n\\n50 60\\n70 115\\n30\\n5\\n\\n(6.5) Speed of light\\nThe data plotted in Fig. 6.1(c) are listed below.\\nDisplacement (m)\\nPhase (rad)\\nError (rad)\\n\\n0.05\\n0.00\\n0.05\\n\\n0.25\\n0.21\\n0.05\\n\\n0.45\\n0.44\\n0.', '05\\n\\n0.65\\n0.67\\n0.05\\n\\n0.85\\n0.88\\n0.09\\n\\nFrequency (Hz) 70 80 90 100 110\\nVoltage (mV)\\n142 167 183 160 221\\nError (mV)\\n5\\n5\\n5 30\\n5\\n\\nDisplacement (m)\\nPhase (rad)\\nError (rad)\\n\\n1.05\\n1.1\\n0.1\\n\\n1.25\\n1.3\\n0.2\\n\\n1.45\\n1.5\\n0.5\\n\\n1.65\\n2.0\\n0.1\\n\\n1.85\\n2.24\\n0.07\\n\\nUse the results of Chapter 5 to ascertain the best-ﬁt gradient and intercept using an unweighted ﬁt. Verify that\\nthe results are in agreement with Table 6.1.\\n\\nThe speed of light is related to the slope, m, of this graph\\n6\\nHz. Calvia the relationship speed of light = 2π×60×10\\nm\\nculate the the slope and intercept of the bestﬁt straight line to the data, and their associated\\nerrors. Hence deduce the speed of light, and its\\nerror. The theoretical predication is that the intercept should be zero. Is this consistent with the\\ndata?\\n\\n(6.2) Linear regression—weighted ﬁt\\nFor the data set of Exercise (6.1) use the results of\\neqns (6.3)–(6.6) to calculate the best-ﬁt gradient and\\nintercept using a weighted ﬁt. Verify that the results are\\nin agreement with Table 6.1. Draw the lag plot, and\\ncalculate the Durbin–Watson statistic D.\\n(6.3) Normalised residuals\\nUse the ﬁt parameters from the last question to plot\\nthe best-ﬁt straight line with the data. Use eqn (6.8) to\\ncalculate the normalised residuals, and plot them.\\n(6.4) Error bars from a χ 2 minimisation\\n(i) For the data set of Exercise (6.1), write a spreadsheet which you can use to perform a χ 2 minimisa2 is obtained for the same values\\ntion. Verify that χmin\\nof the parameters as are listed in Table 6.1. (ii) By\\n2 + 1 outlined in\\nfollowing the procedure of χ 2 → χmin\\nSection 6.5, check that the error bars for m and c are\\nin agreement with Table 6.1. Let the parameters (a)\\nincrease from their optimal values to ﬁnd the extremum\\nfor each parameter, and (b) decrease from their optimal values to ﬁnd the extremum for each parameter.\\nAre the uncertainties determined in (a) and (b) the\\nsame? (iii) Calculate the uncertainties on m and c by\\n2 + 4 and χ 2 →\\nﬁnding the extrema of the χ 2 → χmin\\n2\\nχmin + ', '9 contours. Are your results in agreement with\\nTable 6.2?\\n\\n(6.6) Strategies for error bars\\nConsider the following data set:\\nx\\ny\\nαy\\n\\n1\\n51\\n1\\n\\n2\\n103\\n1\\n\\n3\\n150\\n2\\n\\n4\\n199\\n2\\n\\n5\\n251\\n3\\n\\nx\\ny\\nαy\\n\\n6\\n303\\n3\\n\\n7\\n347\\n4\\n\\n8\\n398\\n5\\n\\n9\\n452\\n6\\n\\n10\\n512\\n7\\n\\n(i) Calculate the weighted best-ﬁt values of the slope,\\nintercept and their uncertainties. (ii) If the data set had\\nbeen homoscedastic, with all the errors equal, α y = 4,\\ncalculate the weighted best-ﬁt values of the slope, intercept and their uncertainties. (iii) If the experimenter took\\ngreater time to collect the ﬁrst and last data points, for\\nwhich α y = 1, at the expense of all of the other data\\npoints, for which α y = 8, calculate the weighted best-ﬁt\\nvalues of the slope, intercept and their uncertainties, and\\ncomment on your results.\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cComputer minimisation\\nand the error matrix\\nAs we discussed in Chapter 6, the errors on the parameters, αi , are related\\n2 . The\\nto how the χ 2 hyper-surface varies around the minimum value, χmin\\nlocal curvature of the error hyper-surface is mapped out by calculating χ 2 as\\nthe parameters are displaced from their optimal values. Therefore, it is not\\na surprise that there is a mathematical relationship between the curvature of\\nthe hyper-surface and the magnitude of the errors of the ﬁtted parameters, see\\neqn (6.13). In this chapter we will develop a general matrix methodology for\\ndescribing the variation of the χ 2 surface and for determining the uncertainties\\nin the ﬁt parameters. We begin by discussing different types of algorithms used\\nin ﬁtting packages to minimise χ 2 ; this both serves to reinforce the discussion\\nof ﬁnding the best ﬁt described in earlier chapters, and is a convenient way of\\nintroducing the matrices from which the uncertainties in the ﬁt parameters can\\nbe deduced.\\nIn the previous chapters we have implicitly assumed that both our parameters and their errors are independent. However, the statistical ﬂuctuations of\\nthe data lead to correlations amo', 'ng the uncertainties in the best-ﬁt values of the\\nindependent parameters. In Section 7.3 we detail how this degree of correlation\\ncan be quantiﬁed and incorporated into error analysis.\\nThe data are ﬁtted using the standard chi-squared statistic, χ 2 , we have\\nseen previously. In general, we wish to ﬁt our N data points, (xi , yi ),\\nwith uncertainties given by αi , to a nonlinear function with N parameters,\\nf (x ; a1 , a2 , . . . , aN ). The analytic results of least-squares ﬁtting discussed\\nin earlier chapters for linear regression cannot be used for nonlinear functions,\\nconsequently we develop approximate iterative procedures for locating the\\nminimum of the multi-dimensional error surface.\\n\\n7.1\\n\\nHow do ﬁtting programs minimise?\\n\\nWe now return to discussing how computer ﬁtting functions arrive at the\\nbest ﬁt. Irrespective of whether the minimisation process occurs within a\\nspreadsheet or a ﬁtting program, all minimisation techniques are based on an\\niterative method of improving a trial solution by a reduction in the goodnessof-ﬁt parameter. There are several different approaches that can be adopted\\nto navigate over the N -dimensional error surface to arrive at the minimum.\\nIn this chapter we restrict our discussion to the easiest case where there is a\\nsingle minimum on the error surface. We outline ﬁve possible minimisation\\n\\n7\\n7.1 How do ﬁtting programs\\nminimise?\\n\\n85\\n\\n7.2 The covariance matrix and\\nuncertainties in ﬁt parameters\\n\\n92\\n\\n7.3 Correlations among\\nuncertainties of ﬁt parameters\\n\\n93\\n\\n7.4 Covariance in error propagation\\n\\n95\\n\\nChapter summary\\n\\n97\\n97\\n\\nExercises\\n\\n\\x0c86\\n\\nComputer minimisation and the error matrix\\n\\nmethods here; further details for these, and alternative, strategies can be found\\nin references such as Bevington and Robinson (2003, Chapter 8) and Press\\net al. (1992, Chapters 10 and 15). Each of the techniques discussed in detail\\nare iterative, and proceed by applying an update rule. We ﬁrst discuss these\\nconcepts in the more familiar context of ﬁnding t', 'he zero of a function.\\n\\n7.1.1\\nFig. 7.1 The Newton–Raphson method for\\nﬁnding the zero crossing of a function. After\\ns iterations the function is f (xs ), and its\\nderivative at xs is f \\x0e (xs ). The tangent to the\\ncurve is drawn at xs , and the zero crossing of\\nthe tangent found. This point is taken as the\\nupdated coordinate of the zero-crossing point\\nof the function, xs+1 . The iterative procedure\\ncontinues until convergence at the desired\\ntolerance.\\n\\nIterative approaches\\n\\nThe Newton–Raphson method is a numerical technique to solve the equation\\nf (x) = 0. It is an iterative procedure illustrated in Fig. 7.1. We assume that the\\nﬁrst approximate solution is x1 , where the function is f (x1 ), and the ﬁrst derivative f \\x0e (x1 ). Let the zero crossing of f (x) be at x1 + h, then f (x1 + h) = 0.\\nFrom Fig. 7.1 we see that if h is small\\nf (x 1 + h) ≈ f (x1 ) + f \\x0e (x1 ) h,\\n∴ f (x1 ) + f \\x0e (x1 ) h ≈ 0,\\n∴h≈−\\n\\nf (x1 )\\n.\\nf \\x0e (x1 )\\n\\n(7.1)\\n\\nThis allows us to write down a second approximation to the zero crossing:\\nx2 = x1 −\\n\\nf (x1 )\\n.\\nf \\x0e (x1 )\\n\\n(7.2)\\n\\nThe process can be repeated to obtain successively closer approximations. If\\nafter s iterations the approximate solution is xs then the next iteration is xs+1 ,\\nand these quantities are related via the relation:\\nxs+1 = xs −\\n\\nf (xs )\\n.\\nf \\x0e (xs )\\n\\n(7.3)\\n\\nEquation (7.3) is known as the update rule, as it allows the parameter (the current best value of the zero crossing) to be amended. The procedure continues\\nuntil the zero-crossing point is found, to within a certain tolerance. If the ﬁrst\\nguess for the solution is close to the actual solution, the procedure converges\\nrapidly. Conversely, if the ﬁrst guess is far from the optimal value there are\\ntwo issues: (i) the convergence can be slower; and (ii) depending on the sign\\nof the gradient of the function it is possible that the updated solution will be\\nfurther from the optimal value than the current value. Therefore it is important\\nto have a reasonable ﬁrst guess as the input to utilise t', 'he power of the Newton–\\nRaphson method. The convergence properties of this method are discussed in\\nExercise (7.1), and the procedure can easily be extended to ﬁnd maxima or\\nminima of a function, as shown in Exercise (7.2).\\nFig. 7.2 An illustration of a grid search on\\na two-dimensional error surface. Initial trial\\nvalues of the gradient and intercept were chosen (gradient 1.90 mV s, intercept −8 mV),\\nand each parameter was optimised in turn\\nuntil convergence and the minimum χ 2 was\\nobtained. Note the inefﬁcient zig-zag motion\\nalong the ﬂat valley bottom.\\n\\n7.1.2\\n\\nGrid search\\n\\nWe illustrate the grid search method for ﬁnding the minimum of the error\\nsurface by applying it to the case of Fig. 6.1(d) (the results of the minimisation\\nprocedure are summarised in Table 6.1), as seen in Fig. 7.2. Starting values\\nof the trial parameters (gradient 1.90 mV s, intercept −8 mV) and step sizes\\n\\n\\x0c7.1 How do ﬁtting programs minimise? 87\\n\\nare chosen. The minimisation proceeds through an iterative process whereby\\nthe goodness-of-ﬁt parameter is minimised by changing each parameter in\\nturn. From the initial position the gradient is kept the same, with the intercept\\nincreased. If the value of χ 2 increases, the direction of motion across the\\nerror surface is reversed. Having started on a downhill trajectory, the values of\\nthe parameter are changed until χ 2 increases. Using the last three increments\\nof the parameter, it is easy to ﬁnd the value at which the minimum occurs,\\nsee Exercise (7.3)—this procedure is known as a line minimisation. The\\nprocedure described above is then repeated for the intercept as shown in Fig.\\n7.2. This iterative procedure converges toward the local minimum. The gridsearch method is powerful in that it is easy to implement computationally if\\nﬁtting to a model which has analytic derivatives.\\nFor a model with more than two parameters a similar procedure is applied,\\nwith each parameter minimised in turn. The whole procedure is then repeated\\nuntil the convergence to', 'lerance is met—the procedure is terminated when\\nthe value of χ 2 changes by less than, say, one part in 103 . If the variation\\nof χ 2 with respect to each parameter is insensitive to the values of the other\\nparameters, the axes of the χ 2 contours are coincident with the parameter axes;\\nunder these conditions the grid-search method converges rapidly. In the more\\ngeneral case, as depicted in Fig. 7.2, there is a degree of correlation among the\\nparameters, and the contours of constant χ 2 are tilted. Figure 7.3 shows the\\nevolution of χ 2 and the parameters as functions of the number of iterations.\\nThe trajectory across the error surface zig-zags, which is very inefﬁcient, and\\nthe convergence is slow. The advantages of the grid-search method are (i)\\nsimplicity, and (ii) that the minimisation process is relatively insensitive to\\nthe initial trial parameters. The major disadvantage is that convergence to the\\nminimum can be very slow for correlated parameters (the more general case).\\n\\nThe gradient-descent method\\n\\nIn the grid-search method each parameter was varied sequentially which is\\nnot efﬁcient. A more elegant approach is to increment all the parameters\\nsimultaneously, with the aim of having a vector directed towards the minimum.\\nThe vector ∇χ 2 lies along the direction along which χ 2 varies most rapidly\\non the error surface. The minimisation proceeds by taking steps along this\\nsteepest descent. The gradient along the direction of the parameter a j can be\\napproximated numerically by the formula\\n\\x03\\n\\x04\\n\\x03 \\x04\\n\\x11\\n\\x10\\nχ 2 a j + δa j − χ 2 a j\\n∂χ 2\\n2\\n=\\n≈\\n,\\n(7.4)\\n∇χ\\nj\\n∂a j\\nδa j\\nwhere δa j is a small increment in a j (typically much smaller than the step\\nsize). Note that it is possible within the framework of some minimisation\\nalgorithms to enter analytic formulae for the gradient with respect to the\\nparameters.\\nLet the N -dimensional column vector as contain the N parameters a j after\\ns iterations. The update rule is\\nas+1 = as − β ∇χ 2 (as ) ,\\n\\n(7.5)\\n\\nFig. 7.3 The evolution of χ 2', ' , and the parameters as a function of iteration number for\\n2 is shown\\nthe grid-search method. χ 2 − χmin\\non a log scale in the inset of (a).\\n\\n(mV)\\n\\n7.1.3\\n\\nFig. 7.4 An illustration of a gradient-descent\\nmethod on a two-dimensional error surface.\\nEach parameter is optimised simultaneously\\nalong a vector deﬁned using the gradient.\\n\\n\\x0c88\\n\\nComputer minimisation and the error matrix\\n\\nwhere the value of the scaling factor β is chosen such that the trajectory\\nproceeds downhill, but does not overshoot up the ascending side of a valley,\\nsee Fig. 7.4. After each step, the direction of the steepest descent is calculated again and the process iterated. The method of steepest descent is good\\nat locating an approximate minimum, but is typically augmented by other\\nmethods to locate the actual minimum. Major problems with this approach are\\nthat as the goodness-of-ﬁt parameters approach the minimum (i) the direction\\nchosen by the method of steepest descent is not the most efﬁcient, and (ii)\\nthe numerical determination of the derivative (eqn 7.4), which involves the\\nsubtraction of two similar numbers, is error prone. For the case of Fig. 6.1(d)\\n2\\nat the 10−3 level within three\\nthe gradient-descent method converges to χmin\\niterations, see the inset to Fig. 7.5, whereas the grid-search method takes\\nnearly 30 iterations to achieve the same level of convergence as seen in the\\ninset to Fig. 7.3. Note, however, that in this case the gradient-descent method\\nfails to make more progress, due to errors in determining the difference in\\neqn (7.4).\\nAn obvious issue with the convergence properties of the gradient-descent\\nmethod is inherent in the update rule, eqn (7.5). Intuitively, we would like\\nto take large steps at locations where the gradient is small (along the valley\\nbottom, for example), and small steps when the gradient is steep (to avoid\\nthe problem of overshooting the valley bottom). Unfortunately the update\\nrule eqn (7.5) does the opposite of the intuitive strategy as the increment is\\np', 'roportional to the magnitude of the gradient. The gradient is perpendicular to\\nthe contour lines at the location where the gradient is evaluated, see Fig. 7.4.\\nAfter each iteration the direction of the gradient is orthogonal to the previous\\nstep direction and hence the trajectory across the error surface proceeds inefﬁciently in a zig-zag manner down the valley. Many of the problems associated\\nwith the method of steepest descent can be remedied by using knowledge of\\nthe curvature of the error surface (the second derivatives) in addition to the\\ngradient.\\nFig. 7.5 The evolution of χ 2 and the parameters as a function of iteration number for\\n2\\nis\\nthe gradient-descent method. χ 2 − χmin\\nshown on a log scale in the inset of (a).\\n\\n1 This is a matrix version of eqn (6.12) gener-\\n\\nalised to N dimensions; written explicitly as\\na summation over components it would\\n\\x02 read\\n\\x06\\n∂χ 2 \\x02\\x02\\nχ 2 (as + h) ≈ χ 2 (as ) + N\\nj=1 ∂a j \\x02 \\x12a j\\nas\\n\\x02\\n\\x042\\n\\x06N ∂ 2 χ 2 \\x02\\x02 \\x03\\n1\\n\\x12a j .\\n+ 2 j=1\\n\\x02\\n∂a 2j \\x02\\nas\\n\\n7.1.4\\n\\nSecond-order expansion: the Newton method\\n\\nThe shape of the error surface in the vicinity of the minimum is approximately\\nparabolic, see Fig. 6.10, therefore a second-order expansion in the parameters\\nabout the local minimum is an excellent approximation—this is the Newton\\nmethod. A Taylor-series expansion of χ 2 about the set of parameters as\\nyields1\\n1\\nχ 2 (as + h) ≈ χ 2 (as ) + gTs h + hT Hs h.\\n2\\n\\n(7.6)\\n\\nHere the small change in the parameters is the vector h; the gradient vector\\ngs (which has N components) is\\ngs = ∇χ 2 (as ) =\\n\\n∂χ 2\\n∂χ 2\\n,··· ,\\n∂a1\\n∂aN\\n\\nT\\n\\n,\\n\\n(7.7)\\n\\n\\x0c7.1 How do ﬁtting programs minimise? 89\\n\\nand the N × N Hessian matrix Hs is\\n⎡ ∂2χ 2\\n⎢\\n⎢\\nHs = H (as ) = ⎢\\n⎣\\n\\n∂a12\\n\\n..\\n.\\n\\n···\\n..\\n\\n∂2χ 2\\n∂a1 ∂aN\\n\\n∂2χ 2\\n∂a1 ∂aN\\n\\n.\\n\\n···\\n\\n..\\n.\\n\\n∂2χ 2\\n2\\n∂aN\\n\\n⎤\\n⎥\\n⎥\\n⎥.\\n⎦\\n\\n(7.8)\\n\\nIn these equations the superscript T denotes the transpose operation.2\\nAt the location of the minimum ∇χ 2 = 0, thus\\n\\n2 The elements of the transpose of a matrix\\n\\n∇χ 2 (as + h) = gs + Hs h = 0,\\n\\n(7.9)\\n\\nh = −H−1\\ns gs .\\n\\n(7.10)\\n\\nw', 'hich has the solution\\n\\nNote that if χ 2 has an exact quadratic dependence on the parameters then the\\nsolution of eqn (7.10) is exact, and the problem is solved in one step; else, the\\nprocess is iterative, and we use the update rule for the next iterate:\\nas+1 = as + h = as − H−1\\ns gs .\\n\\n(7.11)\\n\\nThere exist many efﬁcient matrix methods for solving the set of linear equations (7.10). Newton’s method has a quadratic convergence (the number of\\naccurate digits of the solution doubles in every iteration). Often the method\\nproceeds with a line minimisation, with a scaled step size (as described in\\nSection 7.1.3). Note that if the Hessian matrix is equal to the unit matrix\\n(H = 1) then this method is equivalent to the method of steepest descent.\\n\\n7.1.5\\n\\nSecond-order expansion: the Gauss–Newton method\\n\\nNewton’s method involves calculating and inverting the Hessian matrix, which\\ncontains second-order derivatives of the χ 2 surface. In the Gauss-Newton\\nmethod a simpler approximate form of the Hessian is used, as outlined below.\\nLet us rewrite χ 2 as a sum over the N data points of normalised residuals:\\nχ =\\n2\\n\\nN\\n\\x05\\n\\nRi2 ,\\n\\n(7.12)\\n\\ni=1\\n\\nwith\\nRi =\\n\\nyi − y (xi ; a)\\n.\\nαi\\n\\nWe deﬁne the (N × N ) Jacobian matrix as follows:\\n⎤\\n⎡ ∂R\\n∂ R1\\n1\\n∂a1 · · · ∂aN\\n⎢ . .\\n. ⎥\\n⎥\\nJs = J (as ) = ⎢\\n⎣ .. . . .. ⎦ .\\n∂ RN\\n∂ RN\\n∂a1 · · · ∂aN\\n\\n(7.13)\\n\\n(7.14)\\n\\nare related to the elements\\n\\x10 \\x11 of the original\\n= Ak j .\\nmatrix by the relation AT\\njk\\n\\n\\x0c90\\n\\nComputer minimisation and the error matrix\\n\\nConsider the gradient of χ 2 with respect to the parameter a j :\\nN\\nN\\n\\x05\\n∂χ 2\\n∂ Ri\\n∂ \\x05 2\\n=\\nRi = 2\\nRi .\\n∂a j\\n∂a j\\n∂a j\\ni=1\\n\\n(7.15)\\n\\ni=1\\n\\nWe see that we can write\\n∇χ 2 = ∇\\n\\nN\\n\\x05\\n\\nRi2 = 2 JT R.\\n\\n(7.16)\\n\\ni=1\\n\\nHere R is a column vector with N entries for the residuals. The elements of\\nthe Hessian matrix are\\n\\x05 ∂ Ri ∂ Ri\\n\\x05\\n∂ 2 Ri\\n∂2 \\x05 2\\n∂ 2χ 2\\n=\\nRi = 2\\n+2\\nRi\\n. (7.17)\\n∂a j ∂ak\\n∂a j ∂ak\\n∂a j ∂ak\\n∂a j ∂ak\\ni\\n\\n3 Note that ignoring some of the terms in the\\n\\ndeﬁnition of the Hessian inﬂuences the trajectory across the error surface, but h', 'as no\\nbearing on the values of the ﬁt parameters to\\nwhich the iterative procedure converges.\\n\\ni\\n\\ni\\n\\nThis equation contains two summations; the ﬁrst over the product of gradients,\\nthe second over second-order derivatives. If the second set of terms is ignored,\\nit is possible to approximate the Hessian in the compact form H ≈ 2JT J. The\\njustiﬁcation for this approximation comes from looking at the magnitude of\\nthe term multiplying the second-order derivative: it is simply the normalised\\nresidual Ri . Typically, the normalised residuals should be small, and in the\\n2\\nscattered randomly around zero; hence, on being summed,\\nvicinity of χmin\\nthese terms should make a negligible contribution to the Hessian. By throwing\\naway the second order terms the Hessian is much simpler to evaluate, thereby\\nmaking the method more efﬁcient.3\\nThe main advantage of the Gauss–Newton method is that the minimisation\\nrequires much fewer steps to converge than the previously discussed methods.\\nThe major disadvantage is that the method cannot be relied upon to converge\\ntowards the minimum if the initial trial solution is outside the region where\\nthe error surface is parabolic. As the second-order expansion methods use the\\ncurvature of the error surface the method will not work in regions where the\\ncurvature has the wrong sign.\\n\\n7.1.6\\n\\nThe Marquardt–Levenberg method\\n\\nA more robust ﬁtting strategy is one in which the best elements of the expansion and gradient approach are combined. Ideally this ﬁtting routine would use\\nthe method of steepest descent to progress towards the minimum when the trial\\nsolution was far from the optimum values and, as the goodness-of-ﬁt parameter\\nreduces, the minimisation would switch smoothly to an expansion method as\\nthe minimum was approached and the surface becomes parabolic.\\nBuilding on the insight that the gradient descent and Gauss–Newton\\nmethods are complementary, Levenberg suggested the following update rule\\n(Levenberg 1944):\\nas+1 = as − (Hs + λ1)−1 gs .\\n\\n(7.18)', '\\n\\nThe positive constant λ is usually referred to as the damping, or regularisation,\\nconstant. Large values of λ are used when the trial solution is far from the\\n\\n\\x0c7.1 How do ﬁtting programs minimise? 91\\n\\nminimum; in this case eqn (7.18) reverts to the method of steepest descent,\\neqn (7.5). By contrast, when the trial solution approaches the optimum value,\\nthe error surface becomes parabolic, and smaller values of λ are used such that\\nthe quadratic convergence properties of the Newton method are deployed.\\nMarquardt provided the further insight which remedies one of the major\\ndrawbacks of the gradient-descent method discussed in Section 7.1.3, namely\\nthe zig-zagging along a valley. Marquardt modiﬁed the update rule to take into\\naccount the magnitude of the curvature, in such a way that large steps are taken\\nin directions with small curvatures, and smaller steps in directions with large\\ncurvatures (Marquardt 1963). In the modiﬁed update rule the identity matrix\\nof eqn (7.18) is replaced with the diagonal elements of the Hessian matrix:\\n\\x03\\n\\x15 \\x16\\x04−1\\ngs .\\nas+1 = as − Hs + λ diag Hs\\n\\n(7.19)\\n\\nEffectively, the elements of the Hessian matrix are modiﬁed according to the\\nrule\\nH j j → H j j (1 + λ)\\nH jk → H jk\\n\\n( j \\x11 = k)\\n\\n(7.20)\\n\\nand for large λ the matrix becomes diagonally dominant.\\nThere is a geometrical interpretation of the Marquardt–Levenberg method.\\nAt any given point on the error surface away from the minimum the direction of\\nthe subsequent steps of the minimisation routine for the gradient and expansion\\nmethods are nearly perpendicular. The Marquardt–Levenberg method uses the\\nparameter λ to vary the angle of the trajectory. Far from the minimum the\\ntrajectory follows the path of steepest descent and smoothly changes to that\\nof the expansion trajectory as the minimum is approached and the parabolic\\napproximation becomes increasingly valid. A thorough discussion of how\\nto choose initial values for λ and how to update λ during the minimisation\\nprocedure can be found in Pres', 's et al. (1992).\\nAlthough more complex, the Marquardt–Levenberg algorithm is clearly\\nsuperior to any of the previously discussed minimisation routines. It is the\\nminimisation method used in almost all ﬁtting packages and should be used\\nwhenever possible.\\nTable 7.1 provides a summary of the update formulae used by the ﬁve\\nalgorithms discussed above.\\nTable 7.1 Formulae used to update the next iterate\\n(as+1 = as + h) for the ﬁve optimisation methods\\ndiscussed in the text. g is the gradient vector, H is the\\nHessian matrix, and J is the Jacobian matrix.\\nGradient descent\\n\\nh = −βg\\n\\nNewton\\n\\nH h = −g\\n2JT J h = −g\\n\\nGauss–Newton\\nLevenberg\\nMarquardt–Levenberg\\n\\n(H + λ1) h = −g\\n\\x15 \\x16\\x04\\nH + λ diag H h = −g\\n\\n\\x03\\n\\n\\x0c92\\n\\nComputer minimisation and the error matrix\\n\\nIn the ﬁnal stages of the Marquardt–Levenberg algorithm the matrix used in\\nthe update rule approaches the Hessian. After convergence at the desired level\\nhas been achieved, the update matrix can be evaluated with λ = 0; this process\\nyields the Hessian evaluated with the best-ﬁt parameters. The elements of this\\nmatrix quantify the curvature of the parabolic error surface in the vicinity of\\nthe minimum, and are used to evaluate the uncertainties in the ﬁt parameters.\\n\\n7.2\\n7.2.1\\n\\n4 The curvature matrix is also an N × N\\n2\\nmatrix with components A jk = 12 ∂a∂χ∂a .\\nj k\\n\\n5 For uncertainties which are not normally\\n\\ndistributed one often uses Monte Carlo techniques to ascertain which is the appropriate\\n\\x12χ 2 contour; see Chapter 9.\\n\\nThe covariance matrix and uncertainties\\nin ﬁt parameters\\nExtracting uncertainties in ﬁt parameters\\n\\n2 +1\\nThe uncertainty of a parameter α j is deﬁned as the extremum of the χmin\\ncontour along the a j -axis. As we saw in Chapter 6, when the parameter moves\\naway from its optimal value by an amount equal to \\x12a = a j − ā j = α j , χ 2\\n2\\nevolves to χmin\\n+ 1. We now wish to utilise the matrix methods introduced in\\nthe previous section to calculate the uncertainties in the N ﬁt parameters.\\nIt becomes convenient to re', 'move some of the factors of 2 in the earlier discussion by deﬁning the curvature matrix, A, which is equal to one-half of the\\nHessian matrix.4 The off-diagonal terms are related to the degree of correlation\\nof the uncertainties in the parameters, as they describe the curvature of the χ 2\\nsurface along directions which are not collinear with a parameter axis.\\nThe matrix which is the inverse of the curvature matrix is called the covariance, or error matrix, C:\\n\\x15 \\x16 \\x15 \\x16−1\\n.\\n(7.21)\\nC = A\\n\\nThe elements of the covariance matrix quantify the statistical errors on the\\nbest-ﬁt parameters arising from the statistical ﬂuctuations of the data. If the\\nuncertainties in the measurements are normally distributed then we can extract\\nquantitative information from the error matrix.5 In Chapter 6 we derived\\nthe result for the error in one dimension by analysing the \\x12χ 2 = 1 contour\\n(eqn 6.13); the variance (the uncertainty squared) was seen to be inversely\\nproportional to the curvature of the error surface (eqn 6.12). With N ﬁt\\nparameters we extend the discussion in Section 6.5.2, such that the contour\\n2\\n+ 1 has tangent planes located at ±\\non the error surface deﬁned by χmin\\nthe uncertainties displaced from the optimal values. The matrix equivalent of\\nlocating the \\x12χ 2 = 1 contour shown graphically in two dimensions in Fig. 6.8\\ncan be obtained from eqns (7.6) and (7.21); it can be shown (see Press 1992,\\nSection 15.6) that the uncertainty, α j , in the parameter a j is\\n\\x12\\nαj = Cjj.\\n(7.22)\\nThis is the most important result for calculating the uncertainties in ﬁt parameters having performed a χ 2 minimisation:\\nThe variance in the j th parameter is given by C j j , the j th diagonal element\\nof the error matrix evaluated with the best-ﬁt paramters.\\n\\n\\x0c7.3 Correlations among uncertainties of ﬁt parameters 93\\n\\nIn the case where the errors are uncorrelated, the off-diagonal terms of\\nthe curvature matrix are zero and the diagonal elements of the covariance\\nmatrix are simply the inverse of the indi', 'vidual elements of the curvature matrix,\\n\\x03\\n\\x04−1\\n. However, in the more general case where the errors are\\ni.e. C j j = A j j\\ncorrelated, the diagonal elements of the error matrix are not equal to the inverse\\nof the diagonal elements of the curvature matrix, and the matrix inversion of\\neqn (7.21) must be performed.\\n\\n7.2.2\\n\\nCurvature matrix for a straight-line ﬁt\\n\\nIn the previous section we saw that in the ﬁnal stages of a Marquardt–\\nLevenberg ﬁtting procedure the curvature matrix is evaluated at the best-ﬁt\\nparameters. When ﬁtting a straight line to a data set the two-dimensional error\\nsurface has the same curvature with respect to the slope and intercept for\\nany values of these two parameters. Hence, in this special case, the curvature\\nmatrix can be calculated quite simply, without even having to perform the leastsquares ﬁt.\\nFor the special case of ﬁtting to y = mx + c the four elements of the\\ncurvature matrix are given by (see Exercise (7.7) for a derivation)\\n\\x05 1\\n,\\n(7.23)\\nAcc =\\nαi2\\ni\\n\\x05 xi\\nAcm = Amc =\\n,\\n(7.24)\\nαi2\\ni\\nAmm =\\n\\n\\x05 x2\\ni\\ni\\n\\nαi2\\n\\n.\\n\\n(7.25)\\n\\nThe error matrix can thus be found simply by inverting this 2 × 2 matrix.6\\n\\n7.2.3\\n\\nScaling the uncertainties\\n\\nInherent in the discussion so far about extracting error bars on ﬁt parameters\\nis that the model is a good ﬁt to the data. There are circumstances where the\\n2 obtained is slightly larger than the ideal one. In this case the\\nvalue of χmin\\nuncertainties in the parameters are often scaled. This topic is discussed further\\nin Chapter 8.\\n\\n7.3\\n7.3.1\\n\\nCorrelations among uncertainties of ﬁt\\nparameters\\nCorrelation coefﬁcients—off-diagonal elements\\nof the covariance matrix\\n\\nIn Chapter 4, when developing a calculus-based approximation for the propagation of errors through multi-variable functions, we discarded the offdiagonal terms, arguing that they were zero for independent variables. If we\\n\\n6 Recall that\\n(\\n)−1\\n\\nA\\nC\\n\\nB\\nD\\n\\n=\\n\\n1\\nAD − BC\\n\\n(\\n\\nD\\n−C\\n\\n)\\n−B\\n.\\nA\\n\\n\\x0c94\\n\\nComputer minimisation and the error matrix\\n\\n7 N − 1 appears in the ', 'denominator, as it did\\n\\nare to calculate a quantity that is a function of more than one of the ﬁt\\nparameters, our calculation needs to take into account the correlations among\\nthe uncertainties extracted from the ﬁt. The magnitude of these correlations\\nis contained within the off-diagonal elements of the covariance matrix, C jk ,\\nwhich are correlation coefﬁcients of the ﬁt uncertainties α j and αk . Note that\\nthe diagonal components C j j are necessarily positive, while the off-diagonal\\nelements C jk can be negative.\\nWe illustrate the concept of covariance of two variables as follows. Consider\\nZ which is a function of two variables A and B, Z = f (A, B). Let there be\\nN pairs of measurements of A and B, (Ai , Bi ). For the N measurements of\\nA we can compute the mean, A, and standard deviation σ A , and similarly for\\nB. We can also calculate N values of the function Z i = f (Ai , Bi ). Assuming\\nthat the errors are small we can use a ﬁrst-order expansion to ﬁnd the spread\\nof values of Z i :\\n\\x03\\n\\x04 \\x03\\n\\x04 ∂Z \\x03\\n\\x04 ∂Z\\n+ Bi − B\\n.\\n(7.26)\\nZ i ≈ f A, B + Ai − A\\n∂A\\n∂B\\n\\x03\\n\\x04\\nIt is easy to show that the mean value of Z is given by Z = f A, B . We can\\ncalculate the sample variance of the N values of Z i as follows:7\\n\\nin Chapter 2, on account of the fact that we\\nhave one fewer degree of freedom, as the\\nmean is calculated from the data.\\n\\n\\x042\\n1 \\x05\\x03\\nZi − Z ,\\nN −1\\nN\\n\\nσ Z2 =\\n\\n(7.27)\\n\\ni=1\\n\\nthen from eqn (7.26) we have:\\n\\x0f\\nN \\x0e\\n\\x04 ∂Z \\x03\\n\\x04 2\\n1 \\x05 ∂Z \\x03\\nσ Z2 =\\nAi − A +\\nBi − B\\nN −1\\n∂A\\n∂B\\n\\x0e\\nσ Z2 =\\n\\ni=1\\n\\n∂Z\\n∂A\\n\\n\\x0e\\n\\n\\x0f2\\n\\nσ A2 +\\n\\n∂Z\\n∂B\\n\\n\\x0f2\\nσ B2 + 2\\n\\n∂Z ∂Z\\nσ AB .\\n∂A ∂B\\n\\n(7.28)\\n\\nIn eqn (7.28) σ A2 and σ B2 are the variances of A and B, respectively, and we\\nhave also introduced the covariance σ AB , deﬁned as\\nσ AB\\n\\nN\\n\\x04\\x03\\n\\x04\\n1 \\x05\\x03\\nAi − A Bi − B .\\n=\\nN −1\\n\\n(7.29)\\n\\ni=1\\n\\nWe can extend the discussion of the covariance between two sets of variables\\nto the covariance between ﬁt parameters. Recall that the uncertainty in a\\nparameter we extract from a ﬁt is the standard error, which is the standard\\ndeviation of the mean. Hence w', 'e can use eqn (7.29) for the propagation of\\nuncertainties in correlated variables, with α to be substituted for σ . Note that\\nthe variances and covariance do not necessarily have to have the same units.\\nIt is often easier to use a dimensionless measure of the correlation of two\\nvariables, and to this end we introduce the (N × N ) correlation matrix. The\\ndiagonal elements equal one, and the off-diagonal elements, ρ AB , are called\\ncorrelation coefﬁcients, and are deﬁned as\\nρ AB =\\n\\nσ AB\\nC AB\\n=√\\n.\\nσAσB\\nC A AC B B\\n\\n(7.30)\\n\\n\\x0c7.4 Covariance in error propagation 95\\n\\nCorrelation coefﬁcients are dimensionless quantities constrained to the range\\n−1 ≤ ρ AB ≤ 1. If the two variables are uncorrelated then ρ AB ≈ 0; if ρ AB\\nis close to 1 the variables are strongly positively correlated (a positive value\\nof Ai − A is likely to be associated with a positive value of Bi − B); and\\nif ρ AB is close to −1 the variables are strongly negatively correlated (a\\npositive value of Ai − A is likely to be associated with a negative value of\\nBi − B).\\nWe illustrate the concepts of covariance and correlations of two variables\\nA and B graphically in Fig. 7.6 which shows a scatter plot of 30 pairs\\nof measurements of (Ai , Bi ). In part (a) there is strong positive correlation\\nbetween the variables (ρ AB = 0.95); in (b) there is moderate positive correlation (ρ AB = 0.60); in (c) there is very little correlation (ρ AB = −0.02); and in\\n(d) there is strong negative correlation (ρ AB = −0.81).\\nThe off-diagonal element C jk of the covariance matrix contains information\\nabout the correlation between the uncertainties in the parameters a j and ak .\\nThis information can be incorporated into error-propagation calculations, as\\nwe show in the next section.\\n\\n7.4\\n\\nCovariance in error propagation\\n\\nIn this section we provide a look-up table for some common functions of\\ntwo correlated variables, and we illustrate the concepts introduced in the last\\nsection by an example, including the very important case of the cal', 'ibration\\ncurve.\\nTable 7.2 Some rules for the propagation of errors with two correlated variables.\\nFunction, Z ( A, B)\\n\\nExpression used to calculate α Z\\n\\nZ = A±B\\n\\nα 2Z = α 2A + α 2B ± 2α AB\\n\\x10 α \\x112\\nZ\\n\\nZ = A×B\\nZ=\\n\\n7.4.1\\n\\nZ\\n\\x10 α \\x112\\n\\nA\\nB\\n\\nZ\\n\\nZ\\n\\n=\\n=\\n\\n\\x10 α \\x112\\nA\\n\\nA\\n\\x10 α \\x112\\nA\\n\\nA\\n\\n+\\n+\\n\\n\\x10 α \\x112\\nB\\n\\nB\\n\\x10 α \\x112\\nB\\n\\nB\\n\\n+2\\n−2\\n\\n\\x10α\\n\\nAB\\n\\n\\x11\\n\\nAB\\n\\x10α\\n\\nAB\\n\\n\\x11\\n\\nAB\\n\\nWorked example 1—a straight-line ﬁt\\n\\nIn Fig. 6.9 in Chapter 6 we saw the χ 2 contours for the two parameters, slope\\nand intercept. As the iso-χ 2 ellipses are tilted we expect to ﬁnd a correlation\\nbetween the uncertainties of the ﬁt parameters. Using eqns (7.24)–(7.25) from\\nSection 7.2.2, we calculate the curvature matrix A to be:\\n(\\n\\n0.362 (mV)−2\\nA=\\n20.6 Hz(mV)−2\\n\\n)\\n20.6 Hz(mV)−2\\n.\\n1538 (Hz)2 (mV)−2\\n\\nFig. 7.6 An illustration of the linear correlation between two variables A and B.\\nIn (a) there is strong positive correlation between the variables (ρ AB = 0.95);\\nin (b) there is moderate positive correlation\\n(ρ AB = 0.60); in (c) there is very little correlation (ρ AB = −0.02); and in (d) there is\\nstrong negative correlation (ρ AB = −0.81).\\n\\n\\x0c96\\n\\nComputer minimisation and the error matrix\\n\\nBy inverting the curvature matrix we obtain the error matrix:\\n(\\n)\\n11.5 (mV)2\\n−0.153 (mV)2 Hz−1\\nC=\\n.\\n−0.153 (mV)2 Hz−1 0.0027 (mV)2 (Hz)−2\\nThe square roots of the diagonal elements (to one signiﬁcant ﬁgure) are 3 mV\\nand 0.05 mV/Hz, which are the uncertainties in the intercept and slope, respectively, reported in Table 6.1. The correlation matrix is\\n(\\n)\\n1.00\\n−0.871\\n.\\n−0.871\\n1.00\\nThe negative off-diagonal element reﬂects the fact that the ellipse is tilted in\\nsuch a way that, for a given value of χ 2 , an increase in gradient is accompanied\\nby a decrease in intercept. Let us now use these ﬁt parameters to predict the\\nexpected value, V , of the voltage, and its error, at a frequency, f , of 75 Hz.\\nThe quantities are related by the expression V = m f + c, thus V = 2.03 ×\\n75 − 1 = 151 mV. If we were to ignore the correlation of the uncertainties the\\nerror in V ', 'would be calculated using the ﬁrst entry in Table 4.2 as\\n2\\n+ αc2 = f 2 C22 + C11 ,\\nαV2 = f 2 αm\\n\\n(7.31)\\n\\nwhere we have made use of the fact that the variances in the parameters are\\nequal to the diagonal\\n\\x12 elements of the error matrix. Inserting numerical values,\\nwe obtain αV = 752 × 0.0027 + 11.5 = 5 mV.\\nIncorporating the correlation into our calculation using the ﬁrst entry of\\nTable 7.2 yields a different result:\\nαV2 = f 2 C22 + C11 + 2 f C12 .\\n\\n8 Note that the value of the predicted voltage\\n\\n(151 mV in this case) does not change if the\\ncorrelations in the uncertainties are included.\\n\\n(7.32)\\n\\nNote the presence\\nof the covariance term in eqn (7.32). Inserting numerical val\\x12\\n2\\nues, αV = 75 × 0.0027 + 11.5 + 2 × 75 × −0.153 = 2 mV. With respect\\nto the result obtained without the correlation term, this is (a) different, and (b)\\nreduced—a consequence of the correlation being negative.8\\n\\n7.4.2\\n\\nWorked example 2—a four-parameter ﬁt\\n\\nWe saw qualitatively for the data plotted in Fig. 6.11 that the values of the\\nbackground and peak centre extracted from the ﬁt were largely uncorrelated,\\nwhereas the values of the background and peak width were strongly correlated.\\nWe can analyse the degree of correlation for the ﬁt more quantitatively by\\nanalysing the terms in the correlation matrix. In this example, the correlation\\nmatrix is\\n⎡\\n⎤\\n1.00\\n−0.64\\n0.94\\n−0.25\\n⎢−0.64\\n1.00\\n−0.53 0.0893 ⎥\\n⎢\\n⎥.\\n⎣ 0.94\\n−0.53\\n1.00\\n−0.297⎦\\n−0.25 0.0893 −0.297\\n1.00\\nHere, the ﬁrst parameter is the amplitude, the second the background, the\\nthird the peak width, and the fourth the centre. As expected the correlation of\\nthe background and peak centre is small, ρ24 = 0.089; and the correlation\\n\\n\\x0cExercises\\n\\n97\\n\\nof the background and peak width is strong and negative, ρ23 = −0.53. Note\\nalso that as ρ13 = 0.94 there is a strong positive correlation between the\\namplitude and peak width—one can trade off an increase in the peak height\\nand width by reducing the background.\\n\\nChapter summary\\n• Computer codes ﬁnd the minim', 'um of χ 2 by the use of iterative algorithms for the ﬁt parameters.\\n• In the vicinity of a minimum of χ 2 , the gradient of χ 2 with respect to\\nthe ﬁt parameters is zero.\\n• Far from the minimum a method based on knowledge of the gradient\\nof the error surface with respect to the ﬁt parameters (the method of\\nsteepest descent) can be used to head in the direction of the minimum.\\n• In the vicinity of the minimum, the error surface is a quadratic function\\nof the changes of parameters from their optimal values, and secondorder (Newton) methods based on quadratic expansion are used.\\n• The behaviour of χ 2 in the vicinity of a minimum is governed by the\\nsecond-order derivatives contained in the Hessian matrix, H.\\n• The Marquardt–Levenberg method combines the best features of gradient descent and expansion, and is ubiquitous in minimisation algorithms.\\n• The curvature matrix, A, is equal to one-half of the Hessian matrix.\\n• The error matrix, C, is the inverse of the curvature matrix.\\n• The variance in the j th parameter is given by C j j , the j th diagonal\\nelement of the error matrix.\\n• The off-diagonal elements of the error matrix contain information about\\nthe correlation of the uncertainties of the ﬁt parameters.\\n• The linear correlation coefﬁcient ρi j quantiﬁes the correlation between\\nthe i th and j th parameters.\\n\\nExercises\\n(7.1) Convergence properties of Newton’s method\\nWe investigate the convergence properties of the\\nNewton–Raphson method to ﬁnd zeroes of a function\\npresented in Section\\n√ 7.1.1 by example. Let us ﬁnd an\\napproximation to 26 to 10 decimal places. This process\\nis equivalent to ﬁnding the zero crossing of the function\\nf (x) = x 2 − 26. We use the equation\\nxs+1 = xs −\\n\\nf (xs )\\n(xs )2 − 26\\n=\\nx\\n−\\n,\\ns\\nf \\x0e (xs )\\n2xs\\n\\n\\x0e\\nwhere the derivative of the\\n√ function, f (x) = 2x, has\\nbeen substituted. (a) As 25 = 5, we start with the\\nguess of x1 = 5. Show that the next iterations are:\\nx2 = 5.1, x3 = 5.099 019 607 843, x4 = 5.099 019 513 593,\\nand x5 = 5.099 019 513 593.', ' Note how convergence\\nto better than 10 decimal places is achieved with only\\nﬁve iterations. (b) What solution do you obtain with an\\ninitial guess of x1 = −5? Explain your answer. (c) What\\nsolution do you obtain with an initial guess of x1 = 0?\\nExplain your answer.\\n\\n\\x0c98\\n\\nComputer minimisation and the error matrix\\n(7.2) Newton’s method for ﬁnding maxima and minima\\nModify the results of Section 7.1.1 to derive the result\\nfor the approximate location, xs+1 , of the maximum\\nor minimum of a function, given the value of the ﬁrst,\\nf \\x0e (xs ), and second derivatives, f \\x0e\\x0e (xs ), of the function\\nat the current location, xs :\\nxs+1 = xs −\\n\\nf \\x0e (xs )\\n.\\nf \\x0e\\x0e (xs )\\n\\n(7.3) Finding the minimum of a parabola from three points\\nConsider the variations in χ 2 with respect to the parameter ak . Let the step size be \\x12. The grid-search method\\nproceeds with χ 2 reducing as more step sizes are made,\\nuntil the ﬁrst occurrence of an increase in χ 2 . The last\\ntwo values of ak must bracket the value at which χ 2\\nis minimised. Using the last three values it is possible\\nto calculate the value where the minimum occurs. Let\\nak + \\x12 and\\nthe three values of the parameter be *\\nak , *\\n*\\nak + 2\\x12, and the values of χ 2 for those parameters be\\nχ12 , χ22 and χ32 , respectively. (a) Show that the minimum\\nχ 2 is achieved at a value of\\n\\x12\\nak +\\nak = *\\n2\\n\\n\\x0e\\n\\n3χ12 −4χ22 +χ32\\nχ12 −2χ22 +χ32\\n\\n\\x0f\\n,\\n\\nassuming a parabolic dependence of χ 2 on ak near the\\nminimum. (b) Recalling that the uncertainty, αk , in the\\nparameter ak is ascertained by ﬁnding the increase from\\nthe minimum which will increase χ 2 by 1, show that\\n\\x1c\\nαk = \\x12\\n\\n2\\n\\n.\\nχ12 −2χ22 +χ32\\n\\n(7.4) Error propagation for correlated errors\\nAssume in this question that the uncertainties in A and\\nB are correlated. Verify the results in Table 7.2. (i) If\\nZ = A ± B, show that α 2Z = α 2A + α 2B ± 2α AB .\\n(ii) If Z = A × B, show that\\n\\x03 AB \\x04\\n\\x03 α Z \\x042 \\x03 α A \\x042 \\x03 α B \\x042\\n= A + B + 2 αAB\\n.\\nZ\\n(iii) If Z = BA , show that\\n\\x03 AB \\x04\\n\\x03 α Z \\x042 \\x03 α A \\x042 \\x03 α B \\x042\\n.\\n= A + B − 2 αAB\\nZ\\n(7.5)', ' Geometry of error calculation in two dimensions\\nIn two dimensions the covariance matrix is written\\nC=\\n\\nα12\\nρα1 α2\\n\\nρα1 α2\\n.\\nα22\\n\\nShow that the inverse of the covariance matrix can be\\ncast in the following form:\\n\\n⎡\\n\\n1\\nα12\\n−1\\n1\\n⎣\\nC =\\n1−ρ 2 − ρ\\nα1 α2\\n\\n− α1ρα2\\n1\\nα22\\n\\n⎤\\n⎦.\\n\\nShow that the two eigenvalues λ± of the covariance\\nmatrix are\\n\\x1e\\n\\x1d\\n\\x1c\\n\\x10\\n\\x112\\n1\\nα12 + α22 ±\\nα12 + α22 + 4ρ 2 α12 α22 .\\nλ± =\\n2\\nThe\\neigenvectors\\ncan be written as\\n\\x0e two\\x0f orthonormal\\n\\x0e\\n\\x0f\\ncos φ\\n− sin φ\\nand\\n, where φ is the angle of the\\nsin φ\\ncos φ\\n2\\nmajor axis of the χ + 1 contour. Show that the angle φ\\nis given by\\ntan 2φ =\\n\\n2ρα1 α2\\nα12 − α22\\n\\n.\\n(7.6) Terms in the correlation matrix\\nShow that the diagonal terms of the correlation matrix\\nare equal to unity.\\n(7.7) Curvature matrix for a straight-line ﬁt\\n\\x05 (yi − y (xi ))2\\n, and that after an\\nRecalling that χ 2 =\\nαi2\\ni\\nexperiment has been performed the values of xi , yi and\\nαi are ﬁxed, show that\\n2 2\\n\\x06\\n(i) 12 ∂ χ2 = i 12 ,\\n∂c\\n\\nαi\\n\\n\\x06 xi\\n,\\n(ii) 12 ∂m∂c =\\nαi2\\n∂2χ 2\\n\\ni\\n\\x06 xi2\\n∂2χ 2\\n1\\n(iii) 2\\n=\\n2.\\n∂m 2\\ni αi\\n\\nHence verify the results given for the elements of the\\ncurvature matrix in Section 7.3.\\n(7.8) Using a calibration curve\\nA frequently encountered case where the correlation of\\nthe uncertainties must be taken into account is that of\\na calibration curve. Consider the following set of measurements from an optical-activity experiment, where the\\nangle of rotation of a plane-polarized light beam, θ, is\\nmeasured as a function of the independent variable, the\\nconcentration, C, of a sucrose solution.\\nC (g cm−3 )\\nθ (degrees)\\n\\n0.025 0.05\\n10.7\\n21.6\\n\\n0.075 0.100\\n32.4\\n43.1\\n\\nC ( g cm−3 ) 0.125 0.150 0.175\\nθ ( degrees) 53.9\\n64.9\\n75.4\\n\\n\\x0cExercises\\nThe errors in the angle measurement are all 0.1◦ , the\\nerrors in the concentration are negligible. A straight-line\\nﬁt to the data yields a gradient of 431.7 ◦ g−1 cm3 , and\\nintercept −0.03◦ . Show that the curvature matrix, A, is\\ngiven by\\n\\x10\\n\\x11\\n\\x10\\n\\x11⎤\\n⎡\\n0.00796 (◦ )−2\\n−0.0637 (◦ )−2 g cm−3\\n\\x11\\n\\x10\\n\\x11 ⎦,\\n\\x10\\nA=⎣\\n−0.0637 (◦ )−2 g cm−3 0.637 (g/◦ cm3 )2\\n', 'and that the error matrix is\\n\\x10\\n\\x11\\n\\x10\\n\\x11⎤\\n⎡\\n0.00714 (◦ )2\\n−0.0571 (◦ )2 g−1 cm3\\n\\x11\\n\\x10\\n\\x11 ⎦.\\n\\x10\\nC=⎣\\n−0.0571 (◦ )2 g−1 cm3 0.571 (◦ )2 g−2 cm6\\n\\n99\\n\\nThe entry for the intercept is in the top left-hand corner,\\nthat for the gradient in the bottom right-hand corner.\\nCalculate the associated correlation matrix. Use the\\nentries of the error matrix to answer the following questions: (i) what are the uncertainties in the best-ﬁt intercept and gradient? (ii) what optical rotation is expected\\nfor a known concentration of C = 0.080 g cm−3 , and\\nwhat is the uncertainty? and (iii) what is the concentration given a measured rotation of θ = 70.3◦ and what is\\nthe uncertainty?\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cHypothesis testing –\\nhow good are our\\nmodels?\\nIn Chapter 5 we introduced the goodness-of-ﬁt parameter, χ 2 . We have seen in\\nthe preceding chapters how minimisation of this statistic yields both the best\\nﬁt of a model to a data set and the uncertainties in the associated parameters.\\nImplicit in the discussion so far has been the assumption that the model was\\na correct description of the data. We have shown how various methods can be\\nused to answer the question ‘what is the best ﬁt to my data?’. However, there is\\noften a far more interesting question: ‘are my data consistent with the proposed\\nmodel?’. For instance, ‘is the best ﬁt to the data a straight line?’.\\nThe subject of this chapter is hypothesis testing in the context of error\\nanalysis. We will show how it is possible to use statistical tests to give a\\nprobability that a particular hypothesis is valid. In earlier chapters we presented\\ntechniques for reporting the best estimate of a parameter with its associated\\nuncertainty. We have shown that this uncertainty is a probabilistic statement of\\na conﬁdence limit, based on an appropriate theoretical model. In this chapter\\nwe extend this idea and apply statistical tests to hypotheses or concepts.\\n\\n8.1\\n\\nHypothesis testing\\n\\nThere exist several statistical tests that calculate the pro', 'bability that the data\\nmay be described by a given model. This is undertaken by deﬁning the\\nnull hypothesis, H0 , which is often the assumption that an obtained sample\\ndistribution can be described by a particular parent distribution. When we\\nextend these arguments to testing the quality of a particular ﬁt we test the\\nnull hypothesis that our data, yi (the sample distribution), is well modelled\\nby a particular function, y (xi ) (the parent distribution). Statistical techniques\\nallow the null hypothesis to be tested quantitatively to determine whether the\\nnull hypothesis should be rejected and an alternative hypothesis pursued. The\\ndefault in ﬁtting a model to a data set is that at a particular conﬁdence level\\nor probability there is no evidence that the null hypothesis should be rejected.\\nWe note that the null hypothesis is never accepted as there always remains\\na ﬁnite probability that an alternative hypothesis represented by a different\\nparent distribution would be a better description of the data and hence yield a\\nbetter ﬁt.\\nA statistic that is commonly used to test the signiﬁcance of the null hypothesis in the physical sciences is the χ 2 statistic. The sample distribution is tested\\n\\n8\\n8.1 Hypothesis testing\\n\\n101\\n\\n8.2 Degrees of freedom\\n\\n102\\n\\n8.3 The χ 2 probability\\ndistribution function\\n\\n104\\n\\n8.4 Using χ 2 as a hypothesis test\\n\\n105\\n\\n8.5 Testing the quality of a ﬁt\\nusing χ 2\\n\\n108\\n\\n8.6 Testing distributions using χ 2\\n\\n111\\n\\n8.7 Occam’s razor\\n\\n114\\n\\n8.8 Student’s t-distribution\\n\\n115\\n\\n8.9 Scaling uncertainties\\n\\n115\\n\\n8.10 Summary of ﬁtting\\nexperimental data\\nto a theoretical model\\n\\n116\\n\\nChapter summary\\nExercises\\n\\n117\\n118\\n\\n\\x0c102 Hypothesis testing\\n\\n1 In this case we compare the null hypothesis\\n\\nthat the data are well modelled by the function against the alternative that the statistical\\nvariation in the data set is random.\\n\\nagainst a particular parent distribution taking into account the experimental\\nuncertainties. We have already seen in Chapters 6 and 7 that minimising ', 'the\\nχ 2 statistic allows the best-ﬁt model parameters and their uncertainties to be\\n2 , is a numerical\\nestimated. The resulting minimum value of the χ 2 statistic, χmin\\nmeasure of the discrepancy between the proposed model and the data. As the\\nχ 2 statistic is summed over all the data points it is a quantitative measure\\nof how well the entire data set can be modelled with the proposed parent\\ndistribution and, as such, can be used as a test of the null hypothesis.\\nFor any given data set we can calculate the probability of obtaining a value of\\n2 or higher, given the proposed model.1 When this probability\\nχ 2 equal to χmin\\nis sufﬁciently low (5% and 1% are frequently used) we would reject the\\nhypothesis at the appropriate percentage level.\\n\\n8.2\\n\\nDegrees of freedom\\n\\nWe have seen in preceding chapters that it is possible to give estimates for\\nvarious statistical parameters based on different numbers of data points in a\\nset of measurements. The number of unconstrained variables is known as the\\nnumber of degrees of freedom, and represents the number of independent\\npieces of information that are used to evaluate an estimate of a parameter.\\nIn general, the degrees of freedom is equal to the number of independent\\ndata points used in the estimate minus the number of parameters used in the\\nestimation that have already been determined from the data set. When ﬁtting\\nN independent data points with a function with N parameters the number of\\ndegrees of freedom, ν, is:\\nν = N − N.\\n\\n(8.1)\\n\\nThe more data points that are unconstrained, the more robust a statistical\\nestimate of parameters such as the mean, variance and χ 2 become. We can also\\nconsider the degrees of freedom as the number of measurements exceeding the\\nbare minimum necessary to measure a certain quantity. This is a topic which\\ncan cause much confusion, largely as there are instances where it is not clear\\nwhether one should have many, or few, degrees of freedom. When a complex\\nsituation is being analysed, one often makes sim', 'plifying approximations, such\\nas restricting the motion to one dimension. The motivation is often ‘to reduce\\nthe number of degrees of freedom’, with the implication being that the smaller\\nthe number of degrees of freedom the better. Whereas this can represent the\\ncase for simplifying a physical situation before a mathematical description is\\nadopted, in the case of data analysis the opposite is the case—the more degrees\\nof freedom the better.\\nConsider the case of a measurement of a certain quantity comprising a single\\ndata point. It is obviously possible to ﬁt to the hypothesis that the quantity is\\nconstant, but no real information is gained from this hypothesis. For two data\\npoints, one can ask the more meaningful question ‘are the data consistent with\\na constant?’, but it is pointless to ask the question ‘are the data consistent with\\n\\n\\x0c8.2 Degrees of freedom 103\\n\\na straight line?’ as it is always possible to ﬁnd a straight line that goes through\\ntwo points. There is very little value in modelling a sample distribution with\\nN data points with a parent distribution with greater than N parameters. In\\ndata analysis it is more convincing to use as few constraints as possible when\\nﬁtting a data set, thus maximising the number of degrees of freedom. We will\\ndiscuss in Section 8.7 the concept of what constitutes enough constraints in a\\nhypothesis test.\\nEach parameter of the parent distribution estimated from the sample distribution reduces the number of unconstrained data points by 1. In Section 2.2\\nwe saw that the number of data points, N , appears in the denominator of the\\ndeﬁnition of the mean (eqn 2.1). However N − 1 appears in the denominator of\\nthe deﬁnition of the standard deviation of a sample (Section 2.3.2, eqn 2.2), as\\nthe mean had to be estimated from the same N data points, leaving only N − 1\\nunconstrained values. Moreover, eqn (5.6) used to evaluate the common uncertainty in linear regression in Section 5.2.1 has the factor N − 2 in the denominator as both th', 'e mean and intercept were calculated from the N data points.\\n\\n8.2.1\\n\\nData reduction and the number of degrees\\nof freedom\\n\\nWe have emphasised throughout this book that reducing a (potentially very\\nlarge) number of measurements to a handful of parameters and their errors is\\nthe modus operandi of data analysis. Here we reinforce the concept that having\\na large number of degrees of freedom is the ideal case. Consider the following\\nquiz question: ‘what number comes next in the sequence 1, 2, 4, 6 and 10?’.\\nThe ‘ofﬁcial answer’ is 12. The reasoning is that the series is the sequence of\\nprime numbers less 1. Consider the following function\\nf (x) = 5 − 8.5833x + 5.875x 2 − 1.4167x 3 + 0.125x 4 .\\n\\n(8.2)\\n\\nThis function has been designed to have the property f (1) = 1, f (2) = 2,\\nf (3) = 4, etc. For this function f (6) = 21, therefore we could argue with\\nthe quiz setter about the validity of their answer. By choosing a fourth-order\\npolynomial with ﬁve coefﬁcients we can describe the ﬁve terms of the sequence\\nexactly—there are no degrees of freedom. Obviously, it is impossible to do this\\nin general with a lower-order polynomial. However, we now need to keep all\\nﬁve coefﬁcients to describe the 5 terms in the sequence—this is very inefﬁcient,\\nand the opposite of data reduction.\\nWe can also use this example to highlight some of the issues with\\ninterpolation and extrapolation. There is only one fourth-order polynomial,\\nf (x) in eqn (8.2), which ﬁts the sequence exactly. However there are an\\ninﬁnite number of ﬁfth-order polynomials which ﬁt the ﬁve terms of the\\nsequence. Two of them are\\ng (x) = 14 − 29.133 x + 22.75 x 2 − 7.7917 x 3 + 1.25 x 4 − 0.075 x 5 ,\\nh (x) = 26 − 56.5333 x + 45.25 x 2 − 16.2917 x 3 + 2.75 x 4 − 0.175 x 5 .\\n\\n\\x0c104 Hypothesis testing\\n\\nThese functions have the desired property of being equal to the original\\nsequence for integer arguments, and also g (6) = 12, and h (6) = 0. Therefore\\nif we extrapolate the function g (x) we see it agrees with the ‘prediction’ of\\nt', 'he quiz question; whereas if we extrapolate h (x) we get a radically different\\nanswer. As seen in Fig. 8.1 both functions are smooth, and pass through the\\n‘data’, yet they predict very different behaviour outside the range over which\\nwe have data. By contrast, the difference when interpolating is smaller: for\\nexample g (3.5) = 4.84, and h (3.5) = 4.70.\\nFig. 8.1 The ﬁrst six numbers in the\\nsequence ‘prime number less one’ are shown\\nas solid circles. A fourth-order ﬁt to the ﬁrst\\nﬁve data points is shown, f (x), in addition\\nto two ﬁfth-order ﬁts, g (x) and h (x). Note\\nalso that although the curves show excellent\\nagreement over the range of x values for\\nwhich the data are deﬁned, they deviate\\nsubstantially outside this range, highlighting\\nthe difﬁculties inherent in extrapolation.\\n\\n2 The gamma function is related to the fac-\\n\\ntorial function. For positive integers n the\\ngamma function is equivalent to \\x14 (n + 1) =\\nn!, and for positive half-integers it is deﬁned\\n√\\nas \\x14 (n + 1/2) = π (2n)2n! .\\nn! 2\\n3 The median, m, of a continuous distribution\\n\\nfunction, PDF (x), is the value of x for which\\nthe probability of ﬁnding a value of x > m is\\nequal to the probability of ﬁnding x < m, i.e.\\nm\\n−∞\\n\\nPDF (x) dx =\\n\\n∞\\nm\\n\\nPDF (x) dx.\\n\\nThe mode of a probability function is the\\nvalue of x for which PDF (x) is a maximum.\\n\\n8.3\\n\\nThe χ 2 probability distribution function\\n\\nAs the χ 2 statistic is a random variable it also has a normalised probability\\ndistribution function, given by (Bevington and Robinson 2003, Chapter 11 and\\nSquires 2001, Appendix E):\\n\\x10\\n\\n\\x11\\n\\nX χ ;ν =\\n2\\n\\n\\x03\\n\\nχ2\\n\\n\\x04( ν2 −1)\\n2ν/2\\n\\n\\x15\\n\\x16\\nexp −χ 2 /2\\n,\\n\\x14 (ν/2)\\n\\n(8.3)\\n\\nwhere \\x14 (x) is the gamma function2 and ν is the number of degrees of freedom.\\nIt can be shown using the identities\\n\\x04 introduced in Chapter 3 for probability\\n\\x03\\ndistribution functions that X χ 2 ; ν has an expectation value, or mean, of ν\\n√\\nwith a standard deviation of σχ 2 = 2ν. As the χ 2 probability distribution\\nfunction is asymmetric it is worth noting\\nthat\\n\\x04 the median ', 'and mode do not\\n\\x03\\nhave the same value as the mean: X χ 2 ; ν has a median of approximately\\nν − 2/3 and a mode equal to ν − 2 for ν > 2, as seen in Fig. 8.2(a).3\\nAs with other probability distribution functions, the probability of obtaining\\n2\\nand ∞ is given by the cumulative probability\\na value of χ 2 between χmin\\n\\x04\\n\\x03 2\\nfunction, P χmin ; ν :\\n\\x10\\nP\\n\\n2\\nχmin\\n\\n\\x11\\n\\n∞\\n\\n≤ χ ≤ ∞; ν =\\n2\\n\\n\\x10\\n\\x11\\nX χ 2 ; ν dχ 2 .\\n\\n(8.4)\\n\\n2\\nχmin\\n\\nEquation (8.4) gives the probability that were the sample distribution drawn\\nfrom the hypothesised parent distribution, one would obtain a value of χ 2 equal\\n2 .\\nto, or greater than, χmin\\n\\x04\\n\\x03 2\\n; ν is accessible\\nFortunately the cumulative distribution function P χmin\\nin most spreadsheet and statistical packages and values for speciﬁc combina2\\ntabulated\\nin many statistical books. The two functions\\ntions\\n\\x04\\n\\x03 of χ\\x04 and ν\\x03 are\\n2 ; ν are plotted in Fig. 8.2.\\nX χ 2 ; ν and P χmin\\nThe forms of both functions are mathematically non-trivial due to the\\npresence of the gamma function and can be difﬁcult to evaluate as χ 2 → 0.\\nThe asymmetry of the χ 2 distribution for low ν is clear in Fig. 8.2(a). This\\nasymmetry is described by the degree of skewness in the function, which\\nfor the χ 2 distribution reduces slowly as the number of degrees of freedom\\nincreases. The corresponding cumulative probability distributions for the χ 2\\ndistributions in Fig. 8.2(a) are shown in Fig. 8.2(b).\\n\\n\\x0c8.4 Using χ 2 as a hypothesis test\\n\\nFor one degree of freedom, eqn (8.3) takes the simpler form (Bevington and\\nRobinson 2003, p. 197):\\n\\x11 exp \\x15−χ 2 /2\\x16\\n\\x10\\n2\\n(8.5)\\nX χ ; 1 = \\x17\\x03\\n\\x04 .\\n2π χ 2\\nIn Chapter 6 we saw that to extract the uncertainty in a parameter one needs to\\nreduce an N -dimensional error surface to a single one-dimensional slice that\\nmaps the shape of the error surface with respect to one of the parameters in the\\n2 with all remaining parameters re-optimised to minimise χ 2 .\\nvicinity of χmin\\nThe variation in χ 2 around the minimum, \\x12χ 2 , must obey the χ 2 distribution\\nfor one degree o', 'f freedom (eqn 8.5). The cumulative probability distribution\\nfor one degree of freedom can be used to ﬁnd the probability of obtaining\\na value of \\x12χ 2 of, say, 1 or higher. In Fig. 8.3 we show the percentage\\n2 + \\x12χ 2 ) as\\nprobability of obtaining a value of χ 2 of less than or equal to (χmin\\n2\\na function of \\x12χ . The values in Table 6.2 are obtained from the curve shown\\nin Fig. 8.3. The probability of obtaining a value of \\x12χ 2 up to one is 68%.\\nThe other conﬁdence limits for \\x12χ 2 in Table 6.2 are shown as solid points in\\nFig. 8.3.\\n\\n8.4\\n\\nX (χ2; 2)\\n\\nχ 2 for one degree of freedom\\n\\nP (χ2min; 2)\\n\\n8.3.1\\n\\n105\\n\\nχ2min\\n\\nFig. 8.2 (a) The normalised χ 2 probability\\ndistribution function for ν = 1, 4, 7 and 10\\nwith (b) the corresponding cumulative probability functions.\\n\\nUsing χ 2 as a hypothesis test\\n\\nWe can use eqns (8.3) and (8.4) to perform our hypothesis test. We expect\\n2\\nthat if the proposed model is in good agreement with the data that χmin\\n2\\n2\\nwill be close to the mean of the χ distribution and so χmin ≈ ν. For\\nmany degrees of freedom the χ 2 distribution becomes more symmetric\\nand the median, mode and mean become similar and we would expect for\\na good match \\x03 between sample\\nand parent distributions a corresponding\\n\\x04\\n2 ≈ ν; ν ≈ 0.5. We learn about the quality of the\\nprobability P χmin\\n\\x03 2\\n\\x04\\nagreement between sample and parent by analysing P χmin\\n; ν , the\\n2\\nprobability of obtaining the observed value, or higher, of χmin\\nfor a given\\nnumber of degrees of freedom.\\n2\\nis signiﬁcantly greater than ν the probability,\\nIf the value of χmin\\n\\x04\\n\\x03 2\\nP χmin > ν; ν , is small, as seen in Fig. 8.2(b). Under such circumstances,\\nthere are discrepancies between the model and the data which are unlikely to\\nbe explained by random statistical ﬂuctuations in the sample distribution. This\\ncould arise from either (i) an incorrect null hypothesis, or (ii) an incorrect\\nevaluation or assumption about the uncertainties. Conversely, if \\x03the value\\n\\x04\\n2\\n2 ;ν ,\\nis less than ν the cumulative probability fu', 'nction, P χmin\\nof χmin\\nbecomes greater than 0.5 and tends towards unity. This is not an indication\\nof an improved ﬁt, but rather suggests that the standard errors used in the\\ndetermination of the χ 2 statistic have been overestimated, resulting in an\\nunrealistically small value of χ 2 .\\nWe now turn to the question of when to reject the hypothesis on the grounds\\n2 being too large to attribute to statistical ﬂuctuations in\\nof the value of χmin\\n\\nFig. 8.3 The percentage probability of\\n2 + \\x12χ 2\\nobtaining a value of χ 2 of ≤ χmin\\nas a function of \\x12χ 2 for one degree of\\nfreedom. The conﬁdence limits quoted in\\nTable 6.2 are shown as solid points.\\n\\n\\x0c106 Hypothesis testing\\n\\n\\x03 2\\n\\x04\\nthe data set. Obviously, there is not one critical value of P χmin\\n; ν which\\ndetermines whether the hypothesis\\n\\x04 is rejected; in this treatment we will inves\\x03 2\\n; ν as a function of the results being two or\\ntigate the evolution of P χmin\\nthree standard deviations from the mean. In statistics texts (see, e.g. Rees\\n1987)\\x03 the 5%\\n\\x04 level of signiﬁcance is often chosen as the critical value; i.e.\\nif P χ 2 ; ν ≤ 0.05 the hypothesis is said ‘to be rejected at the 5% level’. As\\nwith the sampling of any probability distribution function the most probable\\nvalue returned will be the expectation value or mean. However, from the\\ndiscussion in Chapters 2 and 3 we would not be surprised to ﬁnd results that\\nare within two standard deviations of the mean. For a test of a particular null\\n2 ≈ ν but would\\nhypothesis, we would therefore expect to obtain a value of χmin\\n2 within two standard deviations of the mean, i.e.\\nnot be surprised to ﬁnd χmin\\n√\\n√\\n2 ≤ ν + 2 2ν. The probability of obtaining a\\nin the range ν − 2 2ν ≤ χmin\\n√\\n2 of ν + 2 2ν or higher is approximately 4 × 10−2 . Due to the\\nvalue of χmin\\nasymmetry of the χ 2 distribution this probability has a very weak dependence\\non ν; for ﬁve degrees of freedom, the probability derived from eqn (8.4)\\nis P (11.3; 5) = 0.045; for ν = 20, P (32.6; 20) = 0.037 and for ν = 10', '0,\\n2 greater than\\nP (128; 100) = 0.029. The probability of ﬁnding a value of χmin\\n√\\n2\\nthree standard deviations from the mean, i.e. χmin > ν + 3 2ν, is an order of\\nmagnitude smaller and is approximately 5 × 10−3 .\\nWe illustrate these ideas in Fig. 8.4 where the cumulative probability distribution for χ 2 with ν = 20 is shown. In Fig. 8.4(a) the distribution is shown with\\n2 of 20 or higher\\nthe mean marked. The probability of obtaining a value of χmin\\nwith ν = 20 is P (20; 20) = 0.46 which is slightly less than 1/2. In subsequent\\n2 of ν + σ , ν + 2σ and ν + 3σ\\nplots the probabilities of obtaining a value of χmin\\nor higher are shown. The probabilities for these points are P (26.3; 20) = 0.16,\\nP (32.6; 20) = 0.04 and P (39.0; 20) = 0.007 respectively.\\n2 greater than ν + 3σ is\\nAlthough the probability of ﬁnding a value of χmin\\nrather low, P (ν + 3σ ; ν) ≈ 10−3 ,\\x03genuinely\\n\\x04 incorrect models will give signif2 ; ν ≈ 10−18 . It is for the experimenter\\nicantly lower probabilities, say P χmin\\nto decide at which threshold\\n\\x04 null hypothesis is rejected. Although ﬁts can\\n\\x03 2 the\\n; ν ≈ 10−3 level, it is not advisable to do this\\nbe accepted at the P χmin\\nas a matter of course. It would be a better strategy to ﬁnd the origin of the\\ndiscrepancy between the model and data.\\n\\nFig. 8.4 Cumulative probability distribution\\nfunctions for 20 degrees of freedom. Part (a)\\n2 equal to the expected\\nshows the case of χmin\\nvalue (ν), the shaded area represents the\\nprobability of obtaining a value of χ 2 equal\\nto ν or higher and is 46% of the area under the\\n2 = ν + σ , ν + 2σ\\ncurve. The cases for χmin\\nand ν + 3σ are shown in (b), (c) and (d)\\nrespectively, with corresponding probabilities of 16%, 4% and 0.7%.\\n\\n\\x03 2\\n\\x04\\n• For a reasonable ﬁt, the value of P χmin\\n; ν ≈ 0.5.\\n\\x03 2\\n\\x04\\n• If P χmin\\n; ν → 1 check your calculations for the uncertainties in the\\nmeasurements, αi .\\n• The null hypothesis is generally not rejected if the value\\n2\\nis within ±2σ of the mean, ν, i.e. in the range\\nof χmin\\n√\\n√\\n2 ≤ ν + 2 2ν.', '\\nν − 2 2ν ≤ χmin\\n\\x04\\n\\x03 2\\n; ν ≈ 10−3 or\\n• The null hypothesis is questioned if P χmin\\n\\x03 2\\n\\x04\\nP χmin ; ν > 0.5.\\n\\x03 2\\n\\x04\\n• The null hypothesis is rejected if P χmin\\n; ν < 10−4 .\\n\\n\\x0c8.4 Using χ 2 as a hypothesis test\\n\\n8.4.1\\n\\n107\\n\\nThe reduced χ 2 statistic\\n\\nIn order to ascertain whether a particular null hypothesis should be rejected at\\na particular conﬁdence level, the probabilities of obtaining the observed value\\n2 or higher given the number of degrees of freedom must be calculated\\nof χmin\\nusing eqn (8.4). However, we can obtain a quick indication as to whether the\\nnull hypothesis should be rejected by considering the so-called reduced chi2 divided by the number\\nsquared statistic, χν2 , which is simply the value of χmin\\nof degrees of freedom:\\nχν2 =\\n\\n2\\nχmin\\n.\\nν\\n\\n(8.6)\\n\\nA good match between the sample and parent distribution occurs when χν2 ≈ 1.\\nWe can understand why the null hypothesis is not rejected if χν2 ≈ 1 by considering that for good agreement between the sample and parent distribution\\neach point will differ from its expected value, i.e. the mean, by typically\\nthe standard deviation of the mean (standard error). Thus each term in the\\nsummation of the χ 2 statistic should be of order one, with the result that\\n2\\n≈ N . Typically, as the number of degrees of freedom is similar to the\\nχmin\\nnumber of data points, χν2 is thus expected to be unity. If the value of χν2 is\\nmuch larger than one, it is likely that the null hypothesis should be rejected.\\nA very small value of χν2 is also unlikely—either the error bars have been\\noverestimated, which reduces the value of χ 2 , or the observed and expected\\nvalues are unrealistically close. Again it is for the experimenter to decide at\\nwhat conﬁdence limit the null hypothesis should be rejected in terms of the\\nreduced chi-squared statistic, χν2 . In Section 8.4 we discussed how one would\\n2 was within 2σ of the mean for a\\nnot be surprised if the observed value of χmin\\ngood ﬁt, and that the null hypothesis should only be questioned if th', 'e value of\\n2 was larger than, say, 3σ from the mean. As the standard deviation of the\\nχmin\\nχ 2 distribution depends on ν, the conﬁdence limits for χν2 also depend on ν. In\\nFig. 8.5 the values of χν2 calculated at ν + σ , ν + 2σ , and ν + 3σ are plotted\\nas a function of the number of degrees of freedom. Recall that for a Gaussian\\ndistribution these intervals correspond to the 68%, 95% and 99.7% conﬁdence\\nlimits. The 3σ conﬁdence limit of χν2 is tabulated for several values of ν in\\nTable 8.1.\\n• For a reasonable ﬁt the value of χν2 ≈ 1.\\n• If χν2 \\x12 1 check your calculations for the uncertainties in the measurements, αi .\\n• The null hypothesis is questioned if χν2 > 2 for ν ≈ 10.\\n• The null hypothesis is questioned if χν2 > 1.5 if ν is in the approximate\\nrange 50 ≤ ν ≤ 100.\\nAlthough easier to calculate, \\x03χν2 does\\x04 not contain as much information as\\n2 and ν to calculate P χ 2 ; ν ; see Exercise (8.2).\\nusing χmin\\nmin\\n\\nFig. 8.5 χν2 calculated at ν + σ (dotted),\\nν + 2σ (dashed), and ν + 3σ (solid) and\\nplotted as a function of the number of degrees\\nof freedom. For 100 degrees of freedom the\\nlimit for not rejecting the null hypothesis is\\nfor a value of χν2 of 1.4, whereas it is 2.3 for\\n10 degrees of freedom.\\n\\nTable 8.1 Example values of the\\nlargest acceptable values\\nof χν\\x112\\n\\x10\\nobtained from the χν2 + 3σ\\nconﬁdence level for different\\ndegrees of freedom, ν.\\nν\\n5\\n10\\n20\\n30\\n50\\n100\\n500\\n\\n\\x10\\n\\nχν2 + 3σ\\n2.9\\n2.3\\n1.9\\n1.8\\n1.6\\n1.4\\n1.2\\n\\n\\x11\\n\\n\\x0c108 Hypothesis testing\\n\\n8.4.2\\n\\nTesting the null hypothesis—a summary\\n\\nThe null hypothesis is that the sample distribution is well modelled by a\\nproposed parent distribution and that any scatter between the two distributions\\nis a result of random statistical variations in the sample. A χ 2 test of this\\n2 and then determining\\nhypothesis is performed by ﬁrst ﬁnding the value of χmin\\nthe number of degrees of freedom. We have seen in the previous sections\\nthat there are two numbers which can be used to test the validity of the null\\nhypothesis:\\n(1) the reduced chi', '-squared statistic, χν2 ;\\n2\\nequal to the ﬁt value or\\n(2) the probability of obtaining a value of χmin\\n2\\nhigher, given ν, P(χmin ; ν).\\nThe χν2 statistic is signiﬁcantly easier to calculate and can be used to reject\\nthe null hypothesis if χν2 > 3. Ambiguity arises in using the χν2 statistic to\\nreject the null hypothesis for values in the range 1 ≤ χν2 ≤ 3 due to a strong\\ndependence of the χν2 conﬁdence levels on ν as seen in Table 8.1. This\\nambiguity can be resolved by calculating (using appropriate software or look2 or higher\\nup tables) the probability of obtaining the observed value of χmin\\n2\\nfor the number of degrees of freedom, P(χmin ; ν). This probability has a\\nmuch weaker dependence on ν and the null hypothesis should be rejected if\\n2 ; ν) < 10−4 .\\nP(χmin\\nBy rejecting the null hypothesis we are stating that the discrepancies\\nbetween the data and proposed model are very unlikely to be due to random statistical ﬂuctuations; there must be a genuine systematic reason for\\nthe disagreement. A good experimentalist would then try different models\\nwith insight gained from further analysis of, for example, the normalised\\nresiduals.\\n\\n8.5\\n4 For a straight-line ﬁt the procedure to obtain\\n2 is as follows:\\nχmin\\n\\n• obtain the best-ﬁt parameters and their\\nuncertainties using eqns (6.3)–(6.6);\\n• for each data point, yi , calculate the\\ny −y x\\nnormalised residual, R = i ( i ) ,\\ni\\n\\nαi\\n\\nusing the best-ﬁt function, y(xi );\\n2 by summing the square\\n• calculate χmin\\nof the normalised residuals for the data\\nset.\\n\\nTesting the quality of a ﬁt using χ 2\\n\\nThe χ 2 statistic can be used as a test of the quality of a ﬁt. In this section we\\ndiscuss by example (a) how to answer the question ‘are the data well described\\nby the theoretical model?’, and (b) how to answer the related question ‘which\\nmodel best describes the data?’.\\nThe ﬁrst step in conducting a χ 2 test is to determine the best-ﬁt model\\n2 depends on the functional form of the\\nfunction. The procedure to ﬁnd χmin\\ntheoretical model. We ', 'saw in Chapter 6 that for a simple straight line the\\nbest-ﬁt line is easily determined analytically.4 If the theoretical model is an\\narbitrary function we highlighted in Chapters 6 and 7 the numerical techniques\\nfor minimising χ 2 .\\nThe null hypothesis is that the model is an appropriate description of the\\ndata. If the null hypothesis is not rejected the model is said to be a ‘good ﬁt’\\n2 ; ν) exceed the limits discussed\\nto the data. If the values of either χν2 or P(χmin\\nabove, the null hypothesis is rejected and the model is said to be a ‘poor ﬁt’\\nto the data. While it is clear what the extremes of a good and poor ﬁt are, the\\nboundary between them is much more subjective. Our advice is to quote both\\n\\n\\x0c8.5 Testing the quality of a ﬁt using χ 2\\n\\n109\\n\\n2 , the number of degrees of freedom, ν, and P(χ 2 ; ν) which\\nthe value of χmin\\nmin\\nallows the reader to judge the quality of the ﬁt.\\nWe now show through some worked examples how the χ 2 -test can be\\napplied to testing the quality of a ﬁt and testing different models.\\n\\n8.5.1\\n\\nWorked example 1—testing the quality of a ﬁt\\n\\nIn Fig. 8.6 we show the data obtained by monitoring the radioactive decay\\nfrom an active 137 Ba isotope. The count rate is expected to decay exponentially\\nto a constant background level. A suitable model to ﬁt the data will contain\\nthree parameters; the initial activity, the half-life of the decay and the background level. Using the procedures outlined in Chapter 6, these parameters\\nand their associated errors were obtained by minimising χ 2 to obtain a value\\n2 = 53.5. There are 62 data points and as there are three ﬁt parameters\\nof χmin\\nthe number of degrees of freedom is ν = 59. The reduced χ 2 value is therefore\\nχν2 = 0.9. As this is less than 1.5 (Table 8.1), and not signiﬁcantly less than\\n1, we do not reject the null hypothesis. We can further quantify the quality\\nof ﬁt by using eqn (8.4) to determine the probability of obtaining the value\\n2 = 53.5, or larger, for 59 degrees of freedom. Using suitabl', 'e look-up tables\\nχmin\\nwe ﬁnd P(53.5; 59) = 0.68. As this probability is close to 0.5 there is, again,\\nno reason to reject the null hypothesis and we can accept the ﬁtted parameters\\nof the hypothesised linear function and their uncertainties with a high degree of\\nconﬁdence. In this example we obtain a value for the half-life of the radioactive\\nisotope5 of t1/2 = 153 ± 4 seconds from the best-ﬁt curve.\\n\\n8.5.2\\n\\nWorked example 2—testing different models\\nto a data set\\n\\n2 is a numerical measure of the discrepancy between a proposed model\\nAs χmin\\nand the data, weighted by the uncertainty in the data, a χ 2 test can be used to\\ndistinguish between the validity of different models. Consider the well-known\\ncase for the period of a pendulum. The conventional derivation of the equation\\nof motion for a pendulum assumes that the initial angular displacement is\\nsmall. If the small-angle approximation is no longer valid, then the period,\\nT , of a pendulum depends not only on its length, L, and the acceleration due\\nto gravity, g, but is also a function of the initial angular displacement, θmax .\\nIt can be shown (Kleppner and Kolenkow 1978, p. 276) that including the\\nlowest-order correction yields the result:\\n\\n\\x07\\nT = 2π\\n\\n(\\n)\\nL\\n1\\n1+\\n(θmax )2 .\\ng\\n16\\n\\n(8.7)\\n\\nIn Fig. 8.7 we present experimental data of the period against the initial angular\\ndisplacement and ﬁt different models to the data.\\n\\nFig. 8.6 The count rate (the number of\\ndecays per second) as a function of time for\\nthe decay of a 137 Ba isotope. The weighted\\nbest-ﬁt curve is shown as a solid line.\\n\\n5 The half-life of 137 Ba is 153 s.\\n\\n\\x0c110 Hypothesis testing\\n\\nIn Fig. 8.7(a) we ﬁt the data to two competing models motivated by physical\\ninsights. We compare the simple case where the period is assumed to have\\nno angular dependence—i.e.\\nthe experimental data are ﬁt to a simple con√\\nstant, T0 = 2π L/g, with a more rigorous approach where the data are ﬁt\\nto eqn (8.7) with a coefﬁcient of the quadratic correction, α, a free parameter:\\n2 ].', ' In Fig. 8.7(b) we test an alternative hypothesis that the\\nT = T0 [1 + α θmax\\nangular dependence of the period follows a linear dependence by ﬁtting the\\ndata to T = T0 [1 + β θmax ]. Visually the experimental data clearly show an\\nangular dependence and the hypothesis that the period is independent of angular amplitude should be rejected—the best-ﬁt constant period does not agree\\nwith any of the six data points within their error bars. To quantify why this null\\nhypothesis should be rejected and whether the other models provide a good ﬁt\\nto the data requires a χ 2 test to be undertaken. The results are encapsulated in\\nTable 8.2.\\nTable 8.2 Three different models are used for the dependence of the period of oscillation of a pendulum on the initial angular displacement.\\nModel\\nFig. 8.7 Experimental data (ﬁlled circles) for\\nthe dependence of the period of a pendulum\\non the initial angular displacement. In (a) the\\nbest-ﬁt constant period is shown as a dashed\\nline, and a model comprising a constant with\\na quadratic correction shown as the solid line.\\nIn (b) a straight-line ﬁt is made to the data.\\n\\n6 Further more precise experimental data\\n\\nwould need to be obtained to differentiate\\nbetween the two models. More data would\\nenable a more robust hypothesis test, and the\\nprecision of the experimental data enables\\nthe subtleties in the shape of the two model\\nfunctions to be compared with the data.\\n\\nT = T0\\n2\\nT = T0 1 + α θmax\\n\\nDegrees of freedom\\n\\n!\\n\\nT = T0 [1 + β θmax ]\\n\\n5\\n\\n2\\nχmin\\n\\nχν2\\n\\n2 ; ν)\\nP(χmin\\n\\n107.2\\n\\n21.4\\n\\n1.6 × 10−21\\n\\n4\\n\\n3.39\\n\\n0.9\\n\\n0.49\\n\\n4\\n\\n4.39\\n\\n1.1\\n\\n0.36\\n\\nThe model of a period independent of amplitude can clearly be rejected.\\n2 = 107.2 yields a reduced χ 2 of\\nWith ﬁve degrees of freedom a value of χmin\\nν\\n21.4, and a probability of obtaining a minimum χ 2 of this magnitude or larger\\nof 1 × 10−21 . The model of a quadratic correction to the constant provides a\\n2 ; ν) which are consistent\\ngood ﬁt to the data, with values of χν2 and P(χmin\\nwith the model being a valid descrip', 'tion of the data. A model with a linear\\ncorrection also provides a good ﬁt to the data. Based on a χ 2 test alone we\\ncannot distinguish between the quality of the ﬁt for the linear and quadratic\\nmodels. However, as there is a theoretical model which predicts a quadratic\\ncontribution we prefer to accept this model, but note that for this data set we\\nstill do not reject the model of a linear correction.6\\n\\n8.5.3\\n\\nWhat constitutes a good ﬁt?\\n\\nOver the last four chapters we have discussed many criteria for deciding\\nwhether a theoretical model is an appropriate description of a data set—i.e.\\n‘is the ﬁt good?’. At the start of Chapter 6 we introduced the three questions\\none should ask when ﬁtting experimental data to a theory. The ﬁrst, and most\\nimportant of these, is to question the quality of the ﬁt as this is a prerequisite\\nfor the other two questions to be relevant. Often it is clear from a simple visual\\ninspection whether a ﬁt is good or poor, but where this is not the case a more\\n\\n\\x0c8.6 Testing distributions using χ 2\\n\\nquantitative analysis is required. We provide here a summary of possible strategies to follow in attempting to quantify the ‘quality of the ﬁt’. For a good ﬁt\\n• Two-thirds of the data points should be within one standard error of the\\ntheoretical model.\\n• χν2\\x03is ≈ 1. \\x04\\n2 ; ν ≈ 0.5.\\n• P χmin\\n• A visual inspection of the residuals shows no structure.\\n• A test of the autocorrelation of the normalised residuals yields D ≈ 2.\\n• The histogram of the normalised residuals should be Gaussian, centred\\non zero, with a standard deviation of 1.\\n\\n8.6\\n\\nTesting distributions using χ 2\\n\\nWe have shown how to use the minimisation of the χ 2 statistic to ﬁnd the bestﬁt parameters, and use the probability distribution function of χ 2 to perform\\na hypothesis test. In this section, we shall extend the use of the χ 2 test and\\ndemonstrate how to perform a null hypothesis test of a distribution. As before,\\nthe null hypothesis is that there is no signiﬁcant difference between the ', 'sample\\nand parent populations—any observed difference is only due to statistical\\nﬂuctuations associated with the random sampling of the parent distribution.\\nSuppose that the sample distribution is composed of N measurements of\\na variable xi . The ﬁrst step in testing a sample distribution against a parent\\ndistribution is to create a histogram of the sample data. The occurrence per\\nbin in the histogram, Oi , is a function of (1) the sample size and (2) the binwidth. We would expect that if we were to repeat the experiment many times,\\nthe number of occurrences per bin would ﬂuctuate about a mean value with\\na particular standard deviation. As each of these repeat measurements gives a\\ncount per bin which is a random process we would expect from Section 3.4\\nthat the appropriate probability distribution\\n√ function is a Poisson with a mean\\noccurrence Oi , and standard deviation Oi .\\nThe second step is to create the histogram of the expected results. There are\\ntwo methods for calculating the expected number, E i , depending on whether\\nthe proposed distribution is discrete or continuous. For a discrete distribution\\nE i is generated by summing the expected occurrences for the range of x-values\\nof the i th bin, and multiplying by N , the total number of measurements. For a\\ncontinuous probability distribution function PDF (x), E i is calculated by integrating PDF (x) over the range of x-values of the i th bin, and multiplying by N .\\nIn performing a χ 2 test we compare the observed occurrences, Oi , with\\nthe expected occurrences, E i , generated from the proposed parent distribution.\\nThe appropriate form for calculating χ 2 is given by eqn (6.2). For the null\\nhypothesis not to be√rejected we would expect that Oi − E i would be small\\nand of the order of E i . Sequential bins are combined if E i < 5 to avoid the\\nχ 2 test being skewed by the asymmetry in the Poisson distribution.\\nthe null hypothesis can be tested\\nOnce the value of χ 2 has been \\x03determined\\n\\x04\\nby considering the proba', 'bility P χ 2 ; ν or χν2 .\\n\\n111\\n\\n\\x0c112 Hypothesis testing\\n\\nThe procedure to perform a χ 2 test for a distribution is as follows:\\n• Construct a histogram of the sample distribution, Oi .\\n• For the same intervals construct a histogram of the expected occurrences, E i .\\n• Combine sequential bins until E i > 5 for all bins.\\n\\x06 (Oi − E i )2\\n• Calculate χ 2 using χ 2 =\\n.\\nEi\\ni\\n\\x03\\n\\x04\\n• A good ﬁt will have: χν2 ≈ 1 and P χ 2 ; ν ≈ 0.5.\\n\\x03\\n\\x04\\n• A poor ﬁt will have: χν2 << 1 or χν2 > 3, and P χ 2 ; ν → 1 or\\n\\x03 2 \\x04\\nP χ ; ν < 10−4 .\\n\\nIn the following section, we give examples of how to test a sample distribution against parent distributions which are (a) discrete and (b) continuous.\\n\\n8.6.1\\n\\nFig. 8.8 Comparing experimental radioactive decay events with a Poisson distribution.\\nIn (a) a histogram of the observed occurrence\\nof counts is plotted (bars) and compared with\\na Poisson distribution (points) and expected\\nﬂuctuations. Part (b) shows a re-binned histogram with bin-widths chosen such that the\\nnumber of expected occurrences is always\\ngreater than 5. Note that in the re-binned\\nhistogram six out of eight observed occurrences fall within the expected range taking\\ninto account the Poisson noise.\\n\\nWorked example 3—testing a discrete distribution\\n\\nConsider the data shown in Fig. 8.8 which gives the results of a radioactive\\ndecay experiment. From the discussions in Chapter 3 we expect that this\\nsample distribution is drawn from a Poisson distribution. Figure 8.8(a) shows\\nthe histogram obtained after taking 58 measurements of one second duration.\\nOur best estimate of the mean of the parent distribution is the mean number of\\ncounts determined from the sample distribution—in this case N̄ = 7.55. The\\nexpected values for a Poisson distribution with this mean are superimposed on\\nthe histogram in Fig. 8.8(a). To calculate the expected values, the probabilities\\ndetermined from the Poisson distribution\\nfunction are scaled by the total\\n\\x03\\n\\x04\\nnumber of samples, N ; E i = P Ni , N × N .\\nVisually it appears', ' that the sample distribution is in agreement with a\\nPoisson distribution but for a quantitative analysis we calculate χ 2 ; these\\ncalculations are carried out explicitly in Table 8.3.\\nDue to the low number of expected occurrences in bins 0–4 and 11–17, these\\nhave been combined to form eight super-bins which are plotted in Fig. 8.8 (b).\\nA visual inspection of the re-binned histogram reveals that for six of the eight\\nbins the observed\\n√ and expected occurrences agree within the expected Poisson\\nﬂuctuations, E i . This is consistent with a good ﬁt, but a more quantitative\\nanalysis of the null hypothesis requires χ 2 to be calculated. We have applied\\ntwo constraints when comparing the sample and parent distributions—namely\\nthe means of the two distributions are the same, and the total number of\\nmeasurements is also the same. The number of degrees of freedom in this\\nexample is therefore ν = 8 − 2 = 6. We determine χ 2 = 6.80 in Table 8.3\\nand calculate both the reduced chi-squared, χν2 = 1.13, and the probability\\nP(6.80; 6) = 0.34. As χν2 is close to 1 and the probability is close to 0.5, there\\nis no reason why the null hypothesis should be rejected and we conclude that\\nthe sample distribution was likely to have been drawn from a Poisson parent\\ndistribution.\\n\\n\\x0c8.6 Testing distributions using χ 2\\n\\n113\\n\\nTable 8.3 Comparing experimental radioactive decays with a Poisson model.\\nThe ﬁrst column is the number of counts, the second is the occurrence of each\\ncount. Column three is the Poisson probability for obtaining a given number of\\ncounts using the mean count of the data. The fourth column gives the expected\\nnumber of occurrences, and χ 2 is calculated in the ﬁfth column.\\nNumber of counts\\n\\nOi\\n\\n0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n> 17\\n\\n⎫\\n0⎪\\n⎪\\n0⎪\\n⎬\\n0 7\\n⎪\\n1⎪\\n⎪\\n⎭\\n6\\n5\\n8\\n13\\n10\\n2\\n4\\n⎫\\n4⎪\\n⎪\\n2⎪\\n⎪\\n⎪\\n⎪\\n2⎪\\n⎬\\n0 9\\n⎪\\n1⎪\\n⎪\\n⎪\\n⎪\\n0⎪\\n⎪\\n⎭\\n0\\n\\x06\\n\\n8.6.2\\n\\n58\\n\\nProb. (%)\\n\\nEi\\n\\n0.05\\n0.40\\n1.50\\n3.77\\n7.12\\n10.75\\n13.53\\n14.60\\n13.78\\n11.56\\n8.73\\n5.99\\n3.77\\n2.19\\n1.18\\n0.60\\n0.28\\n0.21\\n\\n⎫\\n0.03⎪\\n⎪\\n0.23⎪\\n⎬\\n0.87 7.44\\n', '⎪\\n2.19⎪\\n⎪\\n⎭\\n4.13\\n6.23\\n7.85\\n8.47\\n7.99\\n6.71\\n5.06\\n⎫\\n3.48⎪\\n⎪\\n2.19⎪\\n⎪\\n⎪\\n⎪\\n1.27⎪\\n⎬\\n0.69 8.25\\n⎪\\n0.35⎪\\n⎪\\n⎪\\n⎪\\n0.16⎪\\n⎪\\n⎭\\n0.12\\n\\n\\x06\\n\\n\\x06\\n\\n100\\n\\n58\\n\\n(Oi − E i )2\\nEi\\n\\n0.026\\n\\n0.24\\n0.003\\n2.43\\n0.51\\n3.30\\n0.22\\n\\n0.07\\n\\nχ2 =\\n\\n\\x06\\n\\n6.80\\n\\nWorked example 4—testing a continuous\\ndistribution\\n\\nIn the discussion of the central limit theorem in Chapter 3 the key idea is that,\\nindependent of the form of the distribution function of individual measurements, the distribution of the means of, say, ﬁve measurements is Gaussian. As\\nan example we showed the distribution of the average of the six balls drawn in\\nthe UK lottery for 106 independent events. A visual inspection of Fig. 3.9(b)\\nindicates that the histogram of the means resembles a Gaussian. Here we provide a qualitative analysis of this agreement through a χ 2 test. The histogram of\\nthe means is reproduced in Fig. 8.9. The proposed continuous Gaussian model\\nwith the same mean (x̄ = 25.4) and standard deviation (σ = 5.8) as the sample\\nand scaled by the total number of sample occurrences, N = 106, is shown by\\nthe solid line in Fig. 8.9. To compare the histogram of the observed means with\\nthe continuous function requires the Gaussian to be discretised to the same binwidth as the histogram of the observed occurrences. The expected counts per\\nbin were calculated using eqn (3.9) to determine the probability and multiplying by N . In Table 8.4 the data have been re-binned to ensure that E i is always\\nlarger than 5 in any bin resulting in a new sample of 16 measurements. As\\nthere are three constraints (the parent and sample distributions have the same\\nnumber of measurements, and share a common mean and standard deviation)\\nthe number of degrees of freedom is therefore ν = 16 − 3 = 13. We determine\\n\\nFig. 8.9 A histogram of the means of 106\\nUK National Lottery draws. In each draw six\\nballs are selected from the integers 1–49 and\\nwe have calculated the average value of the\\nballs drawn per event. The continuous line\\nis a Gaussian constrained to have the same\\nmea', 'n and standard deviation as the sample\\ndata and is scaled by the total number of\\nevents.\\n\\n\\x0c114 Hypothesis testing\\n\\nTable 8.4 Comparing the distribution of the means of the 106\\nUK National Lottery draws with a\\nGaussian distribution. The ﬁrst column is the mean value, the second\\nis the occurrence of each mean. Column three gives the expected number of occurrences using a Gaussian\\nmodel with the same mean and standard deviation as the sample data, and\\nχ 2 is calculated in the ﬁnal column.\\nBin-widths have been chosen such\\nthat E i is greater than 5 in each bin.\\nNote that all the entries in the last\\ncolumn are of order 1.\\nBin\\n\\nOi\\n\\nEi\\n\\n(Oi − E i )2\\nEi\\n\\n<16\\n17–18\\n19–20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31–32\\n33–34\\n>35\\n\\n4\\n7\\n7\\n8\\n8\\n5\\n4\\n5\\n13\\n6\\n2\\n7\\n8\\n11\\n4\\n7\\n\\n6.3\\n5.6\\n8.5\\n5.4\\n6.1\\n6.7\\n7.1\\n7.3\\n7.3\\n7.1\\n6.7\\n6.1\\n5.4\\n8.5\\n5.6\\n6.3\\n\\n0.85\\n0.33\\n0.28\\n1.25\\n0.60\\n0.41\\n1.33\\n0.72\\n4.48\\n0.16\\n3.26\\n0.14\\n1.25\\n0.71\\n0.47\\n0.08\\n\\n106\\n\\n106\\n\\n16.32\\n\\n\\x06\\n\\n7 Named after William of Occam, a four-\\n\\nteenth century Franciscan friar, who postulated that with two competing theories which\\nmake the same prediction, the simpler one is\\nbetter.\\nFig. 8.10 Different polynomial ﬁts to a data\\nset with 41 points. Low-order polynomial ﬁts\\nsuch as the second-order ﬁt shown in (a) systematically fail to account for the trends in\\nthe data set. Higher order polynomials ﬁt the\\ndata set better. The evolution in the quality\\nof ﬁt, χν2 , is shown as a function of polynomial order in (b). Fits with polynomial orders\\ngreater than ﬁve do not signiﬁcantly improve\\nthe quality of the ﬁt.\\n\\nthat χ 2 = 16.32 in Table 8.4 and calculate both the reduced chi-squared,\\nχν2 = 1.26, and the probability P (16.32; 13) = 0.23. As χν2 is close to 1 and\\nthe probability is close to 0.5, there is no reason why the null hypothesis should\\nbe rejected and we conclude that the distribution of means is well modelled by\\na Gaussian distribution in agreement with the central limit theorem.\\nOne can adopt this methodology to provide a quantitative test as to whether\\nthe his', 'togram of the normalised residuals obtained in a ﬁt is Gaussian as\\nexpected.\\n\\n8.7\\n\\nOccam’s razor\\n\\nIt should be obvious that by adding more parameters to our model, we can get a\\nbetter ﬁt to the experimental data points. As mentioned above in the discussion\\nof the number of degrees of freedom, a ﬁt is much more convincing if there are\\nfar fewer constraints than data points. When we have fewer constraints than\\ndata points it is useful to consider whether the model would be better with\\nmore (or fewer) parameters. We will use a line of argument based on a tool\\ndesignated ‘Occam’s razor’ to ascertain whether another parameter is justiﬁed\\nin the theoretical model.7\\nConsider the data shown in Fig. 8.10. In part (a) a polynomial ﬁt is hypoth2 is plotted as a function\\nesised as a theoretical model, and the value of χmin\\nof the number of parameters included in Fig. 8.10(b). We see that the quality\\nof the ﬁt improves drastically up until the ﬁfth-order term is included. For\\nhigher order polynomials there is only a modest improvement in the quality\\n2 . As\\nof the ﬁt as more terms are added, reﬂected in the slight decrease of χmin\\nthe quality of the ﬁt hardly improves after the ﬁfth-order term is included, we\\napply Occam’s razor to discard higher order corrections, and prefer to accept\\nthe simplest model which accounts quantitatively for the trends in the data.\\nIt is also possible to apply a more quantitative test of whether an additional\\nterm should be kept, in terms of an F-test; see Bevington and Robinson (2003,\\nSection 11.4) for further details.\\n\\n\\x0c8.9 Scaling uncertainties 115\\n\\n8.8\\n\\nStudent’s t-distribution\\n\\nIn Chapter 3 we discussed how to compare experimental results with an\\naccepted value. The analysis centred on the dimensionless quantity\\n√\\nN (x̄ − μ)\\n(x̄ − μ)\\n,\\n(8.8)\\n=\\nt=\\nα\\nσ N −1\\nwhere x̄ is the best estimate based on N measurements with sample standard\\ndeviation of σ N −1 , standard error α, and accepted value μ. Calculations of the\\nconﬁdence limits were conducted with', ' this parameter; for example we showed\\nthat 99% of data points for a Gaussian distribution should have |t| < 2.58, 95%\\nhave |t| < 1.96 and 68% have |t| < 1. However, in practice we do not know the\\nstandard deviation of the parent distribution and we can only estimate it from\\nthe sample distribution. For samples of ﬁnite size the conﬁdence limit becomes\\na function both of the tolerance level chosen and the number of degrees of\\nfreedom, ν. The factors which replace the entries in Table 3.1 are known as the\\nStudent t values, and are derived from a well-known distribution.8 When the\\nnumber of degrees of freedom is large, the distribution approximates well to a\\nGaussian; but for fewer degrees of freedom the Student t distribution is wider\\nthan a Gaussian. Most spreadsheets and analysis packages can calculate the\\nrelevant factor from the desired conﬁdence limit and the number of degrees of\\nfreedom. The evolution of the factor for the 68%, 95% and 99% conﬁdence\\nlimits is shown in Fig. 8.11. The difference between the conﬁdence limits\\nderived from the Student and Gaussian distributions depends on both the\\nconﬁdence limit of interest and the number of degrees of freedom. For the\\n68% conﬁdence limit the difference is only 5% for 10 degrees of freedom and\\n10% for ﬁve degrees of freedom. As we seldom quote the uncertainties to more\\nthan one signiﬁcant ﬁgure we do not have to worry about this effect unless the\\nnumber of degrees of freedom is very small. The Student probability distribution function has higher cummulative probabilities for large deviations than\\na Gaussian. Thus, the importance of the t values increases as the conﬁdence\\nlevel tends to 100%.\\n\\n8.9\\n\\nScaling uncertainties\\n\\nWe have emphasised throughout this book that it is vital to ascertain the\\nmagnitude of the uncertainty in the measurements, αi , and have shown how it is\\npossible to extract uncertainties in parameters from an analysis of the goodness\\nof ﬁt. It is also possible to turn this process on its head, and ', 'learn something\\nabout the uncertainties from the ﬁt. There are two separate procedures which\\nwe discuss here: (i) estimating the common uncertainty on the data points,\\nand (ii) scaling the magnitude of the uncertainties in ﬁt parameters.\\n2 ≈ ν.\\nBoth processes hinge on the concept that a ‘good ﬁt’ will have a χmin\\nRecalling the deﬁnition of the standard error, αi , as the standard deviation of\\n\\n8 W. S. Gosset published the distribution\\n\\nusing the pseudonym ‘Student’ in 1906 while\\nan employee of the Guinness brewery.\\n\\nFig. 8.11 The variation of the t statistic as\\nfunction of the number of degrees of freedom\\nfor the 68%, 95% and 99% conﬁdence limits.\\nAs ν → ∞, the values tend to those obtained\\nusing a Gaussian distribution (1, 1.96 and\\n2.58 respectively). For very few degrees of\\nfreedom the conﬁdence limits have to be\\nbroadened signiﬁcantly.\\n\\n\\x0c116 Hypothesis testing\\n\\n9 Health warning Do not use the data and\\n\\nﬁt parameters to estimate the uncertainty, and\\nthen use the common uncertainty to calculate\\nχ 2 and hence test the quality of ﬁt—this is a\\ncircular argument.\\n\\n10 Health warning Note that many ﬁtting\\n\\npackages automatically scale the ﬁt parameters, often without making it clear how the\\ndata have been manipulated. Many packages\\nwill blindly apply the scaling even if χν2 \\x12 1\\ndue to incorrect error analysis, leading to\\ncompletely unrealistic estimates of the uncertainties.\\n\\nthe mean, one would expect the statistical variation between the theory and the\\ndata, yi − y(xi ), to be of the order of the standard error. One can estimate the\\ncommon uncertainty, αCU , in the measurements by setting χν2 = 1. If the data\\nset is homoscedastic one can use eqn (6.1), to give\\n1\\x05\\n2\\n=\\n(8.9)\\nαCU\\n(yi − y(xi ))2 .\\nν\\nIn most statistical regression packages the common error is returned. Note that\\none cannot use αCU to give any insight into the quality of the ﬁt.9\\n2\\nIt is also possible to use the value of χmin\\nto scale the errors in the\\nﬁt parameters when one has complete conﬁdence in the the', 'oretical model\\nbeing used to describe the experimental data. Let S be the scale factor\\ndeﬁned as\\n\\x07\\n\\x17\\n2\\nχmin\\n(8.10)\\n= χν2 .\\nS=\\nν\\nOne can rewrite the discussion from Section 8.4.1 in terms of S. Thus, if the\\nresults of a χ 2 minimisation yield a value of S that is very large, the model\\nshould be rejected and the experimenter should try and ascertain the reason\\nbehind the large discrepancy between theory and experiment. Similarly the\\nparameters should be rejected if S is very small as it is likely that the error\\nbars have been overestimated. If S is similar to 1 the uncertainties in the ﬁtted\\nparameters can be scaled by S. The reasoning is (see page 16 of the article by\\nthe Particle Data Group, Amsler et al. 2008) that the deviation of S from 1\\nis a consequence of the uncertainties in the experimental data being estimated\\nincorrectly. Not knowing which particular points give rise to the unexpected\\nvalue of S, it is assumed that all the uncertainties are incorrectly scaled by a\\ncommon factor of S. By scaling the uncertainties in the input data by S, the\\nuncertainties in the ﬁt parameters also change by S giving a modiﬁed value\\nof χν2 = 1 (this is equivalent to scaling every element of the error matrix by\\nS). Obviously there are many assumptions inherent in this scaling procedure,\\nand the experimenter has to ask whether they are reasonable and justiﬁed. If\\na scaling factor is applied to the uncertainties, this should be clearly stated in\\nany publication based on these results.10\\n\\n8.10\\n\\nSummary of ﬁtting experimental data\\nto a theoretical model\\n\\nIn the last four chapters we have discussed extensively various issues\\nwhich arise when ﬁtting experimental data to a theoretical model. Here we\\nsummarise the procedure and highlight the questions one should ask after\\nperforming such a ﬁt.\\n\\n\\x0c8.10 Summary of ﬁtting experimental data to a theoretical model 117\\n\\n• Perform the ﬁt and ﬁnd optimal values of the parameters by minimising\\nχ 2.\\n2 and ν decide whether the ﬁt is reasonable—\\n•', ' Based on the value of χmin\\ni.e. questions such as ‘are my data consistent with a Gaussian distribution?’ should be answered at this stage.\\n2\\nand ν to decide\\n• If there are competing theoretical models use χmin\\nwhich model is most appropriate.\\n• If the quality of the ﬁt is poor either (a) consider a different theoretical\\nmodel, or if the theoretical model is known to be valid for the conditions\\nof the experiment, (b) try to identify defects in the experiment or\\nanalysis.\\n• For a good ﬁt the values of the parameters which minimised χ 2 are used\\nto answer the question ‘what are the best-ﬁt parameters?’.\\n• Calculate the error matrix and use the square root of the diagonal\\nelements to answer the question ‘what are the uncertainties in the bestﬁt parameters?’.\\n\\nChapter summary\\n• The χ 2 statistic can be used for hypothesis testing.\\n• The question ‘are my data consistent with the proposed model?’ can be\\n2 .\\nanswered by analysing the value of χmin\\n• The number of degrees of freedom, ν, is equal to the number of data\\npoints, N , less the number of constraints, N .\\n• For√a good ﬁt, the expectation value of χ 2 is ν, with a standard deviation\\nof 2ν.\\n√\\n2 > ν + 3 2ν the null hypothesis is rejected.\\n• If χmin\\nχ2\\n• Reduced chi-squared, χν2 , is deﬁned as χν2 = min .\\nν\\n• Occam’s razor can be used to eliminate unwarranted extra parameters\\nin a theoretical model.\\n• Student’s t distribution should be used when comparing experimental\\nresults with an accepted value with a small number of degrees of\\nfreedom.\\n• It is possible to scale error bars and estimate the statistical ﬂuctuations\\nin a data set if one is conﬁdent that the appropriate theoretical model\\nhas been used to describe the data (at the expense of foregoing any\\ndiscussion about the quality of the ﬁt).\\n\\n\\x0c118 Hypothesis testing\\n\\nExercises\\n(8.1) Conﬁdence limits for χν2\\nMake a table similar to Table 8.1 and calculate the 68%\\nand 90% conﬁdence limits as a function of the degrees\\nof freedom for the χν2 statistic.\\n\\nsequential\\nχ 2 f', 'rom the formula\\n\\x0612 bins. (iii) Calculate\\nχ 2 = i=1\\n(Oi − E i )2 /E i . (iv) Calculate the number\\nof degrees of freedom. (v) Are the data consistent with\\nthe hypothesis of a Gaussian distribution?\\n\\n(8.2) Conﬁdence limits and χν2\\nAfter performing a ﬁt with 10 degrees of freedom the\\n2 is found to be 15.9. Calculate (a) the value\\nvalue of χmin\\n2\\nof χν , and (b) the probability of obtaining a value of\\n2 equal to this value or larger given the degrees of\\nχmin\\nfreedom. In another ﬁt with 100 degrees of freedom,\\n2 is 159. Calculate (c) the value of χ 2 ,\\nthe value of χmin\\nν\\n2 equal\\nand (d) the probability of obtaining a value of χmin\\nto this value or larger given the degrees of freedom.\\nComment on the differences between the values obtained\\nin part (b) and (d).\\n\\n(8.4) Is the distribution of occurrences of balls in the National\\nLottery uniform?\\nIn Fig. 3.9 we showed the histogram of the occurrences\\nof the 49 balls in all 106 National Lottery draws for\\nthe year 2000. The data are reproduced below. Test the\\nhypothesis that the balls are chosen at random, i.e. that\\nthe distribution of occurrences is uniform.\\n\\n(8.3) Does the noise on a photodiode signal follow a Gaussian\\ndistribution?\\nAs we discussed in Chapter 1, for very low intensities the\\ndistribution of counts from a photodetector is expected\\nto follow the Poisson shot-noise distribution. However,\\nfor larger photon ﬂuxes the noise on the voltage generated in a photodiode circuit is expected to follow a\\nGaussian distribution. Figure 3.4 shows the signal output\\nfrom a photodiode as a function of time, and in part (b)\\na histogram of the distribution of data. The number of\\nobserved data points lying within speciﬁed bands, Oi , is\\ngiven below.\\nInterval/σ\\nO\\n\\n(−∞, −2.5)\\n9\\n\\n(−2.5, −2)\\n48\\n\\n(−2, −1.5)\\n142\\n\\nInterval/σ\\nO\\n\\n(−1.5, −1)\\n154\\n\\n(−1, −0.5)\\n438\\n\\n(−0.5, 0)\\n521\\n\\nInterval/σ\\nO\\n\\n(0, 0.5)\\n405\\n\\n(0.5, 1)\\n318\\n\\n(1, 1.5)\\n299\\n\\nInterval/σ\\nO\\n\\n(1.5, 2)\\n100\\n\\n(2, 2.5)\\n57\\n\\n(2.5, ∞)\\n9\\n\\n(i) Use eqn (3.9) to determine the number of data points\\nexp', 'ected in each interval, E i . (ii) Show that E i > 5\\nfor all bins, and hence there is no need to combine\\n\\nN\\nO\\n\\n1\\n11\\n\\n2\\n11\\n\\n3\\n13\\n\\n4\\n14\\n\\n5\\n11\\n\\n6\\n22\\n\\n7\\n15\\n\\n8\\n9\\n\\n9\\n9\\n\\n10\\n16\\n\\nN\\nO\\n\\n11\\n17\\n\\n12\\n12\\n\\n13\\n8\\n\\n14\\n13\\n\\n15\\n8\\n\\n16\\n15\\n\\n17\\n9\\n\\n18\\n13\\n\\n19\\n19\\n\\n20\\n9\\n\\nN\\nO\\n\\n21\\n12\\n\\n22\\n10\\n\\n23\\n17\\n\\n24\\n13\\n\\n25\\n10\\n\\n26\\n9\\n\\n27\\n10\\n\\n28\\n15\\n\\n29\\n9\\n\\n30\\n14\\n\\nN\\nO\\n\\n31\\n16\\n\\n32\\n17\\n\\n33\\n11\\n\\n34\\n13\\n\\n35\\n14\\n\\n36\\n11\\n\\n37\\n13\\n\\n38\\n21\\n\\n39\\n14\\n\\n40\\n13\\n\\nN\\nO\\n\\n41\\n12\\n\\n42\\n11\\n\\n43\\n16\\n\\n44\\n13\\n\\n45\\n10\\n\\n46\\n18\\n\\n47\\n16\\n\\n48\\n16\\n\\n49\\n8\\n\\n(i) Recalling that six balls are selected per draw, and\\nassuming a uniform distribution, calculate the expected\\nnumber of occurrences of each ball, E i . (ii) Show that\\nE i > 5 for all bins, and hence that there is no need\\n2\\nto combine sequential\\n\\x0649 bins. (iii)2 Calculate χ from the\\n2\\nformula χ = i=1 (Oi − E i ) /E i . (iv) Calculate the\\nnumber of degrees of freedom. (v) Are the data consistent with the hypothesis of a uniform distribution of\\noccurrences?\\n(8.5) Is the temporal distribution of goals in a football game\\nuniform?\\nIn September 2009, 101 goals were scored in the English\\nPremier League. A breakdown of the observed number\\nof goals, Oi , during nine equal-duration time intervals is\\ngiven below. Test the hypothesis that there is no preferential time during the game at which goals are scored,\\ni.e. that the time distribution of goals is uniform.\\n\\n\\x0cExercises\\n\\nInterval/minutes\\nGoals scored\\n\\n(1,10)\\n6\\n\\n(11, 20)\\n11\\n\\n(21, 30)\\n8\\n\\nInterval/minutes\\nGoals scored\\n\\n(31, 40)\\n8\\n\\n(41, 50)\\n14\\n\\n(51, 60)\\n12\\n\\nInterval/minutes\\nGoals scored\\n\\n(61, 70)\\n11\\n\\n(71, 80)\\n12\\n\\n(81, 90)\\n19\\n\\n(i) Calculate the mean number of goals per side per\\ngame, N . (ii) Assuming a Poisson distribution, calculate\\nthe expected number of goals per side per game, E i . (iii)\\nAscertain whether some of the bins should be combined.\\n(iv) Calculate χ 2 and the number of degrees of freedom.\\n(v) Test the hypothesis that the number of goals per side\\nper game follows a Poisson distribution.\\n\\n(i) Assuming a uniform distribution, calculate the\\nexpected number of goals per ', 'interval, E i . (ii) Show that\\nE i > 5 for all bins, and hence there is no need to combine sequential bins. (iii) Calculate χ 2 from the formula\\n\\x059\\nχ2 =\\n(Oi − E i )2 /E i . (iv) Calculate the number\\ni=1\\nof degrees of freedom. (v) Are the data consistent with\\nthe hypothesis of a uniform distribution?\\n(8.6) Does the distribution of goals per side per game follow\\na Poisson distribution?\\nIn the ﬁrst six weeks of the 2009 English Premier League\\nseason, 229 goals were scored in the 76 games. Does the\\nnumber of goals per game per side follow a Poisson distribution? A breakdown of the occurrence, Oi , of games\\nin which N goals were scored by a side is given below.\\nGoals/side/game\\nNumber of games\\n\\n0\\n38\\n\\n1\\n51\\n\\n2\\n35\\n\\n3\\n14\\n\\n4\\n7\\n\\n5\\n4\\n\\n119\\n\\n6\\n3\\n\\n(8.7) Is a die fair?\\nA die was thrown 100 times, and the number of times\\neach face landed up is given below.\\nFace value\\nO\\n\\n1\\n17\\n\\n2\\n21\\n\\n3\\n14\\n\\n4\\n13\\n\\n5\\n16\\n\\n6\\n19\\n\\nIf the die is fair the expected number of occurrences\\nwould be the same for each number. Test the hypothesis\\nthat the die is fair.\\n(8.8) Is a straight line a good ﬁt to the data?\\nUse the data tabulated in Exercises (6.5) and (7.8) and the\\nbest-ﬁt straight line intercepts and gradients to calculate\\nχ 2 for the ﬁts. How many degrees of freedom are there\\nfor these ﬁts? Is it fair to conclude that the data are well\\nﬁt by a straight line for these cases?\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cTopics for further study\\n\\nIn his chapter we brieﬂy discuss some topics which had to be omitted from\\nthis book for the sake of brevity, and give an indication of where further details\\nmight be obtained. A recurring theme in this chapter will be that owing to the\\ncomputational power afforded by modern computers it is often far easier to\\ngenerate and analyse synthetic data than it is to look for analytic solutions to\\ndifﬁcult problems.\\n\\n9.1\\n\\nLeast-squares ﬁtting with uncertainties\\nin both variables\\n\\n9\\n9.1 Least-squares ﬁtting with\\nuncertainties in both variables\\n\\n121\\n\\n9.2 More complex error surfaces\\n\\n1', '23\\n\\n9.3 Monte Carlo methods\\n\\n125\\n\\n9.4 Bootstrap methods\\n\\n126\\n\\n9.5 Bayesian inference\\n\\n127\\n\\n9.6 GUM—Guide to the\\nExpression of Uncertainty in\\nMeasurement\\n\\n129\\n\\nWe have used the method of least squares extensively throughout this book to\\nobtain best ﬁts of a model to a data set, subject to the assumption that only\\nthe uncertainty in the dependent variable, y, was signiﬁcant. There are many\\ninstances when the uncertainty in the independent variable, x, is also signiﬁcant, and should be included in the calculations. Here we brieﬂy discuss some\\nof the issues which arise and possible strategies for including the uncertainties\\nin both variables into the analysis.\\n\\n9.1.1\\n\\nFitting to a straight line\\n\\nFor the straight line y = mx + c, we previously included the y-uncertainty,\\nα y i , in our analysis. If there is also an x-uncertainty, αx i , this can be viewed\\nas generating an equivalent y-uncertainty of m αx i , as is evident from Fig. 9.1.\\nTherefore we can modify the deﬁnition of χ 2 to be:\\nχ 2 (m, c) =\\n\\nN\\n\\x05\\n(yi − mxi − c)2\\n.\\n2 + m 2α2\\nα\\ny\\ni\\nx\\ni\\ni=1\\n\\n(9.1)\\n\\nThe weight, wi , is deﬁned as\\n1\\n= α 2y i + m 2 αx2 i ,\\nwi\\n\\n(9.2)\\n\\nand can be interpreted as the inverse of the variance of the linear combination\\nyi − mxi − c. Equation (9.1) is of the appropriate form, i.e. a sum of N random\\nvariables normalised by their variance, for the applicable distribution to be\\n\\nFig. 9.1 In linear regression, an xuncertainty, αx i , in the independent variable\\nbrings about an equivalent y-uncertainty of\\nm αx i .\\n\\n\\x0c122 Topics for further study\\n\\nthat of χ 2 . The difﬁculty in using eqn (9.1) is the nonlinear dependence of\\nχ 2 on m. Possible strategies to be pursued with this approach are outlined\\nin Press et al. (1992, Section 15.3). Finding the uncertainties in m and c is\\nsigniﬁcantly less straightforward than the cases considered in Chapter 7 owing\\nto this nonlinear dependence of χ 2 on m. If the errors follow a Gaussian\\ndistribution then numerical techniques are used to locate the \\x12χ 2 = 1 conto', 'ur\\n(Press et al. 1992, Section 15.3); if the errors are not normally distributed a\\nMonte Carlo technique is usually adopted to quantify the uncertainties (see\\nSection 9.3).\\n\\n9.1.2\\n\\nFitting to a more general function\\n\\nFor the general case we can deﬁne a sum of the weighted squared residuals, S,\\ndeﬁned as:\\nS=\\n\\nN\\n\\x05\\n\\n!\\nwx i (xi − X i )2 + w y i (yi − Yi )2 .\\n\\n(9.3)\\n\\ni=1\\n\\nHere xi and yi are the experimental measurements of the two variables, and X i\\nand Yi are predicted, or calculated, values subject to some model. Typically,\\nthe weightings are chosen to be the inverse of the variances, wx i = 1/αx2 i , and\\nw y i = 1/α 2y i , but other models are also used. Therefore the sum does not, in\\ngeneral, have the χ 2 distribution of Chapter 8, which is why we use another\\nsymbol. The papers by Reed (1989, 1992) and Macdonald and Thompson\\n(1992) discuss this methodology both in the context of ﬁtting a straight line,\\nand more general functions. Macdonald and Thompson’s work is an excellent\\nreview of previous presentations, and provides a survey of the algorithms\\nadopted to tackle the problem of how to minimise S.\\n\\n9.1.3\\n\\nFig. 9.2 The orthogonal distance, \\x18, of a\\npoint from the best-ﬁt straight line is shown.\\nIn orthogonal distance regression the sum of\\nthe squares of the orthogonal distances for\\nall data points is minimised in order to ﬁnd\\nthe best-ﬁt straight line. The concept can be\\nextended to more general functions.\\n\\nOrthogonal distance regression\\n\\nAnother generalised least-squares method is that of orthogonal distance\\nregression. The modus operandi of conventional linear regression is to minimise the sum of the squared vertical distances (see Fig. 5.7) between the data\\nand the y-coordinates of the ﬁt line for the same x-coordinate. In contrast,\\nin orthogonal distance regression it is the orthogonal distances between the\\ndata and the ﬁt line which are minimised, as depicted in Fig. 9.2. Consider\\nonce more the straight line y = mx + c. An orthogonal line will have a\\ngradient of ', '−1/m, and be described by the equation y \\x0e = −x/m + c\\x0e . If\\nthis second line passes through the data point (x1 , y1 ) its equation becomes\\ny \\x0e = (x1 − x) /m + y1 . These two lines will intersect at the point (xInt , yInt ),\\nwhere the coordinates are given by:\\nx1 + my1 − mc\\n,\\n1 + m2\\n= mxInt + c.\\n\\nxInt =\\n\\n(9.4)\\n\\nyInt\\n\\n(9.5)\\n\\n\\x0c9.2 More complex error surfaces 123\\n\\nThe orthogonal distance, \\x18, between the data point (x1 , y1 ) and the ﬁt line is\\nobtained from the equation:\\n\\x182 = (x1 − xInt )2 + (y1 − yInt )2 .\\n\\n(9.6)\\n\\nIn the method of orthogonal distance regression, the sum of the orthogonal\\ndistances is minimised by varying the ﬁt parameters (in this case, m and c).\\nWe recognise the sum of the squares of the orthogonal distances as a special\\ncase of eqn (9.3). The concept can be extended to more general functions,\\nand is clearly described in the paper by Boggs et al. (1987). A range of\\ncommercial software packages exist for implementing different orthogonal\\ndistance regression algorithms.\\n\\n9.2\\n\\nMore complex error surfaces\\n\\nIn Chapters 6–8 we saw numerous examples of error surfaces. All of these had\\nthe feature that there was a single well-deﬁned minimum, and we discussed\\nvarious strategies of how to locate the best parameters. Error surfaces can be\\nmore complicated, as shown schematically in Fig. 9.3. We must distinguish\\nbetween local minima and global minima. The bane of all of the efﬁcient\\nmethods for ﬁnding minima we have discussed previously is that they can get\\n‘trapped’ at local minima. To overcome this issue there exist different search\\nalgorithms which incorporate random changes to the search parameters. Often\\nthis leads to an increase in the value of χ 2 (or whichever quantity is being\\noptimised), which is to the detriment of the minimisation procedure. However,\\nallowing the option of ‘uphill’ trajectories across the error surface allows the\\npossibility of escape from local minima. We discuss in slightly more detail two\\nmethods which are implemented extensively.\\n', '\\n9.2.1\\n\\nSimulated annealing\\n\\nThis method is based on an insight from statistical mechanics, and is outlined\\nin the article by Kirkpatrick et al. (1983). Consider the process by which a\\nmetal cools and anneals. At a high temperature the atoms in the metal are free\\nto move, and as the metal is cooled the mobility decreases. The high initial heat\\nallows the atoms to depart from their initial positions, such that, on cooling,\\nthey can arrange themselves into a pure crystal with long-range order. The\\ncrystalline state represents a lower energy conﬁguration for the system. The\\nprocess of cooling the metal slowly gives the atoms a higher probability of\\nﬁnding conﬁgurations with an internal energy lower than the starting condition.\\nThe method hinges on the cooling being sufﬁciently slow, allowing the atoms\\nto redistribute themselves into a lower-energy conﬁguration as their mobility\\ndecreases.\\nThe analogy with ﬁnding the global minimum of an error surface is the\\nfollowing. The trajectory across the error surface is driven by updating the\\nvalues of the ﬁt parameters with a random increment. This corresponds to\\nthe role heat plays in the thermodynamic system. The role of ‘temperature’\\nis played by a parameter that dictates the probability of the increment being a\\n\\nFig. 9.3 An error surface with more that one\\nminimum. The strategies discussed in earlier\\nchapters are prone to become trapped in the\\nlocal minimum. Algorithms which incorporate random changes to the search parameters\\nare better at ﬁnding the global minimum.\\n\\n\\x0c124 Topics for further study\\n\\ncertain size. The ‘temperature’ is then slowly reduced to zero when the ﬁnal\\nvalues of the parameters chosen are ‘frozen in’. For the initial high ‘temperature’ the parameters essentially change randomly, in analogy with atoms in\\nthe metal being very mobile. As the ‘temperature’ is reduced the trajectory\\ntends to be downhill on the error surface, in analogy with the thermodynamic\\nsystem ﬁnding a lower energy conﬁguration. Cruciall', 'y the opportunity for\\nuphill motion at ﬁnite ‘temperature’ offers a route out of local minima.\\n\\n9.2.2\\n\\n1 10010010 is an example of an 8-bit binary\\n\\nstring.\\n\\nGenetic algorithms\\n\\nGenetic algorithm techniques, like simulated annealing, can also ﬁnd the\\nglobal minimum on the error surface. The ﬁrst step is to encode potential\\nsolutions to the problem (for us, the set of parameters which minimise χ 2 ).\\nThis can be done as a bit string1 in an object known as a chromosome, to\\nemphasise the link with evolutionary biology. The algorithm produces generations thus:\\n(1) A large population of random chromosomes is generated. Each of these\\nchromosomes encodes the information from different solutions (for our\\ncase, these are different values of the parameters).\\n(2) Each chromosome is assigned a ﬁtness score, which is a number to\\nrepresent how well that particular trial solution solves the problem (the\\nﬁtness score needs to increase as χ 2 decreases).\\n(3) Two members of the present population are selected such that a new\\ngeneration can be bred. The selection procedure is such that chromosomes with a higher ﬁtness score are more likely to be selected.\\n(4) A ‘child’ (or new trial solution) is generated by the two ‘parents’ reproducing. Two genetic operations, crossover and mutation, are used to\\nproduce the next generation. The analogy with biological evolution is\\nthat the child shares many of the attributes of its parents. Dependent on\\nthe crossover rate (which is set in the algorithm), a bit is randomly chosen in one chromosome, and all subsequent bits in the ﬁrst chromosome\\nare replaced by the bits from the second chromosome.\\n(5) Each bit in the selected chromosomes has a random (very small) probability of being ﬂipped (i.e. 0 becomes 1, and vice versa)—this is\\nmutation.\\n(6) Steps 2–5 are repeated until a new population has been generated.\\nA consequence of the process utilising selection based on ﬁtness, and reproduction with crossover and mutation, is that the next generation of ', 'chromosomes is (i) different from the previous generation, and (ii) typically\\nﬁtter. New generations are generated until the best solution is obtained,\\nwithin some tolerance. Like simulated annealing, the stochastic nature of\\nthe algorithm enables trial solutions to avoid becoming ‘stagnated’ in\\nlocal minima, and the global minimum to be found. Many of the ideas\\nimplemented in contemporary genetic algorithms were introduced by Holland (1975); the book contains further details of how to implement the\\nprocedure.\\n\\n\\x0c9.3 Monte Carlo methods 125\\n\\n9.3\\n9.3.1\\n\\nMonte Carlo methods\\nIntroduction to Monte Carlo methods\\n\\nMonte Carlo2 methods are numerical techniques for calculating quantities such\\nas integrals, probabilities, and conﬁdence limits, by the use of a sequence of\\nrandom numbers.3 At one level the ethos of Monte Carlo methods can be\\nviewed as being experimental statistics, i.e. the analytic approach adopted\\npreviously is replaced with a numerical methodology. The computational\\npower of modern computers enables a large number of calculations to be performed, thus circumventing in some circumstances a lack of deep theoretical\\nunderstanding.\\nWe illustrate the methodology by showing the Monte Carlo calculation of\\nπ. Consider Fig. 9.4, which shows a circle of diameter 1, circumscribed by a\\nsquare with sides of length 1. Elementary geometry reveals that the ratio of\\nthe area of the circle to the area of the square is π/4. Now imagine we can\\ngenerate a random number, r , constrained to the interval 0 < r < 1. The ﬁrst\\ntwo numbers chosen are used as the (x, y) coordinates of a point within the\\nperimeter of the square of Fig. 9.4. Many such pairs are generated, and some\\nof the points generated are depicted in the ﬁgure. For each point the following\\nquestion has to be answered: does the point lie within the circle? After NTOT\\ntrials let NIN denote the number of points inside the circle. Our estimate of\\n4 × NIN\\nπ is then π =\\n. Table 9.1 shows the results obtained as a function of', '\\nNTOT\\nthe total number of trials. How does one estimate the uncertainty in the value\\ndeduced from a Monte Carlo simulation? Using the relevant distribution for the\\nnumber of points inside√the circle it is expected that the fractional uncertainty\\nin the mean scales as 1/ NTOT . There are signiﬁcantly more efﬁcient methods\\nfor calculating π ; the purpose of this example was to highlight the Monte Carlo\\nmethodology.\\n\\n9.3.2\\n\\n2 The methods are named after the area of\\n\\nMonaco where a famous casino is located.\\nRandom numbers are a deﬁning feature of\\nMonte Carlo calculations, much as the laws\\nof chance govern gambling games.\\n3 Technically, computers generate pseudo-\\n\\nrandom numbers, but the difference will not\\nbe of concern for us.\\n\\nx\\n\\nx\\n\\nx\\n\\nx\\n\\nxx\\n\\nx\\nx\\nx\\nx\\nx\\n\\nx\\n\\nx\\n\\nx\\n\\nx\\nx\\n\\nx x\\n\\nx\\n\\nx\\nx\\nx\\n\\nx\\n\\nx\\n\\nx\\n\\nx\\n\\nx\\nx\\n\\nx\\n\\nx\\n\\nFig. 9.4 A Monte Carlo method for evaluating π . The coordinates of the points are\\nselected at random. With NIN points inside\\nthe circle after NTOT trials, we get the estimate π = 4 × NIN /NTOT .\\n\\nTesting distributions with Monte Carlo methods\\n\\nThe example of estimating π was a special case where the random numbers generated in the interval 0 < r < 1 could be used without having to\\nbe processed further. Typically, this is not the case. The more general case\\nis where we are interested in the properties of some probability distribution\\nfunction, PDF (x). The transformational method is used such that the numbers chosen at random are distributed according to our desired distribution,\\nPDF (x) (see Cowan 1988 and Bevington and Robinson 2003 for details).\\nHaving obtained the appropriate distribution we can proceed to collect synthetic data sets (much as we would collect genuine experimental data from\\na real experiment). Having obtained a sequence of Monte Carlo generated\\nvalues we can apply the statistical techniques discussed in earlier chapters to\\nestimate parameters of interest, such as the mean, variance, etc. In common\\nwith the speciﬁc case of estimating π\\x12demonstrated ', 'in the previous section,\\nthe accuracy of the results scale as 1/ NTOT , with NTOT being limited only\\nby the computational power and the complexity of the problem.\\n\\nTable 9.1 The evolution of the\\nMonte Carlo estimate of π with\\nsample size NTOT . Five different simulations were run for each\\nvalue of NTOT , from which the\\nmean and uncertainty were calculated.\\nNTOT\\n\\nπ\\n\\nUncertainty\\n\\n100\\n500\\n1000\\n5000\\n10000\\n\\n3.18\\n3.15\\n3.14\\n3.124\\n3.145\\n\\n0.05\\n0.03\\n0.03\\n0.009\\n0.003\\n\\n\\x0c126 Topics for further study\\n\\nOne of the most powerful applications of Monte Carlo techniques is to\\ngenerate conﬁdence limits and distribution functions of random variables. The\\ndiscussion of the conﬁdence limits obtained from ﬁt parameters in Chapter 7\\nassumed that the appropriate distribution function was a Gaussian, largely\\nmotivated by the central limit theorem. However, there are many examples,\\nespecially with nonlinear least-squares ﬁtting, which yield non-normal error\\ndistributions. Monte Carlo simulations offer a simple and fast way to map out\\nthe distribution function and to ascertain, say, the relevant \\x12χ 2 contour for the\\nconﬁdence limit of interest. The article by Silverman et al. (2004) has examples\\nof computer simulated histograms for probability distribution functions of\\nproducts and quotients of independent random variables. Further details about\\nMonte Carlo simulations can be found in the books by Bevington and Robinson\\n(2003, Chapter 5), Cowan (1998, Chapter 3) and Press et al. (1992).\\n\\n9.4\\n\\nBootstrap methods\\n\\nOften real data sets have probability distributions which do not perfectly match\\none of the simple, classical distributions we have discussed extensively in the\\nearlier chapters of this book. In this case it is not possible to derive simple analytic results for the conﬁdence limits. Moreover, there are occasions when we\\nwant to consider more complicated statistics than the mean, standard deviation,\\netc. Furthermore, in addition to the question ‘what are the conﬁdence limits?’,\\nwe can also', ' ask ‘are these values realistic?’. Efron developed the bootstrap\\nmethod as a numerical technique that lets us derive conﬁdence intervals for\\nany statistic, on a data set with any probability distribution function. Indeed,\\nthe bootstrap method works even if we don’t know the probability distribution.\\nThe article by Efron and Tibshirani (1986) provides a survey of bootstrap\\ntechniques, with the deﬁnition of the bootstrap as ‘a computer-based method,\\nwhich substitutes considerable amounts of computation in place of theoretical\\nanalysis’ (Efron and Tibshirani 1986, p. 54, opening paragraph). Further details\\nof how to implement bootstrap algorithms can be found in Press et al. (1992,\\nSection 15.6).\\nThe concept of replacement is important for distinguishing among various\\nsampling schemes. Sampling schemes may or may not use replacement—an\\nelement from the original set can be selected many times with replacement, but\\ncannot be selected more than once without replacement. For example, consider\\nthe case when there are 10 red and 10 blue balls in a bag, and a sample of two is\\ndesired. Say we ﬁrst choose a red ball. With replacement, the ﬁrst ball drawn\\nis put back into the bag, such that the probability of the second ball drawn\\nbeing red is one-half, as is the the probability of the second ball drawn being\\nblue. Without replacement, the probability of the second ball drawn being red\\nis 9/19, and the probability of the second ball drawn being blue is 10/19.\\nConsider the case where there are N data points, each of which could either\\nbe a single measurement, or a more complex object such as (xi , yi ) pairs.\\nFrom these data points a statistic of interest can be calculated (such as the\\nmean, or gradient of the best-ﬁt line). The bootstrap method is implemented as\\nfollows:\\n\\n\\x0c9.5 Bayesian inference 127\\n\\n(1) Generate a synthetic data set with the same number of points as the\\noriginal set by selecting, at random, N data points from the original set,\\nwith replacement.4\\n(2) Calculate ', 'the statistic of interest for the synthetic data set.\\n(3) Repeat the ﬁrst two steps a large number of times (typically many\\nhundreds or thousands of times).\\n(4) The distribution of the large number of computed values of the statistic\\nform an estimate of the sampling distribution of the statistic.\\n\\n4 It is also possible to generate synthetic sets\\n\\nwith a different number of elements from the\\noriginal data set, but we do not consider that\\ncomplication here.\\n\\nSubject to the assumption that the data points are independent in distribution\\nand order (Press et al. 1992, Section 15.6), the bootstrap method can answer the\\nquestion as to the form of the sampling distribution for the statistic, and what\\nis (say) the 68% conﬁdence interval. Replacement is crucial in the procedure,\\nas it guarantees that the synthetic data sets are not simply identical to the\\ngenuine data set, i.e. any of the original data points can appear once, not\\nat all, or many times in a synthetic data set. As only the genuine data are\\nused, the bootstrap is an example of a resampling method. Superﬁcially, it\\nappears as if we are getting something for nothing from the bootstrap method.\\nThis was one reason why it took some time for the bootstrap method to\\ngain acceptance. Nowadays the method is backed by sufﬁciently rigorous\\ntheorems to be regarded as reputable. Since the method involves a random\\nnumber generator it ﬁts into the class of Monte Carlo methods discussed in\\nSection 9.3.\\n\\n9.5\\n\\nBayesian inference\\n\\nAll of the results presented to date in this book have been within the framework\\nof the frequentist approach to statistics. An event’s probability is interpreted\\nas the limit of its relative frequency after a large number of trials. An alternative\\napproach to statistics is adopted by Bayesians. Bayes’ theorem5 was derived\\nfrom the general axioms of probability, and relates the conditional and prior\\nprobabilities of events A and B:\\nP (A|B) = P (A)\\n\\nP (B|A)\\n,\\nP (B)\\n\\n(9.7)\\n\\nwhere P (A|B) is the conditional ', 'probability of obtaining A given that event\\nB has occurred, P (B| A) is the conditional probability of obtaining B given\\nthat event A has occurred, and P (A) and P (B) are the unconditional, or\\nprior, probabilities for A and B. The term prior probabilities for A conveys\\nthat the probability does not take into account any information about B. Note\\nin particular that A and B do not have to be repeatable events. The vertical\\nbar (‘|’) in some of the terms in eqn (9.7) denotes ‘given’—the information\\nto the right of the bar is taken as being true. In the Bayesian formulation the\\nbackground information, denoted I , is explicitly included to emphasise that\\nour calculations often make assumptions, and are hence conditional on I .\\nInherent in the Bayesian formulation is the evolution of our certainty about a\\ncertain hypothesis, H , when more data become available. The prior probability\\nwhich represents the degree of plausibility of the hypothesis, H , given the\\n\\n5 Named after the eighteenth century English\\n\\nclergyman Thomas Bayes.\\n\\n\\x0c128 Topics for further study\\n\\nbackground information, I , is P (H |I ). After experimental measurements,\\nsome data, D, become available. Using eqn (9.7) we modify the likelihood\\nfunction, P (H |D, I ):\\nP (H |D, I ) = P (H |I )\\n\\nFig. 9.5 The evolution of the posterior probability distribution function for the biasweighting of selecting a speciﬁc colour from\\na computer generated data set with the ratio\\nred(40): green(30): blue(30) as a function of\\nthe number of samples. The number of samples are 10 for (a), 100 for (b) and 1000\\nfor (c). As the number of trials increases\\nthe posterior probability distribution functions sharpen and peak at values close to the\\nparent values. The functions have been scaled\\nto have the same maximum value.\\n6 This is the binomial distribution function,\\n\\nand the derivation of this result is outlined in\\nChapter 2 of Sivia and Skilling (2006).\\n\\nP (D|H, I )\\n,\\nP (D|I )\\n\\n(9.8)\\n\\nwhich represents the posterior probability, i.e. ', 'the plausibility of the hypothesis H , given the data and background information.\\nTo illustrate the Bayesian formulation, consider the following computer generated example. A bag contains coloured balls, in the ratio red(40): green(30):\\nblue(30). We consider the evolution of the posterior probability distribution\\nfunction for the bias weighting of selecting a speciﬁc colour as a function of\\nthe number of samples. If we denote by G the bias weighting for obtaining a\\ngreen ball, then 1 − G is the bias weighting for not obtaining a green ball. After\\nN samples the posterior probability distribution function, P (GREEN|D, I ), is\\nproportional to6 G a (1 − G)b , where a is the number of green balls obtained,\\nb is the number of red or blue (i.e. not green) balls obtained, and a + b = N .\\nA similar result is obtained for the bias weighting for red and blue. Figure 9.5\\nshows the evolution of the (unnormalised) posterior probability distribution\\nfunctions for the bias weightings for red, green and blue. The number of\\nsamples are 10 for (a), 100 for (b) and 1000 for (c). As the number of trials\\nincreases the posterior probability distribution functions sharpen and peak at\\nvalues close to the parent values. The functions have been scaled to have\\nthe same maximum value, as it is the shape of the functions which is of\\ninterest to us. Note that (i) for a relatively small number of samples there is\\na broad range of bias weightings for each colour; (ii) as more data become\\navailable the centres of the functions evolve much less, and the widths of the\\ndistributions become narrower, reﬂecting our higher conﬁdence in the values of\\nthe bias weighting obtained. The evolution of the peak position of the different\\nposterior probability distribution functions shown in Fig. 9.5 as a function of\\nthe number of samples is listed in Table 9.2.\\nAn excellent treatment of Bayesian inference in data analysis is to be found\\nin the book of Sivia and Skilling (2006); the book by Cowan (1998) gives\\nexamp', 'les of Bayesian statistical tests in particle physics experiments; and the\\narticle ‘Why isn’t every physicist a Bayesian?’ by Cousins (1995) illustrates\\nthe issues involved when a practising experimenter chooses which of the two\\nTable 9.2 The peak position of the different posterior probability distribution\\nfunctions shown in Fig. 9.5 as a function\\nof the number of samples.\\nSamples\\n10\\n50\\n100\\n500\\n1000\\n2000\\n\\nRed\\n\\nBlue\\n\\nGreen\\n\\n0.5\\n0.42\\n0.38\\n0.378\\n0.376\\n0.3955\\n\\n0.1\\n0.16\\n0.29\\n0.340\\n0.319\\n0.3095\\n\\n0.4\\n0.42\\n0.33\\n0.282\\n0.305\\n0.2950\\n\\n\\x0c9.6 GUM—Guide to the Expression of Uncertainty in Measurement 129\\n\\nmajor frameworks to adopt. D’Agostini’s article (2003) highlights the role of\\nOccam’s razor, discussed in Section 8.7, in the Bayesian approach.\\n\\n9.6\\n\\nGUM—Guide to the Expression\\nof Uncertainty in Measurement\\n\\nWe noted in Chapter 1 the potential confusion over the interchangeable use\\nof the terms ‘error’ and ‘uncertainty’. In the 1990s many international bodies\\nwhich represent professional metrologists, who have responsibility for measurements and standards, published Guide to the Expression of Uncertainty in\\nMeasurement, or the GUM (1995). Organisations which support GUM include\\nBureau International des Poids et Mesures (BIPM), International Union of\\nPure and Applied Physics (IUPAP), International Union of Pure and Applied\\nChemistry (IUPAC), and the International Organization for Standardization\\n(ISO). The motivation for GUM is to clarify the deﬁnition of uncertainty,\\nwith the goal of supporting a fully consistent and transferable evaluation of\\nmeasurement uncertainty. It should be noted that, at present, the use of GUM\\nis not widespread in university laboratories. In this book we have classiﬁed\\nerrors as either random or systematic, and made no attempt to combine them.\\nIn the GUM procedure a Type A uncertainty is evaluated by statistical methods,\\nand a Type B uncertainty is evaluated by non-statistical methods. The statistical\\ntechniques introduced in Chapter 2 for dealing with', ' repeat measurements can\\nbe used to evaluate Type A uncertainties; examples of probability distribution\\nfunctions relevant for Type B uncertainties are the Gaussian and uniform\\ndistributions encountered in Chapter 2. After the relevant evaluations, the Type\\nA and B uncertainties may, or may not, be reported separately, in contrast to the\\ncombination of the two components, which is always reported. A very readable\\nintroduction to GUM can be found in Kirkup and Frenkel’s book (2006).\\n\\n\\x0cThis page intentionally left blank\\n\\n\\x0cBibliography\\nAmsler, C. et al. (Particle Data Group) (2008). Phys. Lett., B667, 1–1340.\\nBarford, N. C. (1985). Experimental Measurements: Precision, Error and Truth. John\\nWiley, New York.\\nBates, D. M. and Watts, D. G. (1988). Nonlinear Regression Analysis and its Applications. John Wiley, New York.\\nBevington, P. R. and Robinson, D. K. (2003). Data Reduction and Error Analysis.\\nMcGraw-Hill, New York.\\nBoggs, P. T., Byrd, R. H. and Schnabel, R. B. (1987). A stable and efﬁcient algorithm\\nfor nonlinear orthogonal distance regression. SIAM J. Sci. and Stat. Comput., 8,\\n1052–1078.\\nCousins, R. D. (1995). Why isn’t every physicist a Bayesian? Amer. J. Phys., 63,\\n398–410.\\nCowan, G. (1998). Statistical Data Analysis. Oxford University Press, Oxford.\\nD’Agostini, G. (2003). Bayesian inference in processing experimental data: principles\\nand basic applications. Rep. Prog. Phys., 66, 1383–1419.\\nDavison, A. C. and Hinkley, D. V. (1997). Bootstrap Methods and their Applications,\\nCambridge University Press, Cambridge.\\nDurbin, J. and Watson, G. S. (1950). Testing for serial correlation in least squares\\nregression: I. Biometrika, 37, 409–428.\\nEfron, B. and Tibshirani, R. (1986). Bootstrap methods for standard errors, conﬁdence\\nintervals, and other measures of statistical accuracy. Statist. Sci., 1, 54–75.\\nFeynman, R. P., Leighton, R. B. and Sands, M. (1963). The Feynman Lectures on\\nPhysics, Volume 1, Addison-Wesley, Reading, MA.\\nGuide to the Expression of Uncertainty in ', 'Measurement (1995). 2nd edition. International Organization for Standardization, Geneva.\\nHibbert, D. B. and Gooding, J. J. (2006). Data Analysis for Chemistry. Oxford University Press, Oxford.\\nHigbie, J. (1976). Uncertainty in the measured width of a random distribution. Amer. J.\\nPhys., 44, 706–707.\\nHolland, J. H. (1975). Adaptation in Natural and Artiﬁcial Systems University of\\nMichigan Press, Ann Arbor, MI.\\nJames, F. (2006). Statistical Methods in Experimental Physics. 2nd edition World\\nScientiﬁc, Singapore.\\nKirkpatrick, S., Gelatt Jr., C. D. and Vecchi, M. P. (1983). Optimization by simulated\\nannealing. Science, 220, 671–680.\\nKirkup, L. and Frenkel, B. (2006). An Introduction to Uncertainty in Measurement.\\nCambridge University Press, Cambridge.\\nKleppner, D. and Kolenkow R. J. (1978). An Introduction to Mechanics. McGraw-Hill,\\nNew York.\\nLevenberg, K. (1944). A method for the solution of certain problems in least squares.\\nQuart. Appl. Math., 2, 164–168.\\nLyons, L. (1991). Data Analysis for Physical Science Students. Cambridge University\\nPress, Cambridge.\\n\\n\\x0c132 Bibliography\\nMacdonald, J. R. and Thompson, W. J. (1992). Least-squares ﬁtting when both variables\\ncontain errors: pitfalls and possibilities. Amer. J. of Phys., 60, 66–73.\\nMarquardt, D. W. (1963). An algorithm for least-squares estimation of nonlinear parameters. SIAM J. Appl. Math., 11, 431–441.\\nPress, W. H., Teukolsky, S. A., Vetterling, W.T. and Flannery, B.P. (1992). Numerical\\nRecipes in Fortran 77, 2nd edition. Cambridge University Press, Cambridge.\\nReed, B. C. (1989). Linear least-squares ﬁts with errors in both coordinates. Amer. J.\\nPhys., 57, 642–646, Erratum Amer. J. Phys., 58, 189.\\nReed, B. C. (1992). Linear least-squares ﬁts with errors in both coordinates. II:\\nComments on parameter variances. Amer. J. Phys., 60, 59–62.\\nRees, D. G. (1987). Foundations of Statistics. Chapman and Hall, London.\\nSilverman, M. P., Strange, W. and Lipscombe, T. C. (2004). The distribution of\\ncomposite measurements: How t', 'o be certain of the uncertainties in what we measure.\\nAmer. J. Phys., 72, 1068–1081.\\nSivia, D. S. and Skilling, J. (2006). Data Analysis a Bayesian Tutorial, 2nd edition.\\nOxford University Press, Oxford.\\nSquires, G. L. (2001). Practical Physics. Cambridge University Press, Cambridge.\\nTaylor, J. R. (1997). An Introduction to Error Analysis. University Science Books,\\nCalifornia.\\nWiner, B. J. (1962). Statistical Principles in Experimental Design. McGraw-Hill,\\nNew York.\\n\\n\\x0cIndex\\nabscissa, 54\\nabsolute uncertainty, 18\\naccepted value, 3\\ncomparing with experimental results, 28\\naccuracy, 3, 6\\naddition in quadrature, 41, 43\\nsee also Pythagoras’ theorem\\nagreement with theory, 28, 105–6\\naliasing, 59\\nanalogue device, precision of, 5–6\\narbitrary function, least squares ﬁt to, 72–4,\\n108\\narbitrary units, 55\\narithmetic mean, see mean\\nautocorrelation, 81\\ntest for, see Durbin–Watson statistic\\nsee also lag plot\\naverage see mean\\nsee also weighted mean\\naverage deviation, 11\\nsee also standard deviation\\nBayes’ theorem, 127\\nBayesian approach to statistics, 127\\nBayesian inference, 127–9\\nbell curve, 13\\nsee also Gaussian\\nbest-ﬁt parameters, how to obtain, 73\\nbest-ﬁt straight line, 60\\nsee also method of least squares;\\nchi-squared\\nbias weighting, 128\\nbin width of histogram, 12\\ncombining bins, 111–113\\nbinomial distribution, 128\\nbootstrap method, 126–7\\ncalculus approximation to error propagation,\\n38–40, 43–4, 47\\ncalibration curve, 98\\ncalibration error, 6, 62\\ncentral limit theorem, 31–4, 36, 60, 113–114\\nChauvenet’s criterion, 27, 35\\nchi-squared, χ 2\\ncontours, 75–6\\ncumulative distribution, 104–5\\ndeﬁnition of, 61\\ndistribution for one degree of freedom, 105\\n\\nexpansion of, 75, 88\\nexpectation value, 104\\nfor Poisson statistics, 68\\nmaximum likelihood method and, 60–1\\nminimisation, see method of least squares\\n2 , deﬁnition of, 76\\nminimum, χmin\\nprobability distribution of, 104–5\\nreduced, χν2 , deﬁnition of, 107\\ntesting distributions, 111–114, 118–119\\ntesting the goodness-of-ﬁt, 108–111, 119\\nused in hypothesi', 's testing, 105–6\\nvariance of, 104\\nvariation near a minimum, 75, 98\\nclarity of data presentation, 53–7\\ncombining errors, see propagation of errors\\ncombining experimental results, 49–50\\nsee also weighted mean,\\ncommon sense in error propagation, 47\\ncommon uncertainty, 58–9, 65, 115–116\\nconditional probability, 127\\nconﬁdence limits\\nand Student’s t-distribution, 115\\nfor a Gaussian, 25–6\\nfor reduced chi-squared, 107, 118\\non parameters from a least squares ﬁt, 75–7\\nconstraints, 103, 112–114\\nin ﬁtting, 79–80\\nsee also degrees of freedom\\ncontour plot, 75\\nconvergence, 87, 97–8\\ncorrelated uncertainties, 93\\ncorrelation coefﬁcients, 94\\ncorrelation matrix, 94, 96–7\\ncounting statistics, uncertainty in, see Poisson\\ndistribution\\ncovariance, 94–5\\ncovariance matrix, 92–4\\nsee also error matrix\\ncumulative distribution, 24–5, 104–6\\ncurvature matrix, 92–3, 98\\ncurvature of error surface, 75, 88, 90–3\\ncurve ﬁtting, see method of least squares\\ndamping constant, see regularisation constant\\ndata reduction, 59, 103\\ndata rejection, see Chauvenet’s criterion\\ndecimal places, reporting results, 19\\ndegrees of freedom, 14, 102–5\\n\\ndependent and independent variables on\\ngraphs, 54\\ndeviation, deﬁnition of, 11\\nsee also, standard deviation\\ndiagonally-dominant matrix, 91\\ndigital device, precision of, 6\\ndiscrete variable, 28, 35\\ndistribution\\ncentre of, width of and uncertainty in\\nlocation of centre, 9\\ndistributions\\ncontinuous, 12\\ndiscrete, 28\\nof the mean, see also standard error, 16\\nparent, 13\\nsample, 13\\nStudent’s t,26, 115\\nsee also probability distributions\\ndominant error, 44–5, 48–9\\nDurbin–Watson statistic, 81–2, 83\\nequations, linearising, 54, 57, 64, 69\\nerror, see also uncertainty\\ncalculating errors from least squares\\nminimisation, 74–7\\ncalibration, 6, 62\\ncombining, see propagation of errors\\ncorrelated, 95–6, 98–9\\ndominant, 44–5, 48–9\\nexperimental strategy based on error\\nanalysis, 47–9, 52, 71, 83\\nﬁnal quoted, 17\\nfractional, 17, 30, 48, 56, 125\\nin counting experiments (Poisson\\nstatistics), 30\\nin mean, see', ' standard deviation of the mean\\nin standard deviation, see error in the error\\nin weighted mean, 50\\nindependent, 75\\ninsertion, 6\\nmatrix, 92\\nmistakes, 3, 4–5, 20\\npercentage, 45–6, 48, 69\\npropagating, see propagation of errors\\nrandom, 3\\nrounding, 18–19\\nscaling, 115–116\\nstandard, 14–16, 75, 92–3\\n\\n\\x0c134 Index\\n\\nerror (cont.)\\nsystematic, 4, 6, 62–3\\nwhen not quoted, 18\\nzero, 6, 62\\nerror bars\\nadding to graph, 55–6\\nas a conﬁdence limit, 25, 30\\nasymmetry of, 39–40, 47\\nnon-uniform, see also heteroscedastic data,\\n68–72\\nerror function\\nconﬁdence limits and, 25\\ndeﬁnition of, 24\\nexercises, 35\\nworked example, 25\\nerror in the error, 16–17, 20\\nerror matrix\\nanalytic form for a straight-line ﬁt, 93\\ndeﬁnition of, 92\\ndiagonal elements being variance of\\nparameters, 92\\nexercises, 98–9\\nsee also covariance matrix\\nerror propagation\\nsee propagation of errors\\nerror surface, 74–5\\ncomplex error surfaces with multiple\\nminima, 123–4\\ncurvature of, 75, 88, 90–3\\nmoving across, 76\\nexact numbers, 19\\nextrapolation, 59, 103–4\\nexpansion of error surface\\nGauss–Newton method, 89–90\\nNewton method, 88–9\\nexpectation value, deﬁnition of, 24\\nexperimental strategy based on error analysis,\\n47–9, 52, 71, 83\\nfactorial function (N!), deﬁnition of, 29\\nﬁtting data to a model, 116–117\\nsee also method of least squares\\nﬁtting with constraints, 79–80\\nfractional uncertainty, 17, 30, 125\\nsee also percentage uncertainty\\nfrequentist approach to statistics, 127\\nfunctional approach\\nfor multi-variable functions, 41–3\\nfor single-variable functions, 38–40\\nfundamental noise, 3–4\\ngamma function, deﬁnition of, 104\\nGaussian\\nand central limit theorem, 31\\nchi-squared test of, 113–4\\nconﬁdence limits, 25, 35\\ndeﬁnition of, 13\\nexperimental example, 27–8\\nprobability distribution function, 24\\nGauss–Newton method, 89–90\\n\\ngenetic algorithm, 124\\nglobal minimum, 123\\ngood ﬁt, deﬁnition of, 58, 68, 110–111\\ngoodness-of-ﬁt parameter, see chi-squared\\ngradient-descent method, 87–8\\ngradient of straight line graph, see\\nstraight-line graphs\\ngradient vector, 88', '\\ngraphs\\nadding best-ﬁt line, 57–9\\nchoosing scales, 54\\ndata symbols in graphs, 55, 57\\nguidelines for plotting data, 53–7\\nguide to the eye, 57\\nlab-book graphs, 53\\nlabelling axes, 54–5\\nlegends, 57\\nlinearising data for plotting, 54\\nplotting error bars, 55–6\\npublication graphs, 54\\nseeing trends in the data graphically,\\n56–7\\nusing graphs to estimate errors,\\n62–3\\ngrid-search method, 86–7\\nGUM (Guide to expression of Uncertainty in\\nMeasurement), 3, 129\\nHessian matrix, 89\\nand curvature matrix, 92\\nheteroscedastic data, 68–9\\nhistogram, 12\\nhyper-surface, 74, 85\\nhypothesis\\nnull, 101\\ntesting, 101–2, 108–9\\nindependent errors, 75\\nsee also correlated uncertainties\\nindependent events, 28–30\\nindependent variable, 41\\ninsertion error, 6\\nintegral probability, see cumulative\\ndistribution\\nintercept of straight line graph, see\\nstraight-line graphs\\ninterpolation, 59, 103–4\\niterative methods, 86, 97–8\\nJacobian matrix, 89–91\\nJohnson noise, 4\\nlab-book graphs, see graphs\\nlag plot, 81–2\\nlikelihood function, 128\\nline minimisation, 87\\nline of best ﬁt\\nadding to graph, 57\\ndeﬁnition, 58\\nexercise, 64\\n\\nrelation to method of least squares, 60–3\\nsee also straight-line graphs\\nlinear regression, see straight-line graphs, 83\\nlinear relationship between dependent and\\nindependent variables 54\\nlinear trend line, 58\\nsee also method of least squares\\nlinearising data, 54, 64\\nlocal minimum, 87, 88, 123\\nMarquardt–Levenberg method, 90–2\\nmatrix\\ncorrelation, 94,\\ncovariance, 92–4\\ncurvature, 92–3, 98\\ndiagonally-dominant, 91\\nerror, 92\\nHessian, 89\\nJacobian, 89–91\\ntranspose, 89\\nmaximum likelihood, 59–61\\nmean\\ndeﬁnition of, 10\\ndeviation from, 10\\ndifference between two, 48–9\\ndistribution of, see central limit theorem\\nerror of, see standard error\\nexercises, 20\\nweighted, see weighted mean\\nmeasurements\\naccuracy of, 6\\nexercises, 20\\nprecision of, 5–6\\nrepetition of, 2–6, 9–10, 27, 29, 50, 57, 69\\ntrial, 10, 16, 32–3, 125, 127–8\\nuncertainty in, 2\\nmedian, deﬁnition of, 104\\nmethod of least squares, 58–61\\nanalytic results for unweighted b', 'est-ﬁt\\nstraight line, 58–9\\nanalytic results for weighted best-ﬁt\\nstraight line, 69–70\\nconﬁdence limits for a least squares ﬁt,\\n75–7\\nﬁt to an arbitrary nonlinear function,\\n72–4\\nﬁt to an nth order polynomial, 72\\nobtaining the best-ﬁt parameters by\\nminimisation, 73\\nobtaining the errors in the best-ﬁt\\nparameters by minimisation, 74–7, 83\\nworked examples, 77–9\\nuncertainties in both variables, 121–122\\nminimisation methods, 86–92\\nsee also grid-search method;\\ngradient-descent method; Newton\\nmethod; Gauss–Newton method;\\nMarquardt–Levenberg method;\\nsimulated annealing; genetic\\nalgorithm\\n\\n\\x0cIndex\\n\\nmistakes, 3, 4–5, 20\\nconfusion over units, 5\\nmalfunction of apparatus, 5\\nmisreading scales, 5\\nmode, deﬁnition of, 104\\nmodel\\nnumber of parameters in, see Occam’s\\nrazor\\ntesting, see hypothesis; chi-squared\\nMonte-Carlo method, 92, 125–6\\nmost probable value, see mode\\nNewton method, 88–9\\nNewton–Raphson method, 86, 97–8\\nnoise\\nsee fundamental noise, technical noise, shot\\nnoise\\nsee also, signal to noise\\nnonlinear ﬁtting, see method of least squares\\nnormal distribution, see Gaussian\\nnormalised probability distribution, deﬁnition\\nof, 23\\nnormalised residual, 72, 81, 83\\nsee also residual and lag plot\\nnull hypothesis, 101\\nOccam’s razor, 114, 129\\noffset on instrument revealed by graph, 62–3\\nordinate, 54\\northogonal distance regression (ODR), 122–3\\noutliers, 26–7, 49, 81\\noverdetermined system, 60\\nparabolic approximation to error surface at\\nminimum, 75, 98\\nparameter estimation, 19, 40, 60–1, 67, 72–3\\nparent distribution, deﬁnition of, 13\\npercentage uncertainty, 45–6, 48, 69\\nsee also fractional uncertainty\\nplausibility of hypothesis, 127–8\\nPoisson distribution, 28–31\\napproximation for large mean, 30–1,\\n36\\nasymmetry of, 29\\nchi-squared test of, 112–113\\nconﬁdence limits, 30\\ndeﬁnition of, 29\\nexercises, 35–6\\nfractional uncertainty for Poisson counts,\\n30\\nmean of, 29\\nstandard deviation of, 29\\nworked examples, 29–30\\nposterior probability distribution function,\\n127–8\\nprecision, deﬁnition of, 3, 5\\nof analogue de', 'vice, 5–6\\nof digital device, 6\\npreﬁxes used in the SI system, 54\\nprior probability distribution function, 127–8\\n\\nprobability density function (PDF), see\\nprobability distribution, 23\\nprobability distributions\\nbinomial, 128\\nchi-squared, 104\\nGaussian, 24, 60\\nnormal, see Gaussian\\nPoisson, 29\\nuniform, 35\\npropagation of errors\\ncalculus approximation for many variables,\\n43\\nsummary table for common\\nmulti-variable functions, 44\\ncalculus approximation for single variable,\\n38–9\\nsummary table for common single\\nvariable functions, 39\\nworked example, 40\\ncovariance in, 95–7\\nexercises, 51–2\\nfunctional approach for many variables,\\n40–1\\nworked example, 42–3\\nfunctional approach for single variable,\\n37–8\\nworked example, 39–40\\nsummary, 47\\nwith correlated errors, 95–6, 98–9\\npublication graphs, see graphs\\nPythagoras’ theorem applied to error\\npropagation, 41, 43\\nquadratic sum, see addition in quadrature\\nquoting results, 19, 20\\nrandom error, 3\\nexercises, 20\\ninﬂuence on precision, 3–4, 9–17\\nrandom number, 125, 127\\nreduced chi-squared, χν2 , 107\\nconﬁdence limits in, 107, 118\\nrole in testing the null hypothesis, 107\\nsee also chi-squared\\nregression analysis, 60\\nregularisation constant, 90–1\\nrejecting outliers, 26–7\\nsee also Chauvenet’s criterion\\nrejecting the null hypothesis, 102, 106–8\\nrepetition of measurements, 2–6, 9–10, 27,\\n29, 50, 57, 69\\nreplacement, 126\\nreporting results, 17–19, 20–1\\nresampling, 126–7\\nresidual, 60, 63–4, 90\\nsee also normalised residual and lag plot\\nrounding, 18–19\\nerrors, 18\\nround-to-even method, 19\\nrules for rounding, 18–19\\n\\n135\\n\\nsample distribution, deﬁnition of, 13\\nsampling, 126–7\\nscale factor, 93, 115–116\\nscientiﬁc notation, 18, 21\\nshot noise, 4, 30, 118\\nsee also Johnson noise\\nsignal to noise, 4, 14, 30–1\\nsigniﬁcance level (%), 101–2, 106\\nsigniﬁcant ﬁgures\\nand scientiﬁc notation, 18\\nreporting results, 17, 21\\nrule for addition and subtraction, 19\\nrule for identifying, 18\\nrule for multiplication and division, 19\\nsee also error in the error\\nsimulated annealing, 123–4\\nsk', 'ewness, 104\\nslope, see straight-line graphs\\nstandard deviation, σ\\n68% conﬁdence limit, 26\\nas uncertainty in a single measurement,\\n12\\nas width of distribution, 10\\ndeﬁnition of,\\nrough and ready approach, 10–11\\nstatistical, 12\\nevolution with sample size, 14\\nexercises, 20\\nof parent distribution, 13\\nof Poisson distribution, 29\\nof sample distribution, 13\\nworked example, 11–12\\nstandard deviation of the mean (SDOM), 16,\\n26, 31, 50\\nsee also central limit theorem\\nsee also standard error\\nstandard error, α, 4–16, 92–3\\nand curvature of error surface, 75\\ndeﬁnition of, 16\\nexercises, 20, 98–9\\nsee also distribution, uncertainty in location\\nof centre\\nsee also standard deviation of the mean\\nsteepest descent, 87–8, 91\\nstep sizes, searches, 86–7, 89\\nstraight-line graphs\\ncurvature matrix for, 93, 95–6, 98\\nunweighted ﬁt\\nanalytic results for gradient and\\nintercept, 58–9\\nexercises, 64–5, 83\\nweighted ﬁt\\nanalytic results for gradient and\\nintercept, 69–70\\nexercises, 83\\nsee also method of least squares\\nStudent’s t-distribution, 26, 115\\nsynthetic data set, 127\\nsystematic error, 4, 6\\ninﬂuence on accuracy, 3\\n\\n\\x0c136 Index\\n\\nsystematic error (cont.)\\nusing graphs to test for systematic errors,\\n62–3\\nsee also calibration error, insertion error\\nand zero error\\nt-statistic, deﬁnition of, 115\\ntangent planes of error surface, 76, 92\\nTaylor series expansion, 43\\nin error propagation, 38, 43\\nof chi-squared, 75, 88\\ntechnical noise, 3–4\\ntesting the null hypothesis, 108\\ntolerance, 86, 115\\ntransformational method, 125\\ntrigonometric functions, error propagation in,\\n39\\nType A and Type B uncertainties, 129\\nuncertainty, see also error\\nabsolute uncertainty, 18\\nboth variables having uncertainties, and\\nleast-squares ﬁtting, 121–2\\ncommon uncertainty, 58–9, 65, 115–116\\nfractional uncertainty, 17, 30, 125\\nin a parameter, and contour density, 75–7\\nin a parameter from a Monte Carlo\\nsimulation, 125\\nin counting experiments (Poisson\\nstatistics), 30\\nin ﬁt parameters, and error matrix, 92–3\\nin mean, see standard deviation of the mea', 'n\\nin standard deviation, see error in the error\\n\\nin weighted mean, 50\\npercentage uncertainty, 45–6, 48, 69\\npropagation, see propagation of errors\\nsuccessive repeats give different values, 2\\nType A and Type B, 129\\nwhen not quoted, 18\\nuncorrelated variable, 41\\nuniform distribution, 35\\nupdate rules in minimisation, 86, 91\\nvalue\\naccepted, 3\\nbest estimate of, 3\\nvariable\\ncontinuous, 12, 23, 30–3, 35\\ndependent, 54\\ndiscrete, 4, 12, 28–30, 35\\nindependent, 54\\nvariance, 11, 24, 92–3\\nsee also standard deviation\\nweighted least squares\\nfor arbitrary nonlinear function, 72–4\\nfor nth order polynomial, 72\\nfor straight line ﬁts, 69–71\\nweighted mean, 49–50, 52\\nweighting factor, deﬁnitions of, 50, 70,\\n121–2\\nwhat constitutes a good ﬁt?, 58, 68, 110–111\\nwidth of distribution, see standard deviation, 3\\nworked examples\\ncalculating the mean of ten measurements,\\n10\\n\\ncalculating the standard deviation of ten\\nmeasurements, 11–12\\ncorrelation matrix for a four-parameter ﬁt,\\n96–7\\ncurvature matrix for a straight-line ﬁt,\\n95–6\\nestimating the spread of ten measurements,\\n10\\nﬁtting a linear function through chi-squared\\nminimisation, 77–8\\nﬁtting a nonlinear function through\\nchi-squared minimisation, 79\\nPoisson counting statistics, 29–30\\npropagating errors in multi-variable\\nfunctions, 42–3, 44–5\\npropagating errors in single-variable\\nfunctions, 39–40\\nquoting results, 17\\nrejecting an outlier – using Chauvenet’s\\ncriterion, 27\\ntesting a continuous distribution using\\nchi-squared, 113–114\\ntesting a discrete distribution using\\nchi-squared, 112–113\\ntesting different models using chi-squared,\\n109–110\\ntesting the quality of a ﬁt using\\nchi-squared, 109\\nusing the error function, 25\\nzero crossing of a function, see\\nNewton–Raphson method\\nzero error, 6, 62\\n\\n\\x0cUncertainties in multi-variable\\nfunctions\\nFor the multi-variable function Z = f (A, B, C . . .): the uncertainty in Z due to the uncertainty in A is:\\n\\x02 \\x03\\n\\x04\\n\\x03\\n\\x04\\x02\\nα ZA = \\x02 f Ā + α A , B̄ − f Ā, B̄ \\x02 ,\\nthe uncertainty in Z due to the uncertainty in B is:\\n\\x02 \\x03\\n\\x04\\n\\x03\\n\\x04\\x02', '\\nα ZB = \\x02 f Ā, B̄ + α B − f Ā, B̄ \\x02 ,\\nand similarly for C, D, . . . . From Pythagoras’ theorem the total error is:\\n\\x10 \\x112 \\x10 \\x112\\n(α Z )2 = α ZA + α ZB + · · ·\\nAssuming small uncertainties the calculus-based approximation to this result is:\\n\\x0e\\n\\x0e\\n\\x0e\\n\\x0f\\n\\x0f\\n\\x0f\\n∂Z 2\\n∂Z 2\\n∂Z 2\\n2\\n2\\n2\\n(α A ) +\\n(α B ) +\\n(αC )2 + · · ·\\n(α Z ) =\\n∂A\\n∂B\\n∂C\\nTable 2 Some simple rules for the propagation of errors in multi-variable functions. Always\\nperform a quick check for dominant errors before using these formulae.\\nExpression used to calculate α Z\\n\\nFunction, Z\\n\\nZ = A+B\\nZ = A−B\\n\\n\\x18\\n\\n⎫\\nZ = A × B⎬\\nA\\nZ=\\n⎭\\nB\\nn\\nZ=A\\nZ = kA\\nZ =k\\n\\nA\\nB\\n\\nAn\\nZ =k m\\nB\\nZ = A+ B−C + D\\n(A × B)\\n(C × D)\\n\\x03 n\\n\\x04\\nA × Bm\\nZ=\\n(C p × D q )\\nZ=\\n\\n\\x17\\nαZ =\\n\\n(α A )2 + (α B )2\\n\\x1c\\x10\\nαZ\\nα A \\x112 \\x10 α B \\x112\\n=\\n+\\nZ\\nA\\nB\\n\\x02α \\x02 \\x02 α \\x02\\n\\x02 Z \\x02 \\x02 A\\x02\\n\\x02 = \\x02n\\n\\x02\\n\\x02\\nZ\\nA \\x02\\n\\x02 \\x02\\n\\x02\\n\\x02 αZ \\x02 \\x02 α A \\x02\\nα Z = |k| α A OR \\x02\\n\\x02=\\x02\\n\\x02\\nZ\\nA\\n\\x1c\\x10\\n\\x11\\n\\x11\\n\\x10\\nαZ\\nαA 2\\nαB 2\\n=\\n+\\nZ\\nA\\nB\\n\\x1c\\x10\\n\\x11\\n\\x10\\n2\\nαA\\nα B \\x112\\nαZ\\n=\\nn\\n+ m\\nZ\\nA\\nB\\n\\x17\\n2\\n2\\nα Z = (α A ) + (α B ) + (αC )2 + (α D )2\\n\\x1c\\x10\\nαZ\\nα A \\x112 \\x10 α B \\x112 \\x10 αC \\x112 \\x10 α D \\x112\\n=\\n+\\n+\\n+\\nZ\\nA\\nB\\nC\\nD\\n\\x1c\\x10\\n\\x11\\n\\x11\\n\\x11\\n\\x10\\n\\x10\\n\\x10 α \\x112\\n2\\n2\\n2\\nαA\\nαB\\nαC\\nαZ\\nD\\n=\\nn\\n+ m\\n+ p\\n+ q\\nZ\\nA\\nB\\nC\\nD\\n\\n\\x0c']\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "\n",
    "def load_large_document(file_path, chunk_size=2000, encoding='utf-8'):\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        while True:\n",
    "            chunk = file.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "\n",
    "for chunk in load_large_document('file_name.txt'):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42cf8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.embeddings.create(\n",
    "  model=\"text-embedding-ada-002\",\n",
    "  input=chunks,\n",
    "  encoding_format=\"float\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d9186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00207193  0.00108825 -0.01498739 ...  0.01438478 -0.0155971\n",
      " -0.04474949]\n"
     ]
    }
   ],
   "source": [
    "query_response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=[query],\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "query_embedding = query_response.data[0].embedding\n",
    "query_embedding = np.array(query_embedding).flatten()\n",
    "\n",
    "print(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "963f8976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7122081257527494, 0.7208577527499321, 0.7579591474414539, 0.7282442784317867, 0.7227790455773949, 0.7579457943196682, 0.7858806253936579, 0.798717538399048, 0.7288407178337333, 0.7282808156737461, 0.7303737005114859, 0.7230495662122927, 0.7236369975655741, 0.7097042610082006, 0.7024222413288089, 0.7176272247511002, 0.7099194163872667, 0.7196004817619154, 0.7192680192700882, 0.7412721123479225, 0.7367121857681002, 0.7525936767736485, 0.7488726644729342, 0.7259114831581245, 0.7415241353157187, 0.7306609135930535, 0.7332544437848795, 0.7414185141408092, 0.7347839956685149, 0.7528838261623895, 0.7698288903898622, 0.7334626487897024, 0.727469988470392, 0.7594677029236606, 0.7425021613887174, 0.760804994474767, 0.7246162584776124, 0.7455520924772668, 0.7430166937126378, 0.7380924148751191, 0.7523425122935409, 0.7667261633720832, 0.746109842180755, 0.7369515681181859, 0.7366054695192764, 0.7190595305080234, 0.7339653699565157, 0.7274576869762434, 0.7458497513720624, 0.7472600520096788, 0.7475014063613042, 0.735856015393258, 0.7270105168938692, 0.7567586351614144, 0.7464242726006806, 0.7360481329629199, 0.722375628160594, 0.7149970948795435, 0.7460330564580706, 0.7053363000852203, 0.7278673709173787, 0.7120508589866898, 0.7211054168938037, 0.6952530997929628, 0.7126727432866677, 0.729128581013176, 0.7415962253552731, 0.7466890190603531, 0.7350327916221058, 0.7348187192842381, 0.7442141484818984, 0.7479777885516582, 0.7309436797198682, 0.7369777496271961, 0.7689137740087943, 0.7405745525528884, 0.7362322180172395, 0.7276981507018994, 0.7239118216545355, 0.7471632783661334, 0.7394471086644733, 0.7267436793283099, 0.7433581855420874, 0.7577415445701373, 0.7551422642377342, 0.7600958404373185, 0.7318450325249485, 0.8083422499007307, 0.8004416269934663, 0.7807956604391542, 0.7689674098548428, 0.7531876972271305, 0.760724697501533, 0.7756519816476088, 0.799649610093921, 0.7817385026907564, 0.76093514323932, 0.7477275913838872, 0.757599112689447, 0.7683201685316631, 0.7457414683740403, 0.7629515238532079, 0.76387424813605, 0.7356039783859142, 0.7731923393159943, 0.8206276471649278, 0.7736006751520682, 0.7980387176331797, 0.8159587038320529, 0.7905634182126062, 0.7556636663491625, 0.740649126287493, 0.754986138690136, 0.8045720431017389, 0.7531017076794241, 0.7817342270678586, 0.765981745758716, 0.7622676201718674, 0.7899114708233221, 0.8177890712741743, 0.7190680778495994, 0.7861597346598745, 0.8017478350031995, 0.7717516042063645, 0.769318731724891, 0.776218260185627, 0.7715588256845801, 0.7484521599529887, 0.7566089836487448, 0.7597320890838718, 0.7350788259596506, 0.7436758273302111, 0.742975655139178, 0.7736661763331035, 0.7604475548880146, 0.793904131425914, 0.757975001217807, 0.7553931414274729, 0.7722883528225116, 0.7855511329552844, 0.8068336649120795, 0.7663724430361678, 0.7625657876660493, 0.7511508498930317, 0.8093440892838258, 0.8102940434665807, 0.819983188791468, 0.8199873466181995, 0.835062052050499, 0.8270052487767998, 0.84950924854537, 0.8364469215351532, 0.8170740077377471, 0.7620616844070168, 0.8027790709047402, 0.7912067513625887, 0.8083859399487611, 0.8047025208369604, 0.7867255743134882, 0.7776464416454222, 0.786369293963606, 0.7663339736198101, 0.7954137174105756, 0.8068023053060207, 0.8361742100261085, 0.7954492031876013, 0.7697553216154659, 0.8049860757934406, 0.7893144089431122, 0.7785320512942716, 0.7638602861410473, 0.7613340470662756, 0.7727960429392019, 0.7468330425751851, 0.7596618505089551, 0.7493345724642242, 0.7327077493331013, 0.7322124995435868, 0.7395810011401154, 0.7508393653378627, 0.7420467805702424, 0.7385467807417188, 0.7614861428600667, 0.7707054057201203, 0.7430773179624991, 0.7259332591741096, 0.7421518941505015, 0.7572894412416178, 0.7100188133948604, 0.7366375701892276, 0.7330768110873357, 0.7314651094951309]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "similarity_scores = []\n",
    "for embedding_data in db.data:\n",
    "    chunk_embedding = embedding_data.embedding\n",
    "\n",
    "    chunk_embedding = np.array(chunk_embedding).flatten()\n",
    "\n",
    "    score = cosine_similarity(query_embedding, chunk_embedding)\n",
    "    similarity_scores.append(score)\n",
    "    \n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37009f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All documents sourced from: Measurements and their Uncertainties A practical guide to modern error analysis by I.G. Hughes and T.P.A.Hase .txt-squared statistic, χν2 ;\n",
      "2\n",
      "equal to the ﬁt value or\n",
      "(2) the probability of obtaining a value of χmin\n",
      "2\n",
      "higher, given ν, P(χmin ; ν).\n",
      "The χν2 statistic is signiﬁcantly easier to calculate and can be used to reject\n",
      "the null hypothesis if χν2 > 3. Ambiguity arises in using the χν2 statistic to\n",
      "reject the null hypothesis for values in the range 1 ≤ χν2 ≤ 3 due to a strong\n",
      "dependence of the χν2 conﬁdence levels on ν as seen in Table 8.1. This\n",
      "ambiguity can be resolved by calculating (using appropriate software or look2 or higher\n",
      "up tables) the probability of obtaining the observed value of χmin\n",
      "2\n",
      "for the number of degrees of freedom, P(χmin ; ν). This probability has a\n",
      "much weaker dependence on ν and the null hypothesis should be rejected if\n",
      "2 ; ν) < 10−4 .\n",
      "P(χmin\n",
      "By rejecting the null hypothesis we are stating that the discrepancies\n",
      "between the data and proposed model are very unlikely to be due to random statistical ﬂuctuations; there must be a genuine systematic reason for\n",
      "the disagreement. A good experimentalist would then try different models\n",
      "with insight gained from further analysis of, for example, the normalised\n",
      "residuals.\n",
      "\n",
      "8.5\n",
      "4 For a straight-line ﬁt the procedure to obtain\n",
      "2 is as follows:\n",
      "χmin\n",
      "\n",
      "• obtain the best-ﬁt parameters and their\n",
      "uncertainties using eqns (6.3)–(6.6);\n",
      "• for each data point, yi , calculate the\n",
      "y −y x\n",
      "normalised residual, R = i ( i ) ,\n",
      "i\n",
      "\n",
      "αi\n",
      "\n",
      "using the best-ﬁt function, y(xi );\n",
      "2 by summing the square\n",
      "• calculate χmin\n",
      "of the normalised residuals for the data\n",
      "set.\n",
      "\n",
      "Testing the quality of a ﬁt using χ 2\n",
      "\n",
      "The χ 2 statistic can be used as a test of the quality of a ﬁt. In this section we\n",
      "discuss by example (a) how to answer the question ‘are the data well described\n",
      "by the theoretical model?’, and (b) how to answer the related question ‘which\n",
      "model best describes the data?’.\n",
      "The ﬁrst step in conducting a χ 2 test is to determine the best-ﬁt model\n",
      "2 depends on the functional form of the\n",
      "function. The procedure to ﬁnd χmin\n",
      "theoretical model. We saw in Chapter 6 that for a simple straight line the\n",
      "best-ﬁt line is easily determined analytically.4 If the theoretical model is an\n",
      "arbitrary function we highlighted in Chapters 6 and 7 the numerical techniques\n",
      "for minimising χ 2 .\n",
      "The null hypothesis is that the model is an appropriate description of the\n",
      "data. If the null hypothesis is not rejected the model is said to be a ‘good ﬁt’\n",
      "2 ; ν) exceed the limits discussed\n",
      "to the data. If the values of either χν2 or P(χmin\n",
      "above, the null hypothesis is rejected and the model is said to be a ‘poor ﬁt’\n",
      "to the data. While it is clear what the extremes of a good and poor ﬁt are, the\n",
      "boundary between them is much more subjective. Our advice is to quote both\n",
      "\n",
      "\f8.5 Testing the quality of a ﬁt using χ 2\n",
      "\n",
      "109\n",
      "\n",
      "2 , the number of degrees of freedom, ν, and P(χ 2 ; ν) which\n",
      "the value of χmin\n",
      "min\n",
      "allows the reader to judge the quality of the ﬁt.\n",
      "We now show through some worked examples how the χ 2 -test can be\n",
      "applied to testing the quality of a ﬁt and testing different models.\n",
      "\n",
      "8.5.1\n",
      "\n",
      "Worked example 1—testing the quality of a ﬁt\n",
      "\n",
      "In Fig. 8.6 we show the data obtained by monitoring the radioactive decay\n",
      "from an active 137 Ba isotope. The count rate is expected to decay exponentially\n",
      "to a constant background level. A suitable model to ﬁt the data will contain\n",
      "three parameters; the initial activity, the half-life of the decay and the background level. Using the procedures outlined in Chapter 6, these parameters\n",
      "and their associated errors were obtained by minimising χ 2 to obtain a value\n",
      "2 = 53.5. There are 62 data points and as there are three ﬁt parameters\n",
      "of χmin\n",
      "the number of degrees of freedom is ν = 59. The reduced χ 2 value is therefore\n",
      "χν2 = 0.9. As this is less than 1.5 (Table 8.1), and not signiﬁcantly less than\n",
      "1, we do not reject the null hypothesis. We can further quantify the quality\n",
      "of ﬁt by using eqn (8.4) to determine the probability of obtaining the value\n",
      "2 = 53.5, or larger, for 59 degrees of freedom. Using suitabl Based on the value of χmin\n",
      "i.e. questions such as ‘are my data consistent with a Gaussian distribution?’ should be answered at this stage.\n",
      "2\n",
      "and ν to decide\n",
      "• If there are competing theoretical models use χmin\n",
      "which model is most appropriate.\n",
      "• If the quality of the ﬁt is poor either (a) consider a different theoretical\n",
      "model, or if the theoretical model is known to be valid for the conditions\n",
      "of the experiment, (b) try to identify defects in the experiment or\n",
      "analysis.\n",
      "• For a good ﬁt the values of the parameters which minimised χ 2 are used\n",
      "to answer the question ‘what are the best-ﬁt parameters?’.\n",
      "• Calculate the error matrix and use the square root of the diagonal\n",
      "elements to answer the question ‘what are the uncertainties in the bestﬁt parameters?’.\n",
      "\n",
      "Chapter summary\n",
      "• The χ 2 statistic can be used for hypothesis testing.\n",
      "• The question ‘are my data consistent with the proposed model?’ can be\n",
      "2 .\n",
      "answered by analysing the value of χmin\n",
      "• The number of degrees of freedom, ν, is equal to the number of data\n",
      "points, N , less the number of constraints, N .\n",
      "• For√a good ﬁt, the expectation value of χ 2 is ν, with a standard deviation\n",
      "of 2ν.\n",
      "√\n",
      "2 > ν + 3 2ν the null hypothesis is rejected.\n",
      "• If χmin\n",
      "χ2\n",
      "• Reduced chi-squared, χν2 , is deﬁned as χν2 = min .\n",
      "ν\n",
      "• Occam’s razor can be used to eliminate unwarranted extra parameters\n",
      "in a theoretical model.\n",
      "• Student’s t distribution should be used when comparing experimental\n",
      "results with an accepted value with a small number of degrees of\n",
      "freedom.\n",
      "• It is possible to scale error bars and estimate the statistical ﬂuctuations\n",
      "in a data set if one is conﬁdent that the appropriate theoretical model\n",
      "has been used to describe the data (at the expense of foregoing any\n",
      "discussion about the quality of the ﬁt).\n",
      "\n",
      "\f118 Hypothesis testing\n",
      "\n",
      "Exercises\n",
      "(8.1) Conﬁdence limits for χν2\n",
      "Make a table similar to Table 8.1 and calculate the 68%\n",
      "and 90% conﬁdence limits as a function of the degrees\n",
      "of freedom for the χν2 statistic.\n",
      "\n",
      "sequential\n",
      "χ 2 f\n",
      "ν − 2 2ν ≤ χmin\n",
      "\u0004\n",
      "\u0003 2\n",
      "; ν ≈ 10−3 or\n",
      "• The null hypothesis is questioned if P χmin\n",
      "\u0003 2\n",
      "\u0004\n",
      "P χmin ; ν > 0.5.\n",
      "\u0003 2\n",
      "\u0004\n",
      "• The null hypothesis is rejected if P χmin\n",
      "; ν < 10−4 .\n",
      "\n",
      "\f8.4 Using χ 2 as a hypothesis test\n",
      "\n",
      "8.4.1\n",
      "\n",
      "107\n",
      "\n",
      "The reduced χ 2 statistic\n",
      "\n",
      "In order to ascertain whether a particular null hypothesis should be rejected at\n",
      "a particular conﬁdence level, the probabilities of obtaining the observed value\n",
      "2 or higher given the number of degrees of freedom must be calculated\n",
      "of χmin\n",
      "using eqn (8.4). However, we can obtain a quick indication as to whether the\n",
      "null hypothesis should be rejected by considering the so-called reduced chi2 divided by the number\n",
      "squared statistic, χν2 , which is simply the value of χmin\n",
      "of degrees of freedom:\n",
      "χν2 =\n",
      "\n",
      "2\n",
      "χmin\n",
      ".\n",
      "ν\n",
      "\n",
      "(8.6)\n",
      "\n",
      "A good match between the sample and parent distribution occurs when χν2 ≈ 1.\n",
      "We can understand why the null hypothesis is not rejected if χν2 ≈ 1 by considering that for good agreement between the sample and parent distribution\n",
      "each point will differ from its expected value, i.e. the mean, by typically\n",
      "the standard deviation of the mean (standard error). Thus each term in the\n",
      "summation of the χ 2 statistic should be of order one, with the result that\n",
      "2\n",
      "≈ N . Typically, as the number of degrees of freedom is similar to the\n",
      "χmin\n",
      "number of data points, χν2 is thus expected to be unity. If the value of χν2 is\n",
      "much larger than one, it is likely that the null hypothesis should be rejected.\n",
      "A very small value of χν2 is also unlikely—either the error bars have been\n",
      "overestimated, which reduces the value of χ 2 , or the observed and expected\n",
      "values are unrealistically close. Again it is for the experimenter to decide at\n",
      "what conﬁdence limit the null hypothesis should be rejected in terms of the\n",
      "reduced chi-squared statistic, χν2 . In Section 8.4 we discussed how one would\n",
      "2 was within 2σ of the mean for a\n",
      "not be surprised if the observed value of χmin\n",
      "good ﬁt, and that the null hypothesis should only be questioned if the value of\n",
      "2 was larger than, say, 3σ from the mean. As the standard deviation of the\n",
      "χmin\n",
      "χ 2 distribution depends on ν, the conﬁdence limits for χν2 also depend on ν. In\n",
      "Fig. 8.5 the values of χν2 calculated at ν + σ , ν + 2σ , and ν + 3σ are plotted\n",
      "as a function of the number of degrees of freedom. Recall that for a Gaussian\n",
      "distribution these intervals correspond to the 68%, 95% and 99.7% conﬁdence\n",
      "limits. The 3σ conﬁdence limit of χν2 is tabulated for several values of ν in\n",
      "Table 8.1.\n",
      "• For a reasonable ﬁt the value of χν2 ≈ 1.\n",
      "• If χν2 \u0012 1 check your calculations for the uncertainties in the measurements, αi .\n",
      "• The null hypothesis is questioned if χν2 > 2 for ν ≈ 10.\n",
      "• The null hypothesis is questioned if χν2 > 1.5 if ν is in the approximate\n",
      "range 50 ≤ ν ≤ 100.\n",
      "Although easier to calculate, \u0003χν2 does\u0004 not contain as much information as\n",
      "2 and ν to calculate P χ 2 ; ν ; see Exercise (8.2).\n",
      "using χmin\n",
      "min\n",
      "\n",
      "Fig. 8.5 χν2 calculated at ν + σ (dotted),\n",
      "ν + 2σ (dashed), and ν + 3σ (solid) and\n",
      "plotted as a function of the number of degrees\n",
      "of freedom. For 100 degrees of freedom the\n",
      "limit for not rejecting the null hypothesis is\n",
      "for a value of χν2 of 1.4, whereas it is 2.3 for\n",
      "10 degrees of freedom.\n",
      "\n",
      "Table 8.1 Example values of the\n",
      "largest acceptable values\n",
      "of χν\u00112\n",
      "\u0010\n",
      "obtained from the χν2 + 3σ\n",
      "conﬁdence level for different\n",
      "degrees of freedom, ν.\n",
      "ν\n",
      "5\n",
      "10\n",
      "20\n",
      "30\n",
      "50\n",
      "100\n",
      "500\n",
      "\n",
      "\u0010\n",
      "\n",
      "χν2 + 3σ\n",
      "2.9\n",
      "2.3\n",
      "1.9\n",
      "1.8\n",
      "1.6\n",
      "1.4\n",
      "1.2\n",
      "\n",
      "\u0011\n",
      "\n",
      "\f108 Hypothesis testing\n",
      "\n",
      "8.4.2\n",
      "\n",
      "Testing the null hypothesis—a summary\n",
      "\n",
      "The null hypothesis is that the sample distribution is well modelled by a\n",
      "proposed parent distribution and that any scatter between the two distributions\n",
      "is a result of random statistical variations in the sample. A χ 2 test of this\n",
      "2 and then determining\n",
      "hypothesis is performed by ﬁrst ﬁnding the value of χmin\n",
      "the number of degrees of freedom. We have seen in the previous sections\n",
      "that there are two numbers which can be used to test the validity of the null\n",
      "hypothesis:\n",
      "(1) the reduced chi\n"
     ]
    }
   ],
   "source": [
    "chunk_scores = list(zip(chunks, similarity_scores))\n",
    "sorted_chunks = sorted(chunk_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_n = 5\n",
    "combined_string = \"All documents sourced from: file_name .txt\"\n",
    "for i in range(top_n):\n",
    "    combined_string += sorted_chunks[i][0]\n",
    "    \n",
    "print(combined_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d13a4",
   "metadata": {},
   "source": [
    "We've updated our prompt a little bit so that the chatbot knows how we want equations to be outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2694a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Answer the question based only on this context: {combined_string}. Answer the question based on the above context: {query}, you should explain as if i do not have access to this context, always quote _______ as your source. run any code you create, quote explicitely any equations in latex format, always use $ when writing latex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf7c3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt,        \n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb403b91",
   "metadata": {},
   "source": [
    "Here we've changed some of the functions by first initialising in def __init__(self) a string refered to as buffer. This string is then updated in the on_text_created and on_text_delta functions where we have replaced them outputting text with them storing text instead. We then use the format_buffer function to format the text into something that latex can easily read, we essentially just split the plain text, from code, from latex math. The display_output function then takes the processed text from the format_buffer function and displays them as appropriate making the output of our chatbot more readable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39f938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "import io\n",
    "import requests\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.buffer = \"\"  # Buffer to collect text output\n",
    "        \n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        if not self.buffer.endswith(text.value):  # Prevent duplication\n",
    "            self.buffer += text.value\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        if not self.buffer.endswith(delta.value):  # Prevent duplication\n",
    "            self.buffer += delta.value\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "            \n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(f\"\\n\\noutput >\", flush=True)\n",
    "                for output in delta.code_interpreter.outputs:\n",
    "                    if output.type == \"logs\":\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                    elif output.type == \"image\":\n",
    "                        # Fetch the image data using the file_id\n",
    "                        file_id = output.image.file_id\n",
    "                        image_data = self.download_image(file_id)\n",
    "                        if image_data:\n",
    "                            image = Image.open(io.BytesIO(image_data))\n",
    "                            image.show()\n",
    "  \n",
    "    def download_image(self, file_id):\n",
    "        url = f\"https://api.openai.com/v1/files/{file_id}/content\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {openai_api_key}\",\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.content\n",
    "        else:\n",
    "            print(f\"Failed to download image: {response.status_code} {response.text}\")\n",
    "            return None\n",
    "        \n",
    "    def display_output(self):\n",
    "\n",
    "        # Process the buffer to format LaTeX and code blocks\n",
    "        processed_content = self.format_buffer(self.buffer)\n",
    "\n",
    "        # Display as Markdown to correctly render LaTeX and plain text\n",
    "        display(Markdown(processed_content))\n",
    "\n",
    "    def format_buffer(self, buffer):\n",
    "        # Split buffer into lines for processing\n",
    "        lines = buffer.split(\"\\n\")\n",
    "        formatted_lines = []\n",
    "\n",
    "        in_code_block = False\n",
    "\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"code_interpreter\"):\n",
    "                in_code_block = True\n",
    "                formatted_lines.append(line)\n",
    "            elif line.strip() == \"```\":\n",
    "                in_code_block = False\n",
    "                formatted_lines.append(line)\n",
    "            elif in_code_block:\n",
    "                formatted_lines.append(line)\n",
    "            else:\n",
    "                # Check for LaTeX patterns and wrap them in delimiters\n",
    "                line = line.replace(r'\\(', '$').replace(r'\\)', '$')\n",
    "                line = line.replace(r'\\[', '$$').replace(r'\\]', '$$')\n",
    "                formatted_lines.append(line)\n",
    "        \n",
    "        return \"\\n\".join(formatted_lines)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d0dcf",
   "metadata": {},
   "source": [
    "Note here that when you run the stream, you need to 1: create a unique EventHandler(), 2: specify that EventHandler in the stream and 3: without event_handler.display_output() no visible output would be given, so this is an important step to be able to see your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bca3721e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To find the minimum chi-squared value ($\\chi_{\\text{min}}^2$), you can follow a systematic procedure. This process is essential for testing the quality of a fit between your data and a theoretical model. Here’s a step-by-step guide:\n",
       "\n",
       "1. **Obtain the Best-Fit Parameters**:\n",
       "   - First, you need to determine the best-fit parameters for your model. These parameters are those that minimize the chi-squared value. The equations for obtaining these parameters depend on the specific model you are using. For a straight-line fit, you can use the equations provided in the book \"Measurements and their Uncertainties: A practical guide to modern error analysis\" by I.G. Hughes and T.P.A. Hase.\n",
       "\n",
       "2. **Calculate the Normalized Residuals**:\n",
       "   - For each data point, calculate the normalized residual. The normalized residual $R_i$ for a data point $y_i$ with an associated uncertainty $\\alpha_i$ is given by:\n",
       "     $$\n",
       "     R_i = \\frac{y_i - y(x_i)}{\\alpha_i}\n",
       "     $$\n",
       "     Here, $y(x_i)$ is the value predicted by the best-fit function at the point $x_i$.\n",
       "\n",
       "3. **Sum the Squares of the Normalized Residuals**:\n",
       "   - The minimum chi-squared value ($\\chi_{\\text{min}}^2$) is obtained by summing the squares of the normalized residuals for all data points:\n",
       "     $$\n",
       "     \\chi_{\\text{min}}^2 = \\sum_{i} R_i^2 = \\sum_{i} \\left(\\frac{y_i - y(x_i)}{\\alpha_i}\\right)^2\n",
       "     $$\n",
       "\n",
       "### Example for a Straight-Line Fit\n",
       "\n",
       "For a straight-line fit, the procedure is as follows:\n",
       "\n",
       "1. **Determine the Best-Fit Parameters**:\n",
       "   - Use the equations for a straight-line fit to find the slope and intercept that minimize $\\chi^2$.\n",
       "\n",
       "2. **Calculate the Normalized Residuals**:\n",
       "   - For each data point $(x_i, y_i)$ with uncertainty $\\alpha_i$, calculate:\n",
       "     $$\n",
       "     R_i = \\frac{y_i - (mx_i + c)}{\\alpha_i}\n",
       "     $$\n",
       "     where $m$ is the slope and $c$ is the intercept of the best-fit line.\n",
       "\n",
       "3. **Sum the Squares of the Normalized Residuals**:\n",
       "   - Compute the minimum chi-squared value:\n",
       "     $$\n",
       "     \\chi_{\\text{min}}^2 = \\sum_{i} \\left(\\frac{y_i - (mx_i + c)}{\\alpha_i}\\right)^2\n",
       "     $$\n",
       "\n",
       "By following these steps, you can find the minimum chi-squared value, which is a crucial part of assessing the quality of your fit. This process is detailed in \"Measurements and their Uncertainties: A practical guide to modern error analysis\" by I.G. Hughes and T.P.A. Hase."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "event_handler = EventHandler()\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"\",\n",
    "  event_handler=event_handler,\n",
    ") as stream:\n",
    "  stream.until_done()\n",
    "\n",
    "event_handler.display_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8ff5f",
   "metadata": {},
   "source": [
    "Similarly as we've done before you can then use the following two boxes to have a conversation, each time you use it you need only change the message in thread_message content= then run the next box to continue the conversation as we're use messages.create here to add messages to the already existing thread. Also note that we need to create a new EventHandler() everytime we want a new output as the current eventhandler only stores the most recent output, dont worry about storage though because we can simply just overwrite this eventhandler everytime we send a new message and then store the messages seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c56d4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what chapter would i find it in again?\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4235055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You can find the detailed procedure for obtaining the minimum chi-squared value ($\\chi_{\\text{min}}^2$) in Chapter 8 of \"Measurements and their Uncertainties: A practical guide to modern error analysis\" by I.G. Hughes and T.P.A. Hase. Specifically, the relevant sections are:\n",
       "\n",
       "- **Section 8.4**: Using $\\chi^2$ as a hypothesis test\n",
       "- **Section 8.5**: Testing the quality of a fit using $\\chi^2$\n",
       "\n",
       "These sections provide a comprehensive explanation of how to calculate $\\chi_{\\text{min}}^2$ and use it to test the quality of a fit between your data and a theoretical model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "event_handler2 = EventHandler()\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"\",\n",
    "  event_handler=event_handler2,\n",
    ") as stream:\n",
    "  stream.until_done()\n",
    "\n",
    "event_handler2.display_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81da5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
