{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8b462e",
   "metadata": {},
   "source": [
    "In this jupyter notebook we'll be creating a chat bot that is able to take data and create line of best fit for that data using python, we'll give it access to a data analysis textbook specifically Measurements and their Uncertainties A practical guide to modern error analysis by I.G. Hughes and T.P.A.Hase such that it performs the task in a way we'll be familiar with. We start as we have done before: importing modules that we need to and creating the assistant. Make sure that if you haven't already installed the openai module that you install it and if anything goes wrong in the code and you have not installed the openai module, install it and try again. \n",
    "\n",
    "You'll notice that when creating the assistant we have defined a term known as \"top_p\", a lower top_p makes the model more deterministic but a higher top_p makes the model more creative and diverse. Because we are trying to make a chat bot that gives information to the user based on data that it already has we'll use a top_p of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0215c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"\"\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Code_Interpreter+File_Supported\",\n",
    "  description=\"You are a factual education AI Assistant dedicated to providing accurate, useful information. Your primary task is to assist me by providing me reliable and clear responses to my questions, only ever use information from file search as your source, this knowledge base is the measurements and their uncertainties textbook.  You are reluctant of making any claims unless they are stated or supported by the knowledge base.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}],\n",
    "  top_p=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915fe3c",
   "metadata": {},
   "source": [
    "We can then call .update to give the assistant access to a precreated vector store of the pdf of your choice (you'll need to do this through Open AIs dashboard). We could have also done this when creating the assistant but as a means for demonstrating that you may change an assistant during your code I have chosen to do it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [\"your_vector_store_id\"]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6a981",
   "metadata": {},
   "source": [
    "We then load the data we want to give the chat bot and start a thread including that data and the prompt we want to give the chatbot, here because we are giving the chatbot data we have specified the tool we want it to use is the code_interpreter but we could have included all of the tools if we were unsure what the input file would be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de057735",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file=open(\"Data.csv\", \"rb\"),\n",
    "    purpose=\"user_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8214095",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"how would i go about writing code that can plot the line of best fit on this data using a method of least squares \",\n",
    "      \"attachments\": [\n",
    "        {\"file_id\": file.id,\"tools\": [{\"type\": \"code_interpreter\"}]}, \n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc441e",
   "metadata": {},
   "source": [
    "We'll use the exact same event handler as we did in the code interpreter and then run our stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "\n",
    "class EventHandler(AssistantEventHandler):    \n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(f\"\\n\\noutput >\", flush=True)\n",
    "                for output in delta.code_interpreter.outputs:\n",
    "                    if output.type == \"logs\":\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "                    elif output.type == \"image\":\n",
    "                        # Fetch the image data using the file_id\n",
    "                        file_id = output.image.file_id\n",
    "                        image_data = self.download_image(file_id)\n",
    "                        if image_data:\n",
    "                            image = Image.open(io.BytesIO(image_data))\n",
    "                            image.show()\n",
    "  \n",
    "    def download_image(self, file_id):\n",
    "        url = f\"https://api.openai.com/v1/files/{file_id}/content\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {openai_api_key}\",\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.content\n",
    "        else:\n",
    "            print(f\"Failed to download image: {response.status_code} {response.text}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
